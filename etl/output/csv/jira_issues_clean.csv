key,fields.summary,fields.issuetype.name,fields.issuetype.id,fields.status.name,fields.status.id,fields.resolution.name,fields.resolutiondate,fields.created,fields.updated,fields.assignee.name,fields.assignee.displayName,fields.assignee.key,fields.description,created,resolved
BOOKKEEPER-680,Bookkeeper bookies need to store ledger keys with ledger fragments,Bug,1,Resolved,5,Fixed,2017-10-09 11:47:23,2009-04-01 15:59:07,2017-10-09T11:47:23.000+0000,,,,"currently ledger keys are stored in memory; however, we need to restrict access even after reboots so it needs to be in nonvolatile storage. the most obvious solution would be to store the ledger keys with the ledger fragments on the bookie.",2009-04-01 15:59:07,2017-10-09 11:47:23
BOOKKEEPER-14,Size limit for bookkeeper scans,Improvement,4,Resolved,5,Won't Do,2017-10-09 09:57:19,2009-05-08 05:29:21,2017-10-09T09:57:19.000+0000,,,,"Right now a bookkeeper scan can limit the amount of data scanned by specifying the number of entries to be scanned. But in many cases, if the entries are of different sizes, it is not easy to know how many to scan.

It is better to be able to specify both a count limit as well as a size limit , with the semantics that the scan should stop if either of those limits is reached.",2009-05-08 05:29:21,2017-10-09 09:57:19
BOOKKEEPER-10,Last hint for open ledger,New Feature,2,Resolved,5,Done,2017-10-09 09:58:01,2009-07-11 07:45:46,2017-10-09T09:58:01.000+0000,fpj,Flavio Paiva Junqueira,fpj,"In some use cases of BookKeeper, it is useful to be able to read from a ledger before closing the ledger. To enable such a feature, the writer has to be able to communicate to a reader how many entries it has been able to write successfully. The main idea of this jira is to continuously update a znode with the number of successful writes, and a reader can, for example, watch the node for changes.

 I was thinking of having a configuration parameter to state how often a writer should update the hint on ZooKeeper (e.g., every 1000 requests, every 10,000 requests). Clearly updating more often increases the overhead of writing to ZooKeeper, although the impact on the performance of writes to BookKeeper should be minimal given that we make an asynchronous call to update the hint.",2009-07-11 07:45:46,2017-10-09 09:58:01
BOOKKEEPER-691,improve bookkeeper javadocs for internal classes,Bug,1,Resolved,5,Won't Do,2017-10-09 09:36:54,2010-01-26 18:00:58,2017-10-09T09:36:54.000+0000,breed,Benjamin Reed,breed,the internal classes of bookkeeper are lacking javadoc.,2010-01-26 18:00:58,2017-10-09 09:36:54
BOOKKEEPER-694,GSoC 2010: FUSE module for BookKeeper,Wish,5,Resolved,5,Won't Do,2017-10-09 09:35:17,2010-03-13 00:41:21,2017-10-09T09:35:17.000+0000,,,,"FUSE module for BookKeeper
Possible Mentor
Ben Reed (breed at apache dot org)

Requirements
C/Java, some networking familiarity

Description
BookKeeper is a distributed write ahead log with client & server written in Java. BookKeeper client & server also use ZooKeeper. There is a BookKeeper API that clients can use to integrate write ahead logging into their application. It would be a lot easier if applications could use BK without changes to the client application through use of a file system api (FUSE). The project would involve implementing a C interface for BookKeeper (Java already exists) and implementing the FUSE module.

Example use: the write ahead log in mysql, called binlogs are typically written to the local filesystem using the std filesystem api. We could modify mysql to use BooKeeper, however if we had a BK FUSE module we could run it (mysql) w/o any modification and get the performance/reliability of a distributed write ahead log.",2010-03-13 00:41:21,2017-10-09 09:35:17
BOOKKEEPER-2,bookkeeper does not put enough meta-data in to do recovery properly,Sub-task,7,Closed,6,Fixed,2012-07-18 15:01:41,2010-07-09 20:40:40,2013-02-13T15:46:26.000+0000,ikelly,Ivan Kelly,ikelly,"somewhere, probably zookeeper, we need to keep track of the the information about keys used for access and for mac validation as well as the digest type for entries. we can't write a general recovery tool without it.",2010-07-09 20:40:40,2012-07-18 15:01:41
BOOKKEEPER-693,Review of BookKeeper Documentation (Sequence flow and failure scenarios),Task,3,Resolved,5,Done,2017-10-09 09:35:52,2010-11-04 08:30:00,2017-10-09T09:35:52.000+0000,,,,"I have prepared a document describing some of the internals of bookkeeper in terms of:
1. Sequence of operations
2. Files layout
3. Failure scenarios

The document is prepared by mostly by reading the code. Can somebody who understands the design review the same.",2010-11-04 08:30:00,2017-10-09 09:35:52
BOOKKEEPER-17,Documentation for Hedwig,Improvement,4,Resolved,5,Fixed,2011-06-28 04:28:47,2010-11-16 18:33:51,2011-11-30T11:40:17.000+0000,ikelly,Ivan Kelly,ikelly,,2010-11-16 18:33:51,2011-06-28 04:28:47
BOOKKEEPER-5,Issue with Netty in BookKeeper,Bug,1,Closed,6,Fixed,2011-08-30 07:49:03,2011-02-21 20:55:47,2011-12-07T15:56:09.000+0000,ikelly,Ivan Kelly,ikelly,"In one my experiments, I found that a BookKeeper object was locked after I tried to halt it. By searching the Web, I found that the issue is described here:

http://www.jboss.org/netty/community.html#nabble-td5492010

I'll upload a patch to fix it. For now, I'm marking it for 3.4.0, but if there is any chance we can get it in 3.3.3, it would be nice.",2011-02-21 20:55:47,2011-08-30 07:49:03
BOOKKEEPER-11,Read from open ledger,New Feature,2,Closed,6,Fixed,2011-07-28 18:34:55,2011-02-22 22:45:38,2011-12-07T15:56:14.000+0000,ikelly,Ivan Kelly,ikelly,"The BookKeeper client currently does not allow a client to read from an open ledger. That is, if the creator of a ledger is still writing to it (and the ledger is not closed), then an attempt to open the same ledger for reading will execute the code to recover the ledger, assuming that the ledger has not been correctly closed.

It seems that there are applications that do require the ability to read from a ledger while it is being written to, and the main goal of this jira is to discuss possible implementations of this feature.",2011-02-22 22:45:38,2011-07-28 18:34:55
BOOKKEEPER-12,BookKeeper as a sequencer,New Feature,2,Resolved,5,Won't Do,2017-10-09 09:57:29,2011-03-08 10:41:52,2017-10-09T09:57:29.000+0000,fpj,Flavio Paiva Junqueira,fpj,"It would be interesting to use BookKeeper as a sequencer for a number of parallel streams of events. The general idea is to use BookKeeper to establish a total order on the events of concurrent streams, and use the ordered sequence as the input of an architectural element that processes the events in the streams. This way the state of the element is reproducible.

Given that we currently interleave the entries of concurrent ledgers in a bookie for writing efficiently, I believe it wouldn't be difficult to extend the interface to enable such a feature.",2011-03-08 10:41:52,2017-10-09 09:57:29
BOOKKEEPER-692,TeaKeeper: Hot standby support using bookkeeper,Improvement,4,Resolved,5,Won't Do,2017-10-09 09:36:36,2011-03-14 17:20:36,2017-10-09T09:36:36.000+0000,ikelly,Ivan Kelly,ikelly,"Currently Bookkeeper provides functionality for cold backups. If the entity logging to bookkeeper fails, its replacement must recover the ledgers which had been used for backup before becoming available. This is acceptable in some cases, such as HBase Wals where a small delay in recovery only results in a small percentage of data being unavailable. 

However, systems such as the HDFS namenode, this delay can be unacceptable, such as cases where data is being served to customers. Secondary namenodes should be ready to go the instant the primary goes down.

TeaKeeper proposes a wrapper library around Bookkeeper providing T-Junction like functionality for logging. It also provides for primary/secondary election and automated hot failover. 

HDFS namenode is primary target of this work.

The attached design doc contains more details.",2011-03-14 17:20:36,2017-10-09 09:36:36
BOOKKEEPER-1,Static variable makes tests fail,Bug,1,Closed,6,Fixed,2011-05-25 09:42:40,2011-04-26 17:19:10,2011-12-07T15:56:08.000+0000,ikelly,Ivan Kelly,ikelly,"The following final static variable is causing LedgerDeleteTest to fail:

{noformat}
final static long LOG_SIZE_LIMIT = Long.getLong(""logSizeLimit"", 2 * 1024 * 1024 * 1024L);
{noformat}

because the test counts on the value of the variable to change and the new maven setup uses a single process by default, so the value of the variable doesn't change. ",2011-04-26 17:19:10,2011-05-25 09:42:40
BOOKKEEPER-18,maven build is unstable,Bug,1,Closed,6,Fixed,2011-08-29 17:34:45,2011-05-16 16:40:33,2011-12-07T15:56:17.000+0000,ikelly,Ivan Kelly,ikelly,"When checking out from trunk, and after installing zookeeper and zookeeper test artifacts in the local maven repo, and compiling protocol buffers, the build does not work out of the box (either mvn package or mvn -fae test).

I had to modify several files for managing to run the build without issues.

These modifications are included in the attached patch.
",2011-05-16 16:40:33,2011-08-29 17:34:45
BOOKKEEPER-19,BookKeeper doesn't support more than 2Gig of memory,Bug,1,Closed,6,Fixed,2011-05-20 14:15:56,2011-05-18 12:55:23,2011-11-09T15:53:18.000+0000,ikelly,Ivan Kelly,ikelly,"From LedgerCache.java
    private static int pageLimit = (int)(Runtime.getRuntime().maxMemory() / 3) / LedgerEntryPage.PAGE_SIZE;

pageLimit will be negative is maxMemory is 2^31 or more. This causes exceptions later on when pageLimit is used.",2011-05-18 12:55:23,2011-05-20 14:15:56
BOOKKEEPER-21,need to move the bookkeeper doc over from zookeeper,Bug,1,Resolved,5,Fixed,2011-06-28 04:27:39,2011-05-31 17:32:01,2011-11-30T11:41:01.000+0000,,,,the bookkeeper doc is currently in the zookeeper documentation. we need to move it over.,2011-05-31 17:32:01,2011-06-28 04:27:39
BOOKKEEPER-22,Exception in LedgerCache causes addEntry request to fail,Bug,1,Closed,6,Fixed,2011-06-06 15:50:21,2011-06-01 11:31:09,2011-12-07T15:56:13.000+0000,ikelly,Ivan Kelly,ikelly,"The following exception causes a client to stall:

{noformat}
WARN  - [NIOServerFactory:NIOServerFactory@123] - Exception in server socket loop: /0.0.0.0
java.util.NoSuchElementException
        at java.util.HashMap$HashIterator.nextEntry(HashMap.java:796)
        at java.util.HashMap$EntryIterator.next(HashMap.java:834)
        at java.util.HashMap$EntryIterator.next(HashMap.java:832)
        at org.apache.bookkeeper.bookie.LedgerCache.grabCleanPage(LedgerCache.java:429)
        at org.apache.bookkeeper.bookie.LedgerCache.putEntryOffset(LedgerCache.java:133)
        at org.apache.bookkeeper.bookie.LedgerDescriptor.addEntry(LedgerDescriptor.java:84)
        at org.apache.bookkeeper.bookie.Bookie.addEntry(Bookie.java:477)
        at org.apache.bookkeeper.proto.BookieServer.processPacket(BookieServer.java:108)
        at org.apache.bookkeeper.proto.NIOServerFactory$Cnxn.readRequest(NIOServerFactory.java:309)
        at org.apache.bookkeeper.proto.NIOServerFactory$Cnxn.doIO(NIOServerFactory.java:207)
        at org.apache.bookkeeper.proto.NIOServerFactory.run(NIOServerFactory.java:118)

{noformat}

The client  remains connected to the bookie, but never receives a response to the addEntry, causing the client pipeline to stall.",2011-06-01 11:31:09,2011-06-06 15:50:21
BOOKKEEPER-23,Timeout requests,Improvement,4,Closed,6,Fixed,2012-02-01 11:16:30,2011-06-01 21:09:04,2012-10-22T14:50:18.000+0000,ikelly,Ivan Kelly,ikelly,"If a client remains connected to a bookie, requests do not timeout. This is an undesirable behavior if a bookie is up but not responding to a request for some reason, like it is slow or has not handled an exception appropriately and did not respond to the client. I propose to add a timeout mechanism.",2011-06-01 21:09:04,2012-02-01 11:16:30
BOOKKEEPER-24,Client requests get no response when exception is thrown inside socket loop of NIOServerFactory,Bug,1,Resolved,5,Fixed,2017-10-09 09:56:38,2011-06-02 13:46:26,2017-10-09T09:56:38.000+0000,,,,"In the run method of NIOServerFactory, if an exception is thrown, then we catch it and simply log. If this exception has been generated, for example, while processing an addEntry, then the client receives no response for that request.",2011-06-02 13:46:26,2017-10-09 09:56:38
BOOKKEEPER-26,Indentation is all messed up in the BookKeeper code,Improvement,4,Closed,6,Fixed,2011-09-05 17:39:56,2011-06-17 13:41:32,2011-12-07T15:56:07.000+0000,ikelly,Ivan Kelly,ikelly,The indentation in BK code alternates between 2 space and 4 space. We should fix this now if we're ever going to resolve it as otherwise it'll kill history. We have very little history now so it shouldn't be a problem.,2011-06-17 13:41:32,2011-09-05 17:39:56
BOOKKEEPER-27,mvn site failed with unresolved dependencies,Bug,1,Closed,6,Fixed,2011-07-30 23:59:12,2011-06-29 11:11:34,2011-12-07T15:56:04.000+0000,ikelly,Ivan Kelly,ikelly,"This stops javadoc from being generated.

[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building hedwig-protocol 3.4.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] 
[INFO] --- maven-site-plugin:2.0.1:site (default-site) @ hedwig-protocol ---
[INFO]                                                                         
[INFO] ------------------------------------------------------------------------
[INFO] Building hedwig-client 3.4.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] bookkeeper ........................................ SUCCESS [10.312s]
[INFO] hedwig-protocol ................................... SUCCESS [0.111s]
[INFO] hedwig-client ..................................... FAILURE [0.399s]
[INFO] bookkeeper-server ................................. SKIPPED
[INFO] hedwig-server ..................................... SKIPPED
[INFO] bookkeeper-benchmark .............................. SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 11.104s
[INFO] Finished at: Wed Jun 29 13:10:10 CEST 2011
[INFO] Final Memory: 8M/81M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal on project hedwig-client: Could not resolve dependencies for project org.apache.bookkeeper:hedwig-client:jar:3.4.0-SNAPSHOT: Could not find artifact org.apache.bookkeeper:hedwig-protocol:jar:3.4.0-SNAPSHOT -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
[ERROR] For more information about the errors and possible solutions, please read the following articles:
[ERROR] [Help 1] http://cwiki.apache.org/confluence/display/MAVEN/DependencyResolutionException
[ERROR] 
[ERROR] After correcting the problems, you can resum",2011-06-29 11:11:34,2011-07-30 23:59:12
BOOKKEEPER-28,Create useful startup scripts for bookkeeper and hedwig,Bug,1,Closed,6,Fixed,2011-08-30 08:47:49,2011-06-29 12:33:42,2011-12-07T15:56:16.000+0000,ikelly,Ivan Kelly,ikelly,"hedwig's current startup script is messy. bookkeeper doesn't even have one. They should be created before initial release 

bookkeeper-server/bin/bookkeeper
hedwig-server/bin/hedwig

",2011-06-29 12:33:42,2011-08-30 08:47:49
BOOKKEEPER-29,BookieRecoveryTest fails intermittently,Bug,1,Closed,6,Fixed,2011-08-11 19:38:50,2011-06-29 15:35:13,2011-12-07T15:56:11.000+0000,ikelly,Ivan Kelly,ikelly,"The failure doesn't hit every time. You have to run, multiple times. From bookkeeper-server, run mvn test -Dtest=BookieRecoveryTest multiple times to repro.
Test output is attached.

-------------------------------------------------------
 T E S T S
-------------------------------------------------------
Running org.apache.bookkeeper.test.BookieRecoveryTest
log4j:WARN No appenders could be found for logger (org.apache.bookkeeper.test.BaseTestCase).
log4j:WARN Please initialize the log4j system properly.
Tests run: 8, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 6.794 sec <<< FAILURE!

Results :

Tests in error: 
  testAsyncBookieRecoveryToSpecificBookie[1](org.apache.bookkeeper.test.BookieRecoveryTest)

Tests run: 8, Failures: 0, Errors: 1, Skipped: 0

",2011-06-29 15:35:13,2011-08-11 19:38:50
BOOKKEEPER-30,Test are too noisy,Improvement,4,Closed,6,Fixed,2011-07-12 10:37:32,2011-06-29 15:38:03,2011-12-07T15:56:15.000+0000,ikelly,Ivan Kelly,ikelly,"Tests for hedwig currently output a lot of log4j. Logs should be disabled by default. Each module should have a log4j.properties in src/test/resources with everything disabled but commented out so logs are easy to enable for the tests.

Also, bookkeeper complains about lack of appenders.",2011-06-29 15:38:03,2011-07-12 10:37:32
BOOKKEEPER-31,Need a project logo,Improvement,4,Resolved,5,Done,2017-10-06 08:42:53,2011-07-01 22:07:08,2017-10-06T08:42:53.000+0000,breed,Benjamin Reed,breed,we need a logo for the project something that looks good in the big and the small and is easily recognizable.,2011-07-01 22:07:08,2017-10-06 08:42:53
BOOKKEEPER-32,Clean up LOG.debug statements,Improvement,4,Closed,6,Fixed,2012-09-14 13:44:00,2011-07-07 13:31:23,2013-02-13T15:46:27.000+0000,stuhood,Stu Hood,stuhood,"There are a couple of LOG.debug statements in the client package that are not in an if block under isDebugEnabled(). They are invoked frequently, so they affect performance.",2011-07-07 13:31:23,2012-09-14 13:44:00
BOOKKEEPER-33,Add length and offset parameter to addEntry,Improvement,4,Closed,6,Fixed,2011-08-11 18:38:28,2011-07-14 08:30:43,2011-12-07T15:56:10.000+0000,ikelly,Ivan Kelly,ikelly,"<from email to dev list>
I'm having an issue with the LedgerHandle#addEntry api.

[1] best illustrates it. I'm buffering namenode transactions in the stream and only transmitting when either flush is called or I have enough data to pass my threshold. This means I have a byte buffer in my class which I fill up as new transactions come in. When I transmit, I set this buffer as an entry to bookkeeper. I.e. N whole namenode transactions will be contained in 1 single bk entry. 

The problem is this byte buffer (DataOutputBuffer in this case). I reuse the same buffer over and over. But this buffer has a fixed size. If I transmit before it is full, the whole buffer size will be transmitted anyhow. If the buffer is being reused, this will retransmit old transactions out of order. For example, in the first use, the buffer fills with, [a,b,c,d,e] and adds this as an entry and resets the byte buffer. Then transaction f is  added and flushed, in this case [f,b,c,d,e] is not transmitted. 

What I need is the ability to set offset and length in the byte[] passed to addEntry. Is there a reason this wasn't added in the initial implementation? If not, and if you agree this is a valid usecase, ill open a JIRA and add this functionality. Im getting around this now by doing an extra Array.copyOf which is less than ideal.
</from email>",2011-07-14 08:30:43,2011-08-11 18:38:28
BOOKKEEPER-34,org.apache.bookkeeper.test.BookieReadWriteTest fails since 1143850,Bug,1,Resolved,5,Invalid,2011-08-01 16:21:07,2011-07-18 20:43:50,2011-11-30T11:41:49.000+0000,,,,"Repro instructions:

Checkout trunk 
mvn clean install -DskipTests
mvn test 

git bisect indicates that the problem came in with BOOKKEEPER-5. I haven't had a look at what it actually is though yet.

",2011-07-18 20:43:50,2011-08-01 16:21:07
BOOKKEEPER-36,Client backpressure,Improvement,4,Open,1,,,2011-07-29 13:52:34,2017-10-17T21:29:54.000+0000,fpj,Flavio Paiva Junqueira,fpj,"The way we currently throttle on the client is by counting the number of outstanding operation on LedgerHandle, and having the application select what an appropriate value is. This is not a good way of doing it because the application has to guess what a good value is. We need to implement some form of backpressure instead to make sure we throttle only when the system is saturated. ",2011-07-29 13:52:34,
BOOKKEEPER-38,Bookie Server doesn't exit when its zookeeper session is expired. So the process is hang there.,Bug,1,Closed,6,Fixed,2011-08-23 22:39:35,2011-08-08 06:53:22,2011-12-07T15:56:06.000+0000,ikelly,Ivan Kelly,ikelly,"Bookie server doesn't process zookeeper watcher events and just ignore them. So when session expires, bookie server hangs there and can't do nothing.",2011-08-08 06:53:22,2011-08-23 22:39:35
BOOKKEEPER-39,"Bookie server failed to restart because of too many ledgers (more than ~50,000 ledgers)",Bug,1,Closed,6,Fixed,2011-11-28 18:29:17,2011-08-08 09:15:25,2016-06-08T08:15:14.000+0000,ikelly,Ivan Kelly,ikelly,"If we have ~500,000 topics in hedwig, we might have more than ~500,000 ledgers in bookkeeper (a topic has more than 1 ledger). So when the bookie server restarted, a logfile GC thread is started, which will call zk.getChildren to fetch all ledgers, and it failed because of package length limitation.

2011-08-01 01:18:46,373 - ERROR [main-EventThread:EntryLogger$GarbageCollectorThread$1@164] - Error polling ZK for the available ledger nodes:
org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /ledgers
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
        at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
        at org.apache.zookeeper.ZooKeeper.getChildren(ZooKeeper.java:1519)
        at org.apache.bookkeeper.bookie.EntryLogger$GarbageCollectorThread$1.processResult(EntryLogger.java:162)
        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:592)
        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:481)
2011-08-01 01:18:46,373 - WARN  [main-EventThread:Bookie$1@242] - ZK client has been disconnected to the ZK server!
2011-08-01 01:18:47,278 - WARN  [main-SendThread(perf13.platform.mobile.sp2.yahoo.com:2181):ClientCnxn$SendThread@980] - Session 0x131833dec850034 for server perf13.platform.mobile.sp2.yahoo.com/98.139.43.86:2181, unexpected error, closing socket connection and attempting reconnect
java.io.IOException: Packet len9976413 is out of range!
        at org.apache.zookeeper.ClientCnxnSocket.readLength(ClientCnxnSocket.java:112)
        at org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:78)
        at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:264)
        at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:958) ",2011-08-08 09:15:25,2011-11-28 18:29:17
BOOKKEEPER-40,BookieClientTest fails intermittantly,Bug,1,Closed,6,Fixed,2012-01-13 17:07:11,2011-08-08 11:29:00,2012-10-22T14:50:19.000+0000,ikelly,Ivan Kelly,ikelly,"To repro:
true; while [ $? = 0 ]; do mvn test -Dtest=BookieClientTest; done

Problem seems to be
{code}
        BookieClient bc = new BookieClient(channelFactory, executor);
        ChannelBuffer bb;
        bb = createByteBuffer(1, 1, 1);
        bc.addEntry(addr, 1, passwd, 1, bb, wrcb, null);
        synchronized (arc) {
            bc.readEntry(addr, 1, 1, recb, arc);

{code}
The test doesn't wait for addEntry to complete before doing a read. It should be simple to fix. ",2011-08-08 11:29:00,2012-01-13 17:07:11
BOOKKEEPER-41,Generation of packages for distribution.,Improvement,4,Closed,6,Fixed,2011-10-06 16:54:46,2011-08-10 14:20:35,2011-12-07T15:56:05.000+0000,ikelly,Ivan Kelly,ikelly,We should configure maven to generate distribution tarballs. ,2011-08-10 14:20:35,2011-10-06 16:54:46
BOOKKEEPER-42,bookkeeper-server readme file is outdated,Bug,1,Resolved,5,Fixed,2017-10-09 09:56:29,2011-08-10 18:40:57,2017-10-09T09:56:29.000+0000,,,,The information in the file is outdated.,2011-08-10 18:40:57,2017-10-09 09:56:29
BOOKKEEPER-43,NullPointException when releasing topic,Bug,1,Closed,6,Fixed,2011-08-23 22:35:08,2011-08-11 05:20:40,2011-12-07T15:56:17.000+0000,ikelly,Ivan Kelly,ikelly,"Got NullPoint Exception when releasing topic.

java.lang.NullPointerException
        at org.apache.hedwig.server.subscriptions.AbstractSubscriptionManager.lostTopic(AbstractSubscriptionManager.java:221)
        at org.apache.hedwig.server.topics.AbstractTopicManager.realReleaseTopic(AbstractTopicManager.java:153)
        at org.apache.hedwig.server.topics.AbstractTopicManager.access$000(AbstractTopicManager.java:38)
        at org.apache.hedwig.server.topics.AbstractTopicManager$1.operationFailed(AbstractTopicManager.java:140)
        at org.apache.hedwig.util.CallbackUtils$1.tick(CallbackUtils.java:75)
        at org.apache.hedwig.util.CallbackUtils$1.operationFailed(CallbackUtils.java:85)
        at org.apache.hedwig.server.common.TopicOpQueuer$AsynchronousOp$1.operationFailed(TopicOpQueuer.java:54)
        at org.apache.hedwig.server.subscriptions.AbstractSubscriptionManager$AcquireOp$1.operationFailed(AbstractSubscriptionManager.java:139)
        at org.apache.hedwig.server.subscriptions.ZkSubscriptionManager$1.safeProcessResult(ZkSubscriptionManager.java:79)
        at org.apache.hedwig.zookeeper.SafeAsyncZKCallback$ChildrenCallback.processResult(SafeAsyncZKCallback.java:66)
        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:567)
        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:481)",2011-08-11 05:20:40,2011-08-23 22:35:08
BOOKKEEPER-44,Reuse publish channel to default server to avoid too many connect requests to default server when lots of producers came in same time,Improvement,4,Closed,6,Fixed,2011-08-30 08:13:18,2011-08-11 05:28:04,2011-12-07T15:56:08.000+0000,ikelly,Ivan Kelly,ikelly,"Currently when client wants to publish messages to a specific topic (client doesn't know which hub owns this topic), it needs to ask default server which hub owns it. Client needs to connect to default server each time, even the channel to default server has been established. So too many unused connections will be opened and closed, when it publishes to different topics concurrently.

Reuses existed channel to default server to avoid the above issue.",2011-08-11 05:28:04,2011-08-30 08:13:18
BOOKKEEPER-46,Wait in BookieClietTest does not wait enough in some runs,Bug,1,Resolved,5,Won't Do,2017-10-09 09:55:55,2011-08-15 21:07:56,2017-10-09T09:55:55.000+0000,,,,"In testWriteGaps, the following excerpt of code can generate an NPE:

{noformat}
        synchronized (arc) {
            bc.readEntry(addr, 1, 1, recb, arc);
            arc.wait(1000);
            assertEquals(0, arc.rc);
            assertEquals(1, arc.entry.getInt());
        }
{noformat}",2011-08-15 21:07:56,2017-10-09 09:55:55
BOOKKEEPER-48,hedwig - publish messages to new topics slows down when the number of topics increase,Improvement,4,Resolved,5,Won't Do,2017-10-09 09:55:42,2011-08-16 11:14:52,2017-10-09T09:55:42.000+0000,,,,"Now each ledger in bookkeeper has separate index file. Publishing messages to new topics needs to create the index file and write a header. So number of files need to be created and written increase when number of ledgers(topics) increase, which slows down disk i/o. 

index file creation and written will slow down getFileInfo operation. Even worse, it lock the whole fileInfoCache, which might affect other bookkeeper operations.

Need a solution not to lock the whole fileInfoCache while creating/written index files.

Some testing results listed as below (3 bookie servers, 2 quorum.)

* Create {num_ledgers} ledgers, each ledgers publish 2 messages. (make sure index file of a specified ledger are all created in 3 bookie servers)
| *num ledgers* | 5,000 | 50,000 | 500,000 |
| *bookie* | 459.178 | 419.26 | 86.03 |

* After publishing 2 messages, publish messages in round-robin way ledger by ledger, until publishing 10,000,000 messages.
| *num ledgers* | 5,000 | 50,000 | 500,000 |
| *bookie* | 31,048.572 | 30,463.1 | 17,962.899 |",2011-08-16 11:14:52,2017-10-09 09:55:42
BOOKKEEPER-50,NullPointException at LedgerDescriptor#cmpMasterKey,Bug,1,Closed,6,Fixed,2011-11-04 10:47:18,2011-08-18 10:41:02,2013-05-02T02:29:45.000+0000,ikelly,Ivan Kelly,ikelly,"the LedgerDescriptor will be created when it is missed in LedgerCache. NullPointException will be thrown out in the following case:

1. The ledger descriptor is created and cached to LedgerCache because of a readEntry operation in bookie. The ledger descriptor was created without setting master key (we don't know master key in a read request)
2. An addEntry is sent after 1 . since the ledger descriptor has been cached, so addEntry will use it to compare master key. then NullPointException is thrown out.",2011-08-18 10:41:02,2011-11-04 10:47:18
BOOKKEEPER-51,NullPointException at FIFODeliveryManager#deliveryPtrs,Bug,1,Closed,6,Fixed,2011-08-30 09:14:52,2011-08-18 10:52:23,2011-12-07T15:56:08.000+0000,ikelly,Ivan Kelly,ikelly,"when unsubscribe immediately after subscribe, and before startDelivery, the deliveryPtrs is null, so the following MapMethods.removeFromMultiMap will cause a use of NullPointException",2011-08-18 10:52:23,2011-08-30 09:14:52
BOOKKEEPER-52,Message sequence confuse due to the subscribeMsgQueue@SubscribeResponseHandler,Bug,1,Closed,6,Fixed,2011-08-30 10:14:39,2011-08-18 11:07:11,2011-12-07T15:56:13.000+0000,ikelly,Ivan Kelly,ikelly,"In setMessageHandler function, when subscribeMsgQueue is not empty, the main thread will consume the message in subscribeMsgQueue, at the same time, the messageHandler have been set, so the worker thread will consume new coming message in handleSubscribeMessage. So the message Sequence will be confused",2011-08-18 11:07:11,2011-08-30 10:14:39
BOOKKEEPER-53,race condition of  outstandingMsgSet@SubscribeResponseHandler ,Bug,1,Closed,6,Fixed,2011-11-28 23:18:42,2011-08-25 05:48:13,2011-12-07T15:56:11.000+0000,ikelly,Ivan Kelly,ikelly,"outstandingMsgSet is a Set, so it is not thread-safe. The detail is as below:

MessageConsumeRetryTask is In a timer, so in timer thread, when the timer is up, it will cause a outstandingMsgSet add operation:
MessageConsumeRetryTask.run() -> outstandingMsgSet.add(message) -> outstandingMsgSet.add(message)

At the same time, in other thread(maybe main thread), there may be other operations of this outstandingMsgSet:
MessageConsumeCallback.operationFinished() -> messageConsumed(Message message) -> outstandingMsgSet.remove(message);",2011-08-25 05:48:13,2011-11-28 23:18:42
BOOKKEEPER-55,SubscribeReconnectRetryTask might retry subscription endlessly when another subscription is already successfully created previously,Bug,1,Closed,6,Fixed,2013-01-02 21:24:49,2011-08-25 10:52:23,2013-02-13T15:46:29.000+0000,hustlmsp,Sijie Guo,hustlmsp,"For channelDisconnected envent, we try to automatically recover the connection and subscription. But when users call HedwigSubscriber.subscribe() at the same time, it might succeed before the auto recovery. Then the auto recovery can never succeed as the server will report topic busy failure. Then the SubscribeReconnectRetryTask will retry again and again endlessly. We found this in our auto test.

Fix is easy, we just need to firstly check if the channel for this topic and subscribe id is null, if not it means some subscription is already created before, we don't need to bother recover.",2011-08-25 10:52:23,2013-01-02 21:24:49
BOOKKEEPER-56,Race condition of message handler in connection recovery in Hedwig client,Bug,1,Closed,6,Fixed,2012-04-28 08:12:00,2011-08-26 08:09:50,2012-10-22T14:50:19.000+0000,hustlmsp,Sijie Guo,hustlmsp,"There's a race condition in the connection recovery logic in Hedwig client. The message handler user set might be overwritten incorrectly. 

When handling channelDisconnected event, we try to reconnect to Hedwig server. After the connection is created and subscribed, we'll call StartDelivery() to recover the message handler to the original one of the disconnected connection. But if during this process, user calls StartDelivery() to set a new message handler, it will get overwritten to the original one.

The process can be demonstrated as below:

|| main thread || netty worker thread ||
| StartDelivery(messageHandlerA) | |
| (connection Broken here, and recovered later...) |
|                                             | ResponseHandler::channelDisconnected()   (connection disconnected event received) |
|                                             | new SubscribeReconnectCallback(subHandler.getMessageHandler()) (store messageHandlerA in SubscribeReconnectCallback to recover later) |
|                                             | client.doConnect() (try reconnect)  |
|                                             | doSubUnsub() (resubscribe) |
|                                             | SubscriberResponseHandler::handleSubscribeResponse()  (subscription succeeds) |
| StartDelivery(messageHandlderB)             |                                                                               |
|                                             | SubscribeReconnectCallback::operationFinished()                               |
|                                             | StartDelvery(messageHandlerA)   (messageHandler get overwritten)              |   

I can stably reproduce this by simulating this race condition by put some sleep in ResponseHandler.

I think essentially speaking we should not store messageHandler in ResponseHandler, since the message handler is supposed to be bound to connection. Instead, no matter which connection is in use, we should use the same messageHandler, the one user set last time. So I think we should change to store messageHandler in the HedwigSubscriber, in this way we don't need to recover the handler in connection recovery and thus won't face this race condition.

",2011-08-26 08:09:50,2012-04-28 08:12:00
BOOKKEEPER-57,NullPointException at bookie.zk@EntryLogger,Bug,1,Closed,6,Fixed,2011-08-31 10:18:53,2011-08-29 08:37:26,2011-12-07T15:56:10.000+0000,ikelly,Ivan Kelly,ikelly,"In Bookie.java, if the recovery time is longer than gcWaitTime, bookie.zk is null and gc thread will exit",2011-08-29 08:37:26,2011-08-31 10:18:53
BOOKKEEPER-58,Changes introduced in BK-38 cause BookieClientTest to hang indefinitely.,Bug,1,Closed,6,Fixed,2011-08-29 17:33:24,2011-08-29 13:25:14,2011-12-07T15:56:15.000+0000,ikelly,Ivan Kelly,ikelly,"As subject says, BK-38 introduces a bug that stops BookieClientTest from running. To run: mvn test -Dtest=BookieClientTest",2011-08-29 13:25:14,2011-08-29 17:33:24
BOOKKEEPER-59,Race condition in netty code allocates and orphans resources (BK-5 revisited),Bug,1,Closed,6,Fixed,2011-09-16 14:56:48,2011-08-30 07:46:22,2011-12-07T15:56:05.000+0000,ikelly,Ivan Kelly,ikelly,"We thought BK-5 fixed this, but it still hits if you run for long enough.

To repro,

true; while [ $? = 0 ]; do mvn test -Dtest=BookieReadWriteTest; done

Leave this running for 5-6 hours, and the bug should hit. From looking at the code it could be that connect is unsynchronized, so resources could be allocated and lost by concurrent executions of connect(). ",2011-08-30 07:46:22,2011-09-16 14:56:48
BOOKKEEPER-61,BufferedChannel read endless when the remaining bytes of file is less than the capacity of read buffer,Bug,1,Closed,6,Fixed,2011-10-07 22:24:49,2011-08-30 10:28:49,2013-05-02T02:29:43.000+0000,ikelly,Ivan Kelly,ikelly,"If last record in entry log file is truncated (length of data is short than expected length), bookie went into infinite loop on reading this record.

A truncated record can be caused in following cases:
1) bookie server is killed during bookie restart to relay logs.
2) bookie server is killed when bookie does adding entry operation.",2011-08-30 10:28:49,2011-10-07 22:24:49
BOOKKEEPER-62,Bookie can not start when encountering corrupted records,Bug,1,Closed,6,Fixed,2011-11-30 10:14:42,2011-08-30 10:36:47,2014-12-18T06:17:36.000+0000,ikelly,Ivan Kelly,ikelly,"bookie tries to extract ledger ids from entry loggers during starting up. if some records corrupted, an IOException is thrown out.

in extractLedgersFromEntryLogs function:

line 459:
                int rc = bc.read(buff, pos);
                if (rc != data.length) {
                    throw new IOException(""Short read for entryLog "" + entryLogId + ""@"" + pos + ""("" + rc + ""!=""
                            + data.length + "")"");
                }",2011-08-30 10:36:47,2011-11-30 10:14:42
BOOKKEEPER-63,Hedwig PubSubServer must wait for its Zookeeper client to be connected upon startup,Bug,1,Closed,6,Fixed,2011-09-05 10:33:43,2011-08-31 11:29:45,2011-12-07T15:56:09.000+0000,ikelly,Ivan Kelly,ikelly,"When a PubSubServer is instantiated in *non-standalone* mode, it creates a ZkTopicManager which takes a Zookeeper client as an argument.
Unfortunately, this Zookeeper client may not be connected yet (not in CONNECTED state yet), and when this is the case, creation of ZkTopicManager fails, leading to failure of the PubSubServer startup.

Typical error (adapted, line numbers take into account commented patching code):
jjava.io.IOException: org.apache.hedwig.exceptions.PubSubException$ServiceDownException: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hedwig/standalone/hosts/x.x.x.x:4080:9876
	at org.apache.hedwig.server.netty.PubSubServer.instantiateTopicManager(PubSubServer.java:170)
	at org.apache.hedwig.server.netty.PubSubServer$3.run(PubSubServer.java:294)
	at java.lang.Thread.run(Thread.java:680)
Caused by: org.apache.hedwig.exceptions.PubSubException$ServiceDownException: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /hedwig/standalone/hosts/x.x.x.x:4080:9876
	at org.apache.hedwig.server.topics.ZkTopicManager$4.safeProcessResult(ZkTopicManager.java:146)
etc...

This is particularly problematic for running tests that require to pass a config to the PubSubServer.",2011-08-31 11:29:45,2011-09-05 10:33:43
BOOKKEEPER-64,LedgerHandle#asyncAddEntry expects byte[] to remain available until completion,Bug,1,Resolved,5,Won't Do,2017-10-09 09:55:29,2011-09-06 14:00:03,2017-10-09T09:55:29.000+0000,,,,"When a call is made to asyncAddEntry, the byte[] passed must not change until the async confirmation comes back. Otherwise the result is undefined. While for some API this is acceptable, I BK is aimed at applications where buffering may be used. This may force an extra copy before sending the data to BK to ensure the data sticks around. This is pointless as one of the first things addEntry does is make a copy while staging the data to send.",2011-09-06 14:00:03,2017-10-09 09:55:29
BOOKKEEPER-65,fix dependencies on incompatible versions of netty,Bug,1,Closed,6,Fixed,2011-10-17 21:40:13,2011-09-07 10:29:47,2011-12-07T15:56:07.000+0000,ikelly,Ivan Kelly,ikelly,"bookkeeper-benchmark and hedwig-client depend on netty 3.1.2.GA
bookkeeper-server depends on netty 3.2.4.Final

These versions are actually incompatible, due to a change to ProtobufDecoder constructor's signature",2011-09-07 10:29:47,2011-10-17 21:40:13
BOOKKEEPER-66,use IPv4 for builds,Bug,1,Closed,6,Fixed,2011-11-30 15:42:35,2011-09-13 14:10:42,2011-12-07T15:56:09.000+0000,ikelly,Ivan Kelly,ikelly,"On some linux boxes that run a dual IPv6-IPv4 network stack, with IPv6 enabled (e.g. debian-based), there is an issue with some java programs, preventing network connections.

This results in ""org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /ledgers"" in BookieZKExpireTest test (for instance) but is actually due to a previous ""java.net.NoRouteToHostException: Network is
unreachable"" issue.

I could reproduce this on a debian 6 for instance, and the issue is similar another one detailed in a Hadoop ticket: https://issues.apache.org/jira/browse/HADOOP-6056

We should make sure IPv4 is used for builds so that one can build bookkeeper out of the box, without configuration changes to the OS.",2011-09-13 14:10:42,2011-11-30 15:42:35
BOOKKEEPER-68,Conditional setData,Bug,1,Closed,6,Fixed,2011-10-18 08:43:31,2011-09-19 21:07:43,2011-12-07T15:56:12.000+0000,ikelly,Ivan Kelly,ikelly,"The write to ZooKeeper to store ledger metadata when closing a ledger must be conditional, otherwise concurrent clients might end up writing in a way that the update of a client overwrites the update of the other. ",2011-09-19 21:07:43,2011-10-18 08:43:31
BOOKKEEPER-69,"ServerRedirectLoopException when a machine (hosts bookie server & hub server) reboot, which is caused by race condition of topic manager",Bug,1,Closed,6,Fixed,2011-11-18 10:39:01,2011-09-28 06:01:27,2011-12-07T15:56:06.000+0000,ikelly,Ivan Kelly,ikelly,"1) machine perf10 is rebooted. the bookie server & hub server are not restarted automatically after reboot.
2) client 1 & client 2 are still running. the topics owned in perf10 will be re-assigned to perf8/perf9. but they would fail because not enough bookie servers are available.
3) after 2 hours, we found that perf10 is rebooted. we restarted bookie server & hub server on perf10
4) then we got ServerRedirectLoopException in client.",2011-09-28 06:01:27,2011-11-18 10:39:01
BOOKKEEPER-70,reduce or multiplex subscription connections to a hub server,Improvement,4,Resolved,5,Implemented,2012-12-07 11:24:17,2011-09-29 09:58:14,2013-01-14T15:08:03.000+0000,hustlmsp,Sijie Guo,hustlmsp,"now each subscription will establish a connection to hub server, there will be too many connections on both client/server sides.",2011-09-29 09:58:14,2012-12-07 11:24:17
BOOKKEEPER-71,hedwig c++ client does not build. ,Bug,1,Closed,6,Fixed,2011-10-28 13:35:07,2011-09-29 16:26:08,2011-12-07T15:56:14.000+0000,ikelly,Ivan Kelly,ikelly,The path to the protobuf spec is wrong in lib/Makefile.am. ,2011-09-29 16:26:08,2011-10-28 13:35:07
BOOKKEEPER-72,Fix warnings issued by FindBugs,Bug,1,Closed,6,Fixed,2012-05-17 16:33:04,2011-10-07 10:20:37,2012-10-22T14:50:15.000+0000,ikelly,Ivan Kelly,ikelly,Fix warnings issued by FindBugs,2011-10-07 10:20:37,2012-05-17 16:33:04
BOOKKEEPER-74,Bookkeeper Persistence Manager should give up topic on error,Bug,1,Closed,6,Fixed,2012-03-01 14:13:36,2011-10-07 10:31:34,2012-10-22T14:50:14.000+0000,hustlmsp,Sijie Guo,hustlmsp,"There are a couple of problematic cases to deal with:
i)Other region is pushing messages faster that my bookkeeper can handle it (unlikely, but we should have an answer for
this setting)
ii) If there is an error from BK while persisting messages, we cannot continue (because the ordering gurantee might be
violated). In this case, the BK layer should give up the topic.

To retain ordering guarantees, this should be done below the Region manager in the persistence manager layer

",2011-10-07 10:31:34,2012-03-01 14:13:36
BOOKKEEPER-77,Add a console client for hedwig,New Feature,2,Closed,6,Fixed,2012-02-08 10:50:22,2011-10-08 11:59:33,2013-05-02T02:29:45.000+0000,ikelly,Ivan Kelly,ikelly,"implement a console client to use/admin hedwig system.

Usage : hedwig_console [options] COMMAND [argument ...]

(if no COMMAND specified, hedwig_console will enter interactive mode.)

OPTIONS:

{quote}
   --zkquorums            the quorum list of zookeeper cluster
   --zktimeout            timeout of zookeeper client
   --zk_hedwig_prefix     the prefix of zookeeper path to store hedwig metadata
   --region               which region of hedwig to connect
   --consume_interval     the consume interval of hub server
{quote}

COMMANDS:

* pub <topic> <message>
** Publish <message> to the specified <topic>. 

* sub <topic> <subscriber_id> [mode]
** Subscribe the specified <topic> as subscriber <subscriber_id>. (NOTE: only run in INTERACTIVE mode now) 
** mode: subscription mode. available values are 0, 1, 2.
*** 0 = CREATE : create the subscription if not subscription before.
*** 1 = ATTACH (default) : attach the subscription
*** 2 = CREATE_OR_ATTACH : if the subscription is not existed, create the subscription then attach. 

* closesub <topic> <subscriber_id>
** Close subscription of subscriber <subscriber_id>. (NOTE: it just close the subscription connection and do cleanup work in client-side, without REMOVING subscription state from server side) 

* unsub <topic> <subscriber_id>
** Remove subscription state of subscriber <subscriber_id>. the subscription state of subscriber <subscriber_id> will be removed from server side. 

* consume <topic> <subscriber_id> <num_messages_to_consume>
** Move the subscription ptr of subscriber <subscriber_id> from ptr to ptr + num_messages_to_consume. 
* consumeto <topic> <subscriber_id> <message_id>
** Move the subscription ptr of subscriber <subscriber_id> from ptr to <message_id>. 
** NOTE: consume*/*consumeto just sent consume request to hub server and hub server move the subscription ptr in its memory. Hub server lazily persists the subscription ptr to zookeeper. the default persist interval in hub server is 50 messages. so use DESCRIBE TOPIC to show subscription, the subscription ptr might be not changed. 

* pubsub <topic> <subscriber_id_prefix> <timeout_secs> <message_prefix>
** A test command to test healthy of hedwig cluster. 

*# sub <topic> as subscriber <subscriber_id_prefix>_<cur_time> .
*# subscriber <subscriber_id_prefix>_<cur_time> will wait a message until <timeout_secs> secs.
*# publish a message <message_prefix>_<cur_time> to topic <topic> .
*# when subscriber <subscriber_id_prefix> receive the message, it will check the message is the published message
*# received message or timeout, subscriber <subscriber_id_prefix> will unsubscribe the <topic>
*# quit

{quote}
      [hedwig: (standalone) 7] pubsub ttttttttt test 10 test_message
      Starting PUBSUB test ...
      Sub topic ttttttttt, subscriber id test-1319602021044
      Pub topic ttttttttt : test_message-1319602021044
      Received message : test_message-1319602021044
      PUBSUB SUCCESS. TIME: 43 MS
      SUCCESS. Finished 0.058 s
{quote}  

* show hubs
** list all available hub servers. including hostname and how many topics the server owns. 

{quote}
      Example:

      Available Hub Servers:
              98.137.99.27:9875:9876 :        2
{quote}
         

* show topics
** list all existing topics. (NOTE: since we fetch topic lists from zookeeper, we may got PacketLenException when we have millions of topics. it doesn't affect system, just can't display the topic list) 

* describe topic <topic>
** show state of a specified topic, including topic owner, topic persistent information, topic subscriber list and their subscription states. 

{quote}
      Example:

      ===== Topic Information : ttttt =====

      Owner : 98.137.99.27:9875:9876

      >>> Persistence Info <<<
      Ledger 54729 [ 1 ~ 59 ]
      Ledger 54731 [ 60 ~ 60 ]

      >>> Subscription Info <<<
      Subscriber mysub : consumeSeqId: local:50
{quote}
         

* readtopic <topic> [start_msg_id]
** read messages of a specified <topic>. 

*** no <start_msg_id> specified : readtopic will start from <least_consumed_message_id> + 1 of its subscribers. in above exmaple, ""readtopic ttttt"" will start from 50. if there is no subscription, it will start from 1.
*** <start_msg_id> specified : since messages consumed will be removed by garbage collection. so readtopic tries to not read consumed message, it will start from MAX( <start_msg_id> , <least_consumed_message_id> ). 

*** Message Format
**** MsgId : include two parts: first part is which region the message is published from, second part is message id.
**** SrcRegion : region name
**** Message : the message body
{quote}
            ---------- MSGID=LOCAL(51) ----------
            MsgId:     LOCAL(51)
            SrcRegion: standalone
            Message:

            hello
{quote}         

* history
** list history commands 

* redo [<cmdno>|!]
** redo the specified command by command no. (NOTE: ""*redo *"" means redo the previous command) 

* help
** print help information 

* quit|exit
** exit the interactive console ",2011-10-08 11:59:33,2012-02-08 10:50:22
BOOKKEEPER-78,filterable metadata fields in Hedwig's message definition,New Feature,2,Closed,6,Fixed,2012-09-04 13:10:19,2011-10-13 14:43:19,2013-01-14T15:08:46.000+0000,,,,"In order to efficiently implement filtering of Hedwig messages, Hedwig should be able to rely on metadata information. (i.e. without needing to deserialize the content of the message)

Filtering could use a subset of SQL (like in the JMS spec), leading to queries such as : 
""header1 like 'a' AND header2 IS NOT NULL"" 


For that purpose, I propose to add customizable metadata to the definition of Hedwig messages, as header fields.

Metadata must be customizable because it may be arbitrary. We should provide ""map-like"" containers according to the type of the metadata field. Metadata fields would be accessed by name.

There are predefined headers for JMS that could be added as metadata fields such as : destination (~topic), delivery mode (persistent or not), expiration, priority, timestamp, correlation id (link to other message), reply to, type and redelivered. I think only a subset of these should be predefined headers, if any.

Adding metadata fields to Hedwig messages implies modifying the message definition, which does not break backward compatibility when those fields are added as optional in the protocol buffer definition.

 


",2011-10-13 14:43:19,2012-09-04 13:10:19
BOOKKEEPER-79,randomly startDelivery/stopDelivery will core dump in c++ hedwig client,Bug,1,Closed,6,Fixed,2011-11-21 10:33:20,2011-10-14 07:37:18,2011-12-07T15:56:07.000+0000,ikelly,Ivan Kelly,ikelly,"in our test program, we tried to startDelivery/stopDelivery different subscriptions randomly. And it core dump.",2011-10-14 07:37:18,2011-11-21 10:33:20
BOOKKEEPER-80,subscription msg queue race condition in hedwig c++ client,Bug,1,Closed,6,Fixed,2011-11-08 18:10:18,2011-10-14 07:50:11,2011-12-07T15:56:06.000+0000,ikelly,Ivan Kelly,ikelly,,2011-10-14 07:50:11,2011-11-08 18:10:18
BOOKKEEPER-81,disk space of garbage collected entry logger files isn't reclaimed util process quit ,Bug,1,Closed,6,Fixed,2011-11-17 09:00:04,2011-10-14 08:37:16,2011-12-07T15:56:12.000+0000,ikelly,Ivan Kelly,ikelly,"disk space of garbage collected entry logger files isn't reclaimed until process quit. 
it is caused by entry logger doesn't close the file channel of garbage collected files. so the process kept an reference to this file, filesystem only reclaim its space when the process quit.",2011-10-14 08:37:16,2011-11-17 09:00:04
BOOKKEEPER-82,support journal rolling,Improvement,4,Closed,6,Fixed,2011-11-11 10:25:06,2011-10-14 09:27:18,2013-05-02T02:29:45.000+0000,ikelly,Ivan Kelly,ikelly,"now bookkeeper is writing a single journal file, so the journal file has no chance to be garbage collected and the disk space keeps growing.",2011-10-14 09:27:18,2011-11-11 10:25:06
BOOKKEEPER-83,Added versioning and flags to the bookie protocol,Improvement,4,Closed,6,Fixed,2011-10-27 13:41:11,2011-10-17 09:08:32,2011-12-07T15:56:05.000+0000,ikelly,Ivan Kelly,ikelly,"There is no concept of versions in the BookKeeper protocol at the moment. This patch addresses that. 
",2011-10-17 09:08:32,2011-10-27 13:41:11
BOOKKEEPER-84,Add versioning for ZK metadata,Improvement,4,Closed,6,Fixed,2011-10-23 06:10:20,2011-10-17 16:00:55,2011-12-07T15:56:08.000+0000,ikelly,Ivan Kelly,ikelly,"There's no zk metadata versioning, which means that reading clients may misinterpret the data saved in ZK. ",2011-10-17 16:00:55,2011-10-23 06:10:20
BOOKKEEPER-85,TestZkTopicManager fails intermittently,Bug,1,Resolved,5,Won't Do,2017-10-09 09:54:43,2011-10-17 21:41:31,2017-10-09T09:54:43.000+0000,ikelly,Ivan Kelly,ikelly,"To repro, 
$ cd hedwig-server;
$ true && while [ $? = 0 ]; do mvn test -Dtest=TestZkTopicManager;  done
",2011-10-17 21:41:31,2017-10-09 09:54:43
BOOKKEEPER-86,bookkeeper-benchmark fails to compile after BOOKKEEPER-68,Bug,1,Closed,6,Fixed,2011-10-18 18:14:59,2011-10-18 17:04:53,2011-12-07T15:56:10.000+0000,ikelly,Ivan Kelly,ikelly,This is the LedgerHandle#close compatibility issue. I must have forgotten to clean before testing the patch last night.,2011-10-18 17:04:53,2011-10-18 18:14:59
BOOKKEEPER-87,TestHedwigHub exhausts direct buffer memory with netty 3.2.4.Final,Bug,1,Closed,6,Fixed,2011-11-17 14:01:22,2011-10-19 08:55:34,2011-12-07T15:56:06.000+0000,ikelly,Ivan Kelly,ikelly,"The error below happens. This happens because the test starts and stops a lot of bookies, and hedwig hub for each test. Each of these allocates some Direct Buffer memory, which doesn't automatically get returned the the pool once the test is finished. The DirectByteBuffers do seem to be garbage collected, but they don't actually clean up the direct buffer memory until an internal cleaner runs later. I can't find a way to run this manually.

This happens since BOOKKEEPER-65, as the new netty allocates more direct buffers. A work around for the problem for the moment is to run test with 1G heap.
$ mvn test -DargLine=""-Xmx1G""


<snip>
Running org.apache.hedwig.server.integration.TestHedwigHub
Tests run: 92, Failures: 0, Errors: 47, Skipped: 0, Time elapsed: 60.523 sec <<< FAILURE!

Results :

Tests in error: 
  testAsyncHubUnsubscribeWithInvalidSubscriberId[1](org.apache.hedwig.server.integration.TestHedwigHub): Direct buffer memory
  testManualConsumeClient[2](org.apache.hedwig.server.integration.TestHedwigHub): Direct buffer memory
  testManualConsumeClient[2](org.apache.hedwig.server.integration.TestHedwigHub)
  testAttachToSubscriptionSuccess[2](org.apache.hedwig.server.integration.TestHedwigHub): Direct buffer memory
  testAttachToSubscriptionSuccess[2](org.apache.hedwig.server.integration.TestHedwigHub)
  testServerRedirect[2](org.apache.hedwig.server.integration.TestHedwigHub): Direct buffer memory
  testServerRedirect[2](org.apache.hedwig.server.integration.TestHedwigHub)
  testSubscribeAndConsume[2](org.apache.hedwig.server.integration.TestHedwigHub): Direct buffer memory
  testSubscribeAndConsume[2](org.apache.hedwig.server.integration.TestHedwigHub)
  testServerFailoverPublishOnly[2](org.apache.hedwig.server.integration.TestHedwigHub): Direct buffer memory
  testServerFailoverPublishOnly[2](org.apache.hedwig.server.integration.TestHedwigHub)
",2011-10-19 08:55:34,2011-11-17 14:01:22
BOOKKEEPER-88,derby doesn't like - in the topic names,Bug,1,Closed,6,Fixed,2011-10-24 09:38:52,2011-10-19 18:34:22,2011-12-07T15:56:12.000+0000,ikelly,Ivan Kelly,ikelly,"it's just a benchmark, but it is convenient to be able to use derby as a backend for the hedwig benchmark. derby does not support - in topic names.",2011-10-19 18:34:22,2011-10-24 09:38:52
BOOKKEEPER-89,Bookkeeper API changes for initial Bookkeeper release,Improvement,4,Closed,6,Fixed,2011-10-27 16:28:03,2011-10-24 09:56:00,2011-12-07T15:56:07.000+0000,ikelly,Ivan Kelly,ikelly,"Changes are as follows.

BookKeeper#createLedger, parameter is named passwd, ""Key"" used in LedgerHandle api
BookKeeper#getBookieClient shouldn't be public
BookKeeper#createComplete shouldn't be public
BookKeeper#openComplete shouldn't be public
BookKeeper#deleteComplete shouldn't be public
BookKeeper#halt could be changed to close(), should throw a BKException

LedgerHandle#getLedgerKey passwd is used in BookKeeper, should possibly be private
LedgerHandle#getLedgerMetadata shouldn't be public
LedgerHandle#getDigestManager shouldn't be public
LedgerHandle#getDistributionSchedule shouldn't be public
LedgerHandle#writeLedgerConfig shouldn't be public
LedgerHandle#addEntry should return void, errors should go in an Exception
LedgerHandle#readComplete should not be public
LedgerHandle#addComplete should not be public
LedgerHandle#readLastConfirmedCompelte should not be public
LedgerHandle#closeComplete should not be public

ASyncCallback#RecoverCallback shouldn't be public
",2011-10-24 09:56:00,2011-10-27 16:28:03
BOOKKEEPER-90,Hedwig API changes for initial Bookkeeper release,Improvement,4,Closed,6,Fixed,2011-11-17 21:40:22,2011-10-24 13:09:11,2011-12-07T15:56:04.000+0000,ikelly,Ivan Kelly,ikelly,"HedwigClient#getSslFactory shouldn't be public
HedwigClient#getConsumeCallback shouldn't be public
HedwigClient#doConnect shouldn't be public
HedwigClient#getHostFromChannel shouldn't be public
HedwigClient#getResponseHandlerFromChannel shouldn't be public
HedwigClient#getHostForTopic shouldn't be public
HedwigClient#clearAllTopicsForHost shouldn't be public
HedwigClient#getClientTimer shoulnd't be public
HedwigClient#stop should throw some sort of Exception in the case of errors

HedwigPublisher#publish shouldn't use protobuf ByteString, as it requires the user to import protobufs
HedwigPublisher#getChannelForHost shouldn't be public

HedwigSubscriber#HedwigSubscriber shouldn't be public
HedwigSubscriber#doConsume shouldn't be public
HedwigSubscriber#hasSubscription probably shouldn't be public
HedwigSubscriber#getSubscriptionList shoulnd't exist
HedwigSubscriber#getChannelForTopic shouldn't be public
HedwigSubscriber#setChannelforTopic shouldn't be public
HedwigSubscriber#removeChannelForTopic shound't be public

MessageHandler#consume should be called 'deliver'

The hedwig client is under a netty package. There's nothing netty specific about the api, so it should be in the org.apache.hedwig.client package. 
",2011-10-24 13:09:11,2011-11-17 21:40:22
BOOKKEEPER-91,Bookkeeper and hedwig clients should not use log4j directly,Improvement,4,Closed,6,Fixed,2011-11-17 10:20:27,2011-10-24 16:14:33,2011-12-07T15:56:12.000+0000,ikelly,Ivan Kelly,ikelly,"Using log4j directly requires that any application using bookkeeper or hedwig clients have to configure log4j. 

We should use something like commons logging[1] or slf4j[2].

[1] http://commons.apache.org/logging/index.html
[2] http://www.slf4j.org/",2011-10-24 16:14:33,2011-11-17 10:20:27
BOOKKEEPER-92,using wrong context object in readLastConfirmedComplete callback,Bug,1,Closed,6,Fixed,2011-10-25 15:15:09,2011-10-25 12:50:40,2011-12-07T15:56:05.000+0000,ikelly,Ivan Kelly,ikelly,should context in ReadLastConfirmedOp not the context passed from bookieClient.readEntry.,2011-10-25 12:50:40,2011-10-25 15:15:09
BOOKKEEPER-93,bookkeeper doesn't work correctly on OpenLedgerNoRecovery,Bug,1,Closed,6,Fixed,2011-10-27 16:53:24,2011-10-25 14:44:46,2013-05-02T02:29:45.000+0000,ikelly,Ivan Kelly,ikelly,"1) bookkeeper hang when openLedgerNoRecovery, since LedgerOpenOp didn't trigger callback when opening ledger no recovery.

2) race condition in ReadLastConfirmOp

ReadLastConfirmOp callback on readEntryComplete.
a) first decrement numResponsePending
b) then increment validResponses
c) check validResponses to callback with OK
b) check numResponsePending to callback with LedgerRecoveryException

support two callbacks returns on readEntryComplete: A, B. (quorum/ensemble size : 2)

a) A first decrement numResponsePending from 2 to 1.
b) A increment validResponses from 0 to 1.
c) B then decrement numResponsePending from 1 to 0.
d) A check numResponsePending before B check validResponse, A found the numResponsePending is 0 now. A will callback with exception. But the right action is B check validResponse and callback with OK.

3) if an LegerHandle is opened by openLedgerNoRecovery, the lastAddConfirmed will be set to -1. so all read requests will be failed since readEntry id > lastAddConfirmed.

so I suggested that if an LegerHandle is opened by openLegerNoRecovery, the ledgerHandle is under unsafeRead mode. close/write operations will be failed, read operations should not check condition entry_id > lastAddConfirmed.",2011-10-25 14:44:46,2011-10-27 16:53:24
BOOKKEEPER-94,Double callbacks in readLastConfirmedOp which fails readLastConfirmed operation even received enough valid responses.,Bug,1,Closed,6,Fixed,2011-10-26 14:07:09,2011-10-26 01:22:48,2011-12-07T15:56:16.000+0000,ikelly,Ivan Kelly,ikelly,"As comment in [BOOKKEEPER-93 | https://issues.apache.org/jira/browse/BOOKKEEPER-93], double callbacks happen even it success callback receiving enough valid responses.",2011-10-26 01:22:48,2011-10-26 14:07:09
BOOKKEEPER-95,extends zookeeper JMX to monitor and manage bookie server,Sub-task,7,Closed,6,Fixed,2012-01-18 12:10:02,2011-10-26 07:24:23,2013-05-02T02:29:45.000+0000,hustlmsp,Sijie Guo,hustlmsp,we can extends/reuses zookeeper JMX until to monitor and manage bookie server,2011-10-26 07:24:23,2012-01-18 12:10:02
BOOKKEEPER-96,extends zookeeper JMX to monitor and manage hedwig server,Sub-task,7,Closed,6,Fixed,2012-03-19 12:05:15,2011-10-26 07:25:45,2013-05-02T02:29:45.000+0000,ikelly,Ivan Kelly,ikelly,we can extends / reuses zookeeper JMX utils to monitor and manage hedwig server,2011-10-26 07:25:45,2012-03-19 12:05:15
BOOKKEEPER-97,collect pub/sub/consume statistics on hub server,Sub-task,7,Closed,6,Fixed,2012-03-29 13:03:01,2011-10-26 07:27:32,2013-05-02T02:29:45.000+0000,hustlmsp,Sijie Guo,hustlmsp,collecting pub/sub/consume statistics on hub server,2011-10-26 07:27:32,2012-03-29 13:03:01
BOOKKEEPER-98,collect add/read statistics on bookie server,Sub-task,7,Closed,6,Fixed,2012-02-01 12:02:31,2011-10-26 07:29:32,2013-05-02T02:29:45.000+0000,hustlmsp,Sijie Guo,hustlmsp,collect add/read statistics on bookie server,2011-10-26 07:29:32,2012-02-01 12:02:31
BOOKKEEPER-100,Some hedwig tests have build errors,Bug,1,Closed,6,Fixed,2011-10-27 17:12:52,2011-10-27 14:05:41,2011-12-07T15:56:13.000+0000,ikelly,Ivan Kelly,ikelly,Some hedwig tests have minor build errors.,2011-10-27 14:05:41,2011-10-27 17:12:52
BOOKKEEPER-101,Add Fencing to Bookkeeper,New Feature,2,Closed,6,Fixed,2011-11-16 16:06:31,2011-10-27 14:08:05,2011-12-07T15:56:13.000+0000,ikelly,Ivan Kelly,ikelly,"BookKeeper is designed for use as a Write ahead log. In systems with a primary/backup architecture, the primary will write state updates to the WAL. If the primary dies the backup comes online, reads the WAL to get the latest state and starts serving requests. However, if the primary was only partitioned from the network, or stuck in a long GC, a split brain occurs. Both primary and backup can service client requests. 

Fencing(http://en.wikipedia.org/wiki/Fencing_%28computing%29) ensures that this cannot happen. With fencing, the backup can close the WAL of the primary, and cause any subsequent attempt by the primary to write to the WAL to give an error. 

We fence a ledger whenever it is opened by another client using BookKeeper#openLedger. BookKeeper#openLedgerNoRecovery will not fence.
The opening client marks the ledger as fenced in zookeeper, and then sends a readEntry message to a all of bookies with the DO_FENCING flag set. Once at least 1 bookie in each possible quorum of bookies have responded, we can proceed with opening the ledger. Any subsequent attempt to write to the ledger will fail as it will not be able to write to a quorum without one of the bookie in the quorum responding with a ledger fenced error. The client will also be unable to change the quorum without seeing that the ledger has been marked as fenced in zookeeper.
",2011-10-27 14:08:05,2011-11-16 16:06:31
BOOKKEEPER-102,Make bookkeeper use ZK from temporary repo,Improvement,4,Closed,6,Fixed,2011-11-04 10:25:58,2011-11-03 18:08:05,2011-12-07T15:56:14.000+0000,ikelly,Ivan Kelly,ikelly,"As the title says, make BK use zookeeper from a snapshot maven repo. This should be removed before pushing out the release, but for now it will allow us to use Jenkins to sanity check the builds.",2011-11-03 18:08:05,2011-11-04 10:25:58
BOOKKEEPER-104,Add versioning between bookie and its filesystem layout,Improvement,4,Closed,6,Fixed,2011-11-16 18:01:40,2011-11-04 10:43:11,2011-12-07T15:56:15.000+0000,ikelly,Ivan Kelly,ikelly,There is currently no concept of layout version between the filesystem layout and bookie server. This could lead to potential corruption if a newer version of the bookie server is used with an old filesystem layout. ,2011-11-04 10:43:11,2011-11-16 18:01:40
BOOKKEEPER-106,recoveryBookieData can select a recovery bookie which is already in the ledgers ensemble,Bug,1,Closed,6,Fixed,2011-11-15 18:45:41,2011-11-04 16:19:55,2011-12-07T15:56:11.000+0000,ikelly,Ivan Kelly,ikelly,"As the summary says, if you don't specify a destBookie when doing recoveryBookieData, it will select at random from the available bookie list. It doesn't take care to select a bookie which is not is the ledgers ensemble.",2011-11-04 16:19:55,2011-11-15 18:45:41
BOOKKEEPER-107,memory leak in HostAddress of hedwig c++ client,Bug,1,Closed,6,Fixed,2011-11-08 17:58:33,2011-11-04 17:10:59,2011-12-07T15:56:09.000+0000,ikelly,Ivan Kelly,ikelly,"should use freeaddrinfo to free struct addrinfo, instead of using free directly.",2011-11-04 17:10:59,2011-11-08 17:58:33
BOOKKEEPER-108,add configuration support for BK,Improvement,4,Closed,6,Fixed,2011-11-18 10:19:06,2011-11-08 03:11:49,2013-05-02T02:29:46.000+0000,ikelly,Ivan Kelly,ikelly,"As Ivan's comment on BOOKKEEPER-39, we use lots of system properties in BK now. It's better to use a proper configuration  object to manager them.
",2011-11-08 03:11:49,2011-11-18 10:19:06
BOOKKEEPER-109,Add documentation to describe how bookies flushes data,Sub-task,7,Closed,6,Fixed,2011-11-17 08:34:13,2011-11-11 10:00:11,2011-12-07T15:56:04.000+0000,ikelly,Ivan Kelly,ikelly,,2011-11-11 10:00:11,2011-11-17 08:34:13
BOOKKEEPER-111,Document bookie recovery feature,Sub-task,7,Closed,6,Fixed,2011-11-29 23:20:06,2011-11-15 18:09:55,2011-12-07T15:56:14.000+0000,ikelly,Ivan Kelly,ikelly,"The nesting of callbacks in the bookie recovery mechanism is difficult to follow, and we need to make sure that we have it documented so that others are able to read the code.",2011-11-15 18:09:55,2011-11-29 23:20:06
BOOKKEEPER-112,Bookie Recovery on an open ledger will cause LedgerHandle#close on that ledger to fail,Bug,1,Closed,6,Fixed,2012-03-31 14:36:57,2011-11-15 18:22:28,2013-08-07T05:15:04.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Bookie recovery updates the ledger metadata in zookeeper. LedgerHandle will not get notified of this update, so it will try to write out its own ledger metadata, only to fail with KeeperException.BadVersion. This effectively fences all write operations on the LedgerHandle (close and addEntry). close will fail for obvious reasons. addEntry will fail once it gets to the failed bookie in the schedule, tries to write, fails, selects a new bookie and tries to update ledger metadata.

Update Line 605, testSyncBookieRecoveryToRandomBookiesCheckForDupes(), when done
Also, uncomment addEntry in TestFencing#testFencingInteractionWithBookieRecovery()",2011-11-15 18:22:28,2012-03-31 14:36:57
BOOKKEEPER-113,NPE In BookKeeper test,Bug,1,Closed,6,Fixed,2012-02-24 19:08:38,2011-11-17 13:50:36,2012-10-22T14:50:18.000+0000,ikelly,Ivan Kelly,ikelly,"This is not correctness issue, but it is ugly to throw an NPE there. 

{noformat}
Running org.apache.bookkeeper.test.BookieFailureTest
Nov 17, 2011 2:48:28 PM org.jboss.netty.channel.DefaultChannelFuture
WARNING: An exception was thrown by ChannelFutureListener.
java.lang.NullPointerException
	at org.apache.bookkeeper.proto.PerChannelBookieClient.addEntry(PerChannelBookieClient.java:231)
	at org.apache.bookkeeper.proto.BookieClient$1.operationComplete(BookieClient.java:85)
	at org.apache.bookkeeper.proto.BookieClient$1.operationComplete(BookieClient.java:78)
	at org.apache.bookkeeper.proto.PerChannelBookieClient$1.operationComplete(PerChannelBookieClient.java:158)
	at org.jboss.netty.channel.DefaultChannelFuture.notifyListener(DefaultChannelFuture.java:381)
	at org.jboss.netty.channel.DefaultChannelFuture.notifyListeners(DefaultChannelFuture.java:372)
	at org.jboss.netty.channel.DefaultChannelFuture.setSuccess(DefaultChannelFuture.java:316)
	at org.jboss.netty.channel.socket.nio.NioWorker$RegisterTask.run(NioWorker.java:767)
	at org.jboss.netty.channel.socket.nio.NioWorker.processRegisterTaskQueue(NioWorker.java:256)
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:198)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
	at java.lang.Thread.run(Thread.java:680)
{noformat}

The fix should be trivial, though.",2011-11-17 13:50:36,2012-02-24 19:08:38
BOOKKEEPER-114,add a shutdown hook to shut down bookie server safely.,Improvement,4,Closed,6,Fixed,2011-11-18 18:58:56,2011-11-18 11:19:00,2011-12-07T15:56:12.000+0000,ikelly,Ivan Kelly,ikelly,"Currently, if Bookie server is terminated, e.g. CTRL-C, kill -SIGTERM pid, kill pid, the data buffered in BufferedChannel has no chanced to be flushed, which may make files corrupted. 

We should add a shutdown hook to shut down bookie server safely, which will be called when JVM is terminated.",2011-11-18 11:19:00,2011-11-18 18:58:56
BOOKKEEPER-115,LocalBookKeeper fails after BOOKKEEPER-108,Bug,1,Closed,6,Fixed,2011-11-18 18:07:51,2011-11-18 11:57:57,2011-12-07T15:56:12.000+0000,ikelly,Ivan Kelly,ikelly,"After adding configuration to Bookkeeper, localbookie doesn't start because it fails to find /tmp/bk-txn.

The problem is that the configuration uses addProperty where it should use setProperty.",2011-11-18 11:57:57,2011-11-18 18:07:51
BOOKKEEPER-117,Support multi threads in hedwig cpp client to leverage multi-core hardware,Improvement,4,Closed,6,Fixed,2011-11-28 15:24:32,2011-11-23 09:46:28,2011-12-07T15:56:13.000+0000,ikelly,Ivan Kelly,ikelly,"Currently in hedwig cpp client, there is only one thread running io service.
Actually, we can have an io_service pool, each io_service is processed by a separated thread. Each socket connection would be bound to an io_service to process it i/o operations.",2011-11-23 09:46:28,2011-11-28 15:24:32
BOOKKEEPER-118,Hedwig client doesn't kill and remove old subscription channel after redirection.,Bug,1,Closed,6,Fixed,2011-11-28 12:16:10,2011-11-23 10:36:02,2011-12-07T15:56:13.000+0000,ikelly,Ivan Kelly,ikelly,"Currently we found that hedwig cpp client doesn't kill and remove old subscription channels after redirection, so there is lots of unused channels.

Not sure whether hedwig java client has the same issue, need to check it.",2011-11-23 10:36:02,2011-11-28 12:16:10
BOOKKEEPER-119,Keys in configuration have inconsistent style,Bug,1,Closed,6,Fixed,2011-11-28 16:33:10,2011-11-25 09:37:43,2011-12-07T15:56:07.000+0000,ikelly,Ivan Kelly,ikelly,"Some of the keys are CamelCase, some are with underscores. I think we should standardize on CamelCase.",2011-11-25 09:37:43,2011-11-28 16:33:10
BOOKKEEPER-120,Review BookKeeper client documentation,Sub-task,7,Closed,6,Fixed,2011-11-29 22:29:53,2011-11-25 16:10:15,2011-12-07T15:56:08.000+0000,ikelly,Ivan Kelly,ikelly,,2011-11-25 16:10:15,2011-11-29 22:29:53
BOOKKEEPER-121,Review Hedwig client documentation,Sub-task,7,Closed,6,Fixed,2011-11-29 20:00:44,2011-11-25 16:11:25,2011-12-07T15:56:16.000+0000,ikelly,Ivan Kelly,ikelly,,2011-11-25 16:11:25,2011-11-29 20:00:44
BOOKKEEPER-122,Review BookKeeper server documentation,Sub-task,7,Closed,6,Fixed,2011-11-29 23:27:47,2011-11-25 16:12:09,2011-12-07T15:56:15.000+0000,ikelly,Ivan Kelly,ikelly,,2011-11-25 16:12:09,2011-11-29 23:27:47
BOOKKEEPER-124,build has RAT failures,Bug,1,Closed,6,Fixed,2011-11-29 09:06:16,2011-11-28 22:20:18,2011-12-07T15:56:12.000+0000,ikelly,Ivan Kelly,ikelly,"run: mvn apache-rat:check,

It gives errors. Rat is used to check all files have licenses etc.",2011-11-28 22:20:18,2011-11-29 09:06:16
BOOKKEEPER-125,log4j still used in some places,Bug,1,Closed,6,Fixed,2011-11-29 17:46:38,2011-11-29 12:59:38,2011-12-07T15:56:08.000+0000,ikelly,Ivan Kelly,ikelly,"Seems to have crept back in in test which were in the air when the original log4j->slf4j went in.
",2011-11-29 12:59:38,2011-11-29 17:46:38
BOOKKEEPER-127,Make poms use official zookeeper 3.4.0,Bug,1,Closed,6,Fixed,2011-11-29 22:27:14,2011-11-29 21:22:24,2011-12-07T15:56:05.000+0000,ikelly,Ivan Kelly,ikelly,As summary says.,2011-11-29 21:22:24,2011-11-29 22:27:14
BOOKKEEPER-128,pom and script modifications required for generating release packages,Bug,1,Closed,6,Fixed,2011-11-30 10:08:02,2011-11-29 21:37:47,2011-12-07T15:56:09.000+0000,ikelly,Ivan Kelly,ikelly,"These got missed with BOOKKEEPER-41. It's basically a maven assembly file, and making bookkeeper and hedwig scripts executable. Also, for the servers, make log4j and the slf4j log4j adapter, real dependencies, so logging can be enabled.",2011-11-29 21:37:47,2011-11-30 10:08:02
BOOKKEEPER-129,ZK_TIMEOUT typo in client/server configuration,Bug,1,Closed,6,Fixed,2011-11-30 10:40:37,2011-11-30 10:24:47,2011-12-07T15:56:15.000+0000,ikelly,Ivan Kelly,ikelly,"there is a typo ZK_TIMEOUT in client/server configuration:

{code}
    public ClientConfiguration setZkTimeout(int zkTimeout) {
        setProperty(ZK_SERVERS, Integer.toString(zkTimeout));
        return this;
    }
{code}",2011-11-30 10:24:47,2011-11-30 10:40:37
BOOKKEEPER-131,Fix zookeeper test dependency,Bug,1,Closed,6,Fixed,2011-12-01 21:08:57,2011-11-30 15:47:25,2011-12-07T15:56:15.000+0000,ikelly,Ivan Kelly,ikelly,"The zookeeper test jar in maven has changed name since development. Whats more, the new name is incompatible with maven <type>test-jar</type>.

This must be fixed before releasing.",2011-11-30 15:47:25,2011-12-01 21:08:57
BOOKKEEPER-132,Sign artifacts before deploying to maven,Improvement,4,Closed,6,Fixed,2011-11-30 16:21:53,2011-11-30 15:48:14,2011-12-07T15:56:15.000+0000,ikelly,Ivan Kelly,ikelly,"As the summary says, we should sign artifacts before deploying for release.",2011-11-30 15:48:14,2011-11-30 16:21:53
BOOKKEEPER-133,Hub server should update subscription state to zookeeper when losing topic or shutting down,Bug,1,Closed,6,Fixed,2011-12-22 17:36:34,2011-12-01 13:58:24,2012-10-22T14:50:13.000+0000,ikelly,Ivan Kelly,ikelly,"Currently hub server use counter-based mechanism to update subscription state lazily to zookeeper.
But in the following case, it didn't do it.
1) losing ownership of Topic
2) hub server shuts down
3) a subscription channel disconnected",2011-12-01 13:58:24,2011-12-22 17:36:34
BOOKKEEPER-134,Delete superfluous lib directories,Bug,1,Closed,6,Fixed,2011-12-01 22:27:28,2011-12-01 21:31:47,2011-12-07T15:56:16.000+0000,ikelly,Ivan Kelly,ikelly,Removed lib directories which were used for storing old zk jars.,2011-12-01 21:31:47,2011-12-01 22:27:28
BOOKKEEPER-135,Fencing does not check the ledger masterPasswd,Bug,1,Closed,6,Fixed,2012-04-02 10:38:52,2011-12-02 11:11:35,2013-05-02T02:29:49.000+0000,ikelly,Ivan Kelly,ikelly,"When fencing, the ledger handle is not checked before the fencing is applied. Currently the openLedger does fail, on because it will addEntry and fail at that point, but by this stage, fencing has already been applied. The check should be earlier.",2011-12-02 11:11:35,2012-04-02 10:38:52
BOOKKEEPER-137,Do not create Ledger index files until absolutely necessary.,Bug,1,Closed,6,Fixed,2012-02-09 17:15:25,2011-12-02 14:58:10,2012-10-22T14:50:13.000+0000,ikelly,Ivan Kelly,ikelly,"This is an optimization to speed up the case where we have many ledgers and are writing to them at random (a benchmark case we currently have). Currently, we create the ledger index file and write the first 1k of it to disk immediately. With a lot of ledgers being randomly written to, this means a lot of random writes on the ledger disk. This fix postpones the creation of the index file and writing of the first 1k until the first flush of the ledger.",2011-12-02 14:58:10,2012-02-09 17:15:25
BOOKKEEPER-138,NOTICE.txt is invalid,Bug,1,Closed,6,Fixed,2011-12-02 19:36:30,2011-12-02 18:04:07,2011-12-07T15:56:13.000+0000,ikelly,Ivan Kelly,ikelly,"As summary says, should be apache copyright. ",2011-12-02 18:04:07,2011-12-02 19:36:30
BOOKKEEPER-139,Binary packages do not carry NOTICE.txt,Bug,1,Closed,6,Fixed,2011-12-02 20:00:38,2011-12-02 19:39:05,2011-12-07T15:56:09.000+0000,ikelly,Ivan Kelly,ikelly,As summary,2011-12-02 19:39:05,2011-12-02 20:00:38
BOOKKEEPER-140,Hub server doesn't subscribe remote region correctly when a region is down.,Bug,1,Closed,6,Fixed,2011-12-21 16:43:39,2011-12-06 11:31:09,2012-10-22T14:50:15.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Hub server doesn't subscribe remote region correctly in following cases: (assume there is 3 regions, A, B, C)

1. region shuts down before first subscribe.

1) region C is down.
2) subscribe-a subscribe a topic in region A. a subscription state is created in region A's zookeeper. but remote subscribe to region C would fail since region C is down. hub server will respond client that subscribe failed without deleting subscription state. The following subscriptions using same subscribe id and same topic would failed due to NodeExists.

2. region shuts down when attaches existing subscriptions.

1) In region A, there is a local subscriber a for topic T. in region B, subscriber b for topic T. in region B, subscribe c for topic T.
2) servers are all restarted in all three regions. But region C is network-partitioned (or shuts down) from region A and region B.
3) subscriber b and subscribe c try to subscribe T again. hub servers in region B, C will try to remote subscribe region A, but should failed. There is no mechanism to retry remote subscribe. so if messages are published to topic T in region A, subscribe b and subscribe c would receive any message.  ",2011-12-06 11:31:09,2011-12-21 16:43:39
BOOKKEEPER-141,Run extracting ledger id from entry log files in GC thread to speed up bookie restart,Improvement,4,Closed,6,Fixed,2011-12-16 14:35:36,2011-12-12 14:33:39,2012-10-22T14:50:17.000+0000,ikelly,Ivan Kelly,ikelly,"Currently bookie server do extracting ledger id from entry log files when creating a new entry log.

When we have lots of entry logs, we have to scan all these entry log files, then bookie server will be blocked until finished extraction. 

But it is not necessary. Since extraction is only for garbage collection, we can do extraction in GC thread before gc entry log files.",2011-12-12 14:33:39,2011-12-16 14:35:36
BOOKKEEPER-142,"Parsing last log id is wrong, which may make entry log files overwritten",Bug,1,Resolved,5,Fixed,2011-12-16 11:44:02,2011-12-12 14:53:18,2011-12-16T12:16:44.000+0000,ikelly,Ivan Kelly,ikelly,"Currently we use hex string to format log id.
But we don't parse log id correctly.",2011-12-12 14:53:18,2011-12-16 11:44:02
BOOKKEEPER-143,Add SSL support for hedwig cpp client,Improvement,4,Closed,6,Fixed,2012-10-01 13:41:31,2011-12-15 07:41:26,2013-02-13T15:46:46.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Currently Hedwig CPP client doesn't support SSL. 

Example for boost::asio using SSL:

http://www.boost.org/doc/libs/1_46_1/doc/html/boost_asio/example/ssl/client.cpp
",2011-12-15 07:41:26,2012-10-01 13:41:31
BOOKKEEPER-145,Put notice and license file for distributed binaries in SVN,Improvement,4,Closed,6,Fixed,2012-05-15 10:06:38,2011-12-21 10:52:38,2012-10-22T14:50:14.000+0000,ikelly,Ivan Kelly,ikelly,During the 4.0.0 I manually put these in the binary tarballs. This is awkward though. It's easier just to have them in the source tree.,2011-12-21 10:52:38,2012-05-15 10:06:38
BOOKKEEPER-146,TestConcurrentTopicAcquisition sometimes hangs,Bug,1,Closed,6,Fixed,2012-05-25 09:48:39,2011-12-21 16:49:48,2012-10-22T14:50:17.000+0000,ikelly,Ivan Kelly,ikelly,"to repro
{code}
while [ $? = 0 ]; do mvn test -Dtest=TestConcurrentTopicAcquisition; done
{code}

The stacktrace where it hangs looks very like BOOKKEEPER-5

{code}
""main"" prio=5 tid=102801000 nid=0x100601000 waiting on condition [1005ff000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <7bd8e1090> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:196)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2025)
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1253)
	at org.jboss.netty.util.internal.ExecutorUtil.terminate(ExecutorUtil.java:107)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.releaseExternalResources(NioClientSocketChannelFactory.java:143)
	at org.apache.hedwig.client.netty.HedwigClientImpl.close(HedwigClientImpl.java:234)
	at org.apache.hedwig.client.HedwigClient.close(HedwigClient.java:70)
	at org.apache.hedwig.server.topics.TestConcurrentTopicAcquisition.tearDown(TestConcurrentTopicAcquisition.java:99)
	at junit.framework.TestCase.runBare(TestCase.java:140)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
	at junit.framework.TestResult.runProtected(TestResult.java:128)
	at junit.framework.TestResult.run(TestResult.java:113)
	at junit.framework.TestCase.run(TestCase.java:124)
	at junit.framework.TestSuite.runTest(TestSuite.java:232)
	at junit.framework.TestSuite.run(TestSuite.java:227)
	at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83)

{code}",2011-12-21 16:49:48,2012-05-25 09:48:39
BOOKKEEPER-147,Remote subscriptions do not receive all unconsumed messages for a topic,Bug,1,Resolved,5,Won't Do,2017-10-09 09:54:34,2011-12-22 14:06:53,2017-10-09T09:54:34.000+0000,,,,"Take the case of 2 regions, rA & rB and a topic T, and a mobile subscriber, s1. s1 could be a phone or a tablet etc.

s1 subscribes to T on rA at time X. s1 moves location, so that rB is now it's local region. s1 subscribes to T on rB (the connection to rA was lost while moving) at time Y.
Any messages published to T in the period between X and Y, if they have not been sent to s1 will not be sent to s1. ",2011-12-22 14:06:53,2017-10-09 09:54:34
BOOKKEEPER-148,Jenkins build is failing,Bug,1,Closed,6,Fixed,2012-01-11 14:48:22,2012-01-02 11:28:40,2012-10-22T14:50:15.000+0000,ikelly,Ivan Kelly,ikelly,"This is due to running out of DirectBufferMemory in TestFencing which doesn't get garbage collected as normal memory does. TestFencing creates too many BookKeeper client instances, and this is what exhausts the buffers.",2012-01-02 11:28:40,2012-01-11 14:48:22
BOOKKEEPER-149,Implement HedwigSubscriber#getSubscriptionList(ByteString subscriberId),Improvement,4,Resolved,5,Won't Do,2017-10-09 09:54:26,2012-01-02 11:42:02,2017-10-09T09:54:26.000+0000,,,,"This method currently returns null. (see https://github.com/apache/bookkeeper/blob/trunk/hedwig-client/src/main/java/org/apache/hedwig/client/netty/HedwigSubscriber.java#L436 )

A possible implementation would use a control message, like subscription messages. But that will require modifications to the protocol definition. Maybe there is another way?



",2012-01-02 11:42:02,2017-10-09 09:54:26
BOOKKEEPER-150,Entry is lost when recovering a ledger with not enough bookies.,Bug,1,Closed,6,Fixed,2012-01-17 15:52:40,2012-01-03 14:43:07,2012-10-22T14:50:18.000+0000,ikelly,Ivan Kelly,ikelly,"suppose a ledger is created as ensemble size 3 and quorum size 3.
3 entries is added in this ledger, entry ids are 0, 1, 2.

this ledger is not closed. then a bookie server is down.

the ledger is opened. it would be recovered in following steps:
1) retrieve LAC from all bookie ensemble to get maxAddConfirmed. then maxAddPushed would be 2 and maxAddConfirmed would be 1. then lastAddConfirmed would be 1.
2) doRecovery read lastAddConfirmed + 1 (2). it would return right data since there is still 2 replicas.
3) doRecovery add entry 2. but it would fail since there is not enough bookies to form a new ensemble.
4) this ledger will be closed with lastAddConfirmed (1). entry 2 will be lost.

this issue happened in hub server. old ledger will be recovered and closed when changing ownership. so published messages would be lost.

we should not close ledger when we encountered exception during recovery adding, otherwise we would lose entries.",2012-01-03 14:43:07,2012-01-17 15:52:40
BOOKKEEPER-152,Can't recover a ledger whose current ensemble contain failed bookie.,Bug,1,Closed,6,Fixed,2012-02-13 14:47:26,2012-01-11 10:10:15,2013-05-02T02:29:49.000+0000,ikelly,Ivan Kelly,ikelly,"Suppose we have a unclosed ledger L, whose ensemble size is 2, quorum size is 2. the ledger's current ensemble is <bk1, bk2>.

bk2 is crashed. 

we use recovery tool to recover entries in bk2. $ bookkeeper-server/bin/bookkeeper org.apache.bookkeeper.tools.BookKeeperTools bk2 

recovery failed due to recovery tool can't open ledger L, since ledger L doesn't have enough quorum to readLastConfirmed entry. (asyncOpenLedgerNoRecovery)








",2012-01-11 10:10:15,2012-02-13 14:47:26
BOOKKEEPER-153,Ledger can't be opened or closed due to zero-length metadata,Bug,1,Closed,6,Fixed,2012-01-18 14:13:19,2012-01-16 07:05:04,2012-10-22T14:50:18.000+0000,ikelly,Ivan Kelly,ikelly,"Currently creating ledger path and writing ledger metadata are not in a transaction. so if the bookkeeper client (hub server uses bookkeeper client) is crashed, we have a ledger existed in zookeeper with zero-length metadata. we can't open/close it.

we should create the ledger path with initial metadata to avoid such case. besides that, we need to add code in openLedgerOp to handle zero-length metadata for backward compatibility.

",2012-01-16 07:05:04,2012-01-18 14:13:19
BOOKKEEPER-156,BookieJournalRollingTest failing ,Bug,1,Closed,6,Fixed,2012-02-08 10:41:41,2012-01-29 10:40:45,2012-10-22T14:50:16.000+0000,ikelly,Ivan Kelly,ikelly,The test fails for me intermittently. ,2012-01-29 10:40:45,2012-02-08 10:41:41
BOOKKEEPER-157,"For small packets, increasing number of bookies actually degrades performance.",Improvement,4,Closed,6,Fixed,2012-02-01 15:20:32,2012-01-30 12:17:37,2012-10-22T14:50:14.000+0000,ikelly,Ivan Kelly,ikelly,"When benchmarking with packets smaller than 1k, performance will degrade when the ensemble contains more than 3 bookies. See attached diagram.",2012-01-30 12:17:37,2012-02-01 15:20:32
BOOKKEEPER-158,Move latest benchmarking code into trunk,Improvement,4,Closed,6,Fixed,2012-03-09 13:50:04,2012-01-31 11:47:21,2012-10-22T14:50:17.000+0000,ikelly,Ivan Kelly,ikelly,Move the code we've been using for benchmarking into trunk.,2012-01-31 11:47:21,2012-03-09 13:50:04
BOOKKEEPER-159,Add compression on bookies,New Feature,2,Open,1,,,2012-02-02 10:43:11,2017-10-17T21:29:51.000+0000,ikelly,Ivan Kelly,ikelly,"The bottleneck on ledgers is the speed at which we can write to disk. We have CPU going spare, so why not compress the data being written to increase I/O? ",2012-02-02 10:43:11,
BOOKKEEPER-160,bookie server needs to do compaction over entry log files to reclaim disk space,Improvement,4,Closed,6,Fixed,2012-03-08 11:14:08,2012-02-03 13:15:26,2012-10-22T14:50:18.000+0000,ikelly,Ivan Kelly,ikelly,"bookie server aggregates entries into entry log file. suppose there is lots of ledgers, each ledger has little messages. so a entry log file would contains messages from lots of different ledgers. if there is only one ledger not be deleted, the entry log file would not be removed, whose occupied disk space could not be reclaimed.",2012-02-03 13:15:26,2012-03-08 11:14:08
BOOKKEEPER-161,"PerChannelBookieClient tries to reuse HashedWheelTimer, throws Exception",Bug,1,Closed,6,Fixed,2012-02-07 10:05:49,2012-02-06 17:10:28,2012-10-22T14:50:18.000+0000,ikelly,Ivan Kelly,ikelly,"A hashedWheelTimer can only be stopped once, but in the current implementation, only one HashedWheelTimer is used per PerChannelBookieClient which can connect and disconnect many time. Currently stop the hashWheelTimer any time a channel is disconnected, but only create it once in the constructor. This causes exceptions to be thrown in the netty callback thread.",2012-02-06 17:10:28,2012-02-07 10:05:49
BOOKKEEPER-162,LedgerHandle.readLastConfirmed does not work,Bug,1,Closed,6,Fixed,2012-02-13 10:20:11,2012-02-07 05:15:35,2012-10-22T14:50:13.000+0000,fpj,Flavio Paiva Junqueira,fpj,"Two bookkeeper clients.
1st continuously writing to ledger X.
2nd (bk.openLedgerNoRecovery) polling ledger X for new entries and reading them.

In response we always reveiceing 0 as last confirmed entry id (in fact we are receiving -1 from each bookie RecoveryData but then in ReadLastConfirmedOp, but uninitialized ""long maxAddConfirmed;"" takes priority in Math.max(...).

Main question - is given scenario is expected to work at all?

",2012-02-07 05:15:35,2012-02-13 10:20:11
BOOKKEEPER-163,Prevent incorrect NoSuchLedgerException for readLastConfirmed.,Bug,1,Closed,6,Fixed,2012-03-13 06:35:01,2012-02-07 11:51:28,2013-05-02T02:29:49.000+0000,ikelly,Ivan Kelly,ikelly,"bookkeeper client treats NoSuchLedgerException as valid response when reading last confirmed. If NoSuchLedgerException is caused due to an empty directory in following cases, it is an incorrect response. 

1) A disk is replaced or ledger index is removed by a sloppy admin.
2) A disk is not mounted when a bookie machine is restarted.

We need a mechanism to prevent such incorrect responses.

Ivan suggested to generate a instance key for each bookie and write it into the ledger directories. If a directory doesn't have the key, and other directories do, then it shouldn't start. This would also resolve the issue that someone starting a new bookie with the same IP as a bookie which has previously died.",2012-02-07 11:51:28,2012-03-13 06:35:01
BOOKKEEPER-164,Add checksumming for ledger index files,Improvement,4,Open,1,,,2012-02-07 11:54:09,2017-10-17T21:29:48.000+0000,hustlmsp,Sijie Guo,hustlmsp,"now bookie ledger index files lacks checksumming to prevent truncation/corruption. if a ledger index file is truncated, the ledger index file still works but responds wrong response when reading last confirmed.",2012-02-07 11:54:09,
BOOKKEEPER-165,Add versioning support for journal files,New Feature,2,Closed,6,Fixed,2012-02-09 09:21:00,2012-02-07 16:48:47,2012-10-22T14:50:13.000+0000,ikelly,Ivan Kelly,ikelly,Add versioning in the journal so that we can add new features to the journal without breaking backward compatibility.,2012-02-07 16:48:47,2012-02-09 09:21:00
BOOKKEEPER-166,Bookie will not recover its journal if the length prefix of an entry is truncated,Bug,1,Closed,6,Fixed,2012-03-30 11:00:36,2012-02-07 17:00:20,2012-10-22T14:50:14.000+0000,ikelly,Ivan Kelly,ikelly,"Entries in the bookie's journal are written in the format <len><entry>

If the bookie crashes while writing the length part, then the bookie will not be able to recover the journal.
An unlikely situation to happen as this is only 1 int, but an issue none the less.

There is a testcase in BOOKKEEPER-165 which will trigger this when enabled (BookieJournalTest#testTruncatedInLenJournal).

",2012-02-07 17:00:20,2012-03-30 11:00:36
BOOKKEEPER-167,PerChannelBookieClient doesn't use ClientConfiguration,Bug,1,Closed,6,Fixed,2012-02-08 10:41:18,2012-02-08 08:54:15,2012-10-22T14:50:18.000+0000,ikelly,Ivan Kelly,ikelly,"currently, we don't use ClientConfiguration to initialize PerChannelBookieClient. so the readtimeout settings are not applied to PerChannelBookieClient.",2012-02-08 08:54:15,2012-02-08 10:41:18
BOOKKEEPER-168,Message bounding on subscriptions,New Feature,2,Closed,6,Fixed,2012-04-20 09:21:19,2012-02-09 16:53:42,2012-10-22T14:50:13.000+0000,ikelly,Ivan Kelly,ikelly,"In hedwig, messages for a subscription will queue up forever if the subscriber is offline. In some usecases, this is undesirable, as it will eventually mean resource exhaustion. In this JIRA we propose an optional change to the subscription contract, which allows the user to set a bound on the number of messages which will be queued for its subscription while it is offline.",2012-02-09 16:53:42,2012-04-20 09:21:19
BOOKKEEPER-169,bookie hangs on reading header when encountering partial header index file,Bug,1,Closed,6,Fixed,2012-02-17 10:22:14,2012-02-14 16:08:30,2012-10-22T14:50:13.000+0000,ikelly,Ivan Kelly,ikelly,"bookie server hangs on reading header part when reading partial header index file (whose header part is less than 1k). This kind of index file existed because bookie server shuts down when writing header of index file.

bookie server should check file size when reading header. in pre-v3 journal, we don't have master key stored in journal, so if master key is missing, we have no chance to repair it just throw an IOException when reading header. in post-v3 journal, we store master key as an meta entry in journal, so we can rewrite the header part.

",2012-02-14 16:08:30,2012-02-17 10:22:14
BOOKKEEPER-170,Bookie constructor starts a number of threads,Bug,1,Closed,6,Fixed,2012-02-15 15:12:38,2012-02-14 18:25:13,2012-10-22T14:50:16.000+0000,ikelly,Ivan Kelly,ikelly,"Starting a thread in a constructor is bad[1]. Also, it makes unit testing on Bookie a bit of a pain. For this reason, i've refactored the thread starting code out, so that to start the bookie, you call start() like you usually have to for a thread anyhow. As a bonus, it fixes some findbugs issues.


[1] http://stackoverflow.com/questions/84285/calling-thread-start-within-its-own-constructor",2012-02-14 18:25:13,2012-02-15 15:12:38
BOOKKEEPER-171,ServerConfiguration can't use more than one directory for ledgers,Bug,1,Closed,6,Fixed,2012-02-15 10:04:49,2012-02-14 18:28:37,2012-10-22T14:50:16.000+0000,ikelly,Ivan Kelly,ikelly,"ServerConfiguration cannot use more than one directory for ledgers, due to a bug in how it stores multiple values. ",2012-02-14 18:28:37,2012-02-15 10:04:49
BOOKKEEPER-172,Upgrade framework for filesystem layouts,Improvement,4,Closed,6,Fixed,2012-02-24 17:10:43,2012-02-15 13:56:16,2013-05-02T02:29:49.000+0000,ikelly,Ivan Kelly,ikelly,Part of BOOKKEEPER-163. This improvement creates a framework to allow administrators to upgrade the filesystem layout of previous bookkeeper versions to be usable by the most recent software. The upgrade processes are currently empty until BOOKKEEPER-163 adds something.,2012-02-15 13:56:16,2012-02-24 17:10:43
BOOKKEEPER-173,Uncontrolled number of threads in bookkeeper,Bug,1,Closed,6,Fixed,2012-04-20 17:19:27,2012-02-16 06:58:09,2012-10-22T14:50:18.000+0000,hustlmsp,Sijie Guo,hustlmsp,"I am not sure if it is a but or not.

Say, I do have pc with 256 cores, and there is following code in bookkeeper:
{code:title=BookKeeper.java|borderStyle=solid}
OrderedSafeExecutor callbackWorker = new OrderedSafeExecutor(Runtime.getRuntime().availableProcessors());
OrderedSafeExecutor mainWorkerPool = new OrderedSafeExecutor(Runtime .getRuntime().availableProcessors());
{code}
As I understand, callbackWorker is not used at all, so it could be removed.
Also could be required to get more control over mainWorkerPool (say, extract interface + pass instance through contructor).

Myabe there are other places in library where some thread pools are created without ability to reuse existing thread pools in application.






",2012-02-16 06:58:09,2012-04-20 17:19:27
BOOKKEEPER-174,Bookie can't start when replaying entries whose ledger were deleted and garbage collected.,Bug,1,Closed,6,Fixed,2012-02-17 11:50:38,2012-02-16 07:10:43,2012-10-22T14:50:17.000+0000,ikelly,Ivan Kelly,ikelly,"if a journal contains entries which the ledgers they belongs to has been deleted and garbage collected, replaying such journal would encounter NoSuchLedgerException. And the bookie can't start.",2012-02-16 07:10:43,2012-02-17 11:50:38
BOOKKEEPER-175,Bookie code is very coupled,Improvement,4,Closed,6,Fixed,2012-03-20 13:09:42,2012-02-17 10:01:04,2012-10-22T14:50:17.000+0000,ikelly,Ivan Kelly,ikelly,"Bookie owns EntryLogger, LedgerCache, LedgerDescriptors which all depend on each other in strange ways. Sometimes we access the ledgerCache directly, sometimes through LedgerDescriptors. etc, etc. It's messy and there's no hierarchy.

I propose that we refactor Bookie to only contain the EntryLogger and journalling code (this should be factored at some stage also). The EntryLogger can then own the ledgerCache and the LedgerDescriptors, and then we would how have to have the entanglement as observed on BOOKKEEPER-160.",2012-02-17 10:01:04,2012-03-20 13:09:42
BOOKKEEPER-176,HierarchicalBookieFailureTest Hung,Bug,1,Closed,6,Fixed,2012-03-01 14:58:41,2012-02-17 13:21:53,2012-10-22T14:50:16.000+0000,ikelly,Ivan Kelly,ikelly,See jstack attachment.,2012-02-17 13:21:53,2012-03-01 14:58:41
BOOKKEEPER-177,Index file is lost or some index pages aren't flushed.,Bug,1,Closed,6,Fixed,2012-02-24 18:09:41,2012-02-23 13:11:53,2012-10-22T14:50:17.000+0000,hustlmsp,Sijie Guo,hustlmsp,"we found that some index files are lost ore some index pages aren't flushed after applying BOOKKEEPER-137 patch.

this issue can be reproduced by following sequence.

index file missing:

1) create ledger 1 without writing any entries
2) open ledger 1 which causes a recoveryRead entry(0) sent to bookie server. then an empty page is put in pageTable by mistake as below. (we should call updatePage first to check whether bookie server has this ledger)
{code}
                 // in ledgerCache#getEntryOffset
                 lep = grabCleanPage(ledger, pageEntry);
                 synchronized(this) {
                     putIntoTable(pages, lep);
                 }
                 updatePage(lep);
{code}
3) open ledger 2 to write serval entries. a meta entry and several data entries would be put in journal.
4) SyncThread executes to flush ledger. it first flush ledger 1, although ledger 1 has an empty page which is clean, but the code still need to call #getFileInfo, which will cause an NoLedgerException fail the flush. unfortunately, the SyncThread caught this exception and just output an error message then rollLog. the result is ledger 2 is not flushed, and its journal entries would not be replayed after restarted.
{code}
                 lastLogMark.markLog();
 
                 try {
                     ledgerCache.flushLedger(true);
                 } catch (IOException e) {
                     LOG.error(""Exception flushing Ledger"", e);
                 }
                 try {
                     entryLogger.flush();
                 } catch (IOException e) {
                     LOG.error(""Exception flushing entry logger"", e);
                 }
 
                 lastLogMark.rollLog();
{code}


similar case for some index pages are not flushed.",2012-02-23 13:11:53,2012-02-24 18:09:41
BOOKKEEPER-178,Delay ledger directory creation until the ledger index file was created,Improvement,4,Closed,6,Fixed,2012-02-24 18:21:24,2012-02-24 06:05:15,2012-10-22T14:50:14.000+0000,hustlmsp,Sijie Guo,hustlmsp,"The index file creation is delayed until absolutely necessary after BOOKKEEPER-137. but we don't delay the creation of parent directories of index file, it would hurt performance.",2012-02-24 06:05:15,2012-02-24 18:21:24
BOOKKEEPER-180,bookie server doesn't quit when running out of disk space,Bug,1,Closed,6,Fixed,2012-03-08 18:25:28,2012-03-01 05:11:56,2012-10-22T14:50:14.000+0000,ikelly,Ivan Kelly,ikelly,"we found that the publish throughput drops down when one bookie server ran out of disk space (due to we don't do log rotation   which exhausts disk space). 

did some investigation, we found that bookie server doesn't quit when encountering no disk space issue. so hub server treat this bookie server as available. The adding requests would be sent to this bookie server, some adding requests are put in journal queue to flush, but the journal flush thread has quit due to no disk space. so these adding requests didn't respond to bookie client until it read timeout and chose other bookie servers.

we did an experiment to shut down the ran-out-of-disk-space bookie, the publish throughput went up again quickly.",2012-03-01 05:11:56,2012-03-08 18:25:28
BOOKKEEPER-181,Scale hedwig,Improvement,4,Resolved,5,Implemented,2012-12-18 05:56:34,2012-03-07 01:27:52,2013-01-14T14:21:38.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Current implementation of Hedwig and BookKeeper is designed to scale to hundreds of thousands of topics, but now we are looking at scaling them to tens to hundreds of millions of topics, using a scalable key/value store such as HBase.
",2012-03-07 01:27:52,2012-12-18 05:56:34
BOOKKEEPER-182,Entry log file is overwritten when fail to read lastLogId.,Bug,1,Closed,6,Fixed,2012-03-16 09:42:25,2012-03-08 07:36:07,2012-10-22T14:50:17.000+0000,ikelly,Ivan Kelly,ikelly,"we found data corruption happened on entry log files.

2012-03-06 07:26:14,947 - ERROR [NIOServerFactory-3181:BookieServer@413] - Error reading 229@114724
java.io.IOException: problem found in 0@229 at position + 89030194 entry belongs to 6373236044838956613 not 114724
        at org.apache.bookkeeper.bookie.EntryLogger.readEntry(EntryLogger.java:347)
        at org.apache.bookkeeper.bookie.LedgerDescriptor.readEntry(LedgerDescriptor.java:180)
        at org.apache.bookkeeper.bookie.Bookie.readEntry(Bookie.java:1081)
        at org.apache.bookkeeper.proto.BookieServer.processPacket(BookieServer.java:386)
        at org.apache.bookkeeper.proto.NIOServerFactory$Cnxn.readRequest(NIOServerFactory.java:315)
        at org.apache.bookkeeper.proto.NIOServerFactory$Cnxn.doIO(NIOServerFactory.java:213)
        at org.apache.bookkeeper.proto.NIOServerFactory.run(NIOServerFactory.java:124

then we did some investigation on failed ledger:

first looked into ledger 114724's index file.

{code}
entry 75        :       (log:11, pos: 100526580)
entry 76        :       (log:11, pos: 101849530)
entry 77        :       (log:11, pos: 103176596)
entry 78        :       (log:11, pos: 104403977)
entry 79        :       (log:11, pos: 105756017)
entry 80        :       (log:11, pos: 106740803)
entry 81        :       (log:0, pos: 73365)
entry 82        :       (log:0, pos: 1366625)
entry 83        :       (log:0, pos: 2719276)
entry 84        :       (log:0, pos: 4065142)
{code}

from entry 80, the data is written in 0 entry log which is less than 11. (means data is written to an older entry log file)

then we looked into ledger directory as below

{code}
2147483550 Mar  5 11:30 /var/bookkeeper/ledger/0.log
  94122988 Mar  5 11:33 /var/bookkeeper/ledger/1.log
1984247565 Mar  5 11:34 /var/bookkeeper/ledger/2.log
    288376 Mar  5 11:34 /var/bookkeeper/ledger/3.log
 747151813 Mar  6 03:17 /var/bookkeeper/ledger/4.log
 410381287 Mar  6 07:43 /var/bookkeeper/ledger/5.log
2147483363 Feb 27 19:59 /var/bookkeeper/ledger/7.log
2147483565 Feb 29 09:40 /var/bookkeeper/ledger/9.log
1691783168 Mar  1 03:22 /var/bookkeeper/ledger/a.log
 125556720 Mar  1 08:30 /var/bookkeeper/ledger/b.log
         0 Mar  1 08:33 /var/bookkeeper/ledger/c.log
{code}

the 0-5 entry log files are overwritten.

looked into the code, found that when bookie server failed to read lastLogId, it would set the lastLogId to -1. then start writing entry log files from 0. and also there is not checking about the existen of the entry log file.

it would better to scan the directories to found the biggest log id and start from it. and check whether the file exists or not when creating a new entry log file.
",2012-03-08 07:36:07,2012-03-16 09:42:25
BOOKKEEPER-183,Provide tools to read/check data files in bookie server,New Feature,2,Closed,6,Fixed,2012-06-13 15:00:33,2012-03-08 07:40:52,2013-02-13T15:46:26.000+0000,hustlmsp,Sijie Guo,hustlmsp,"We have written some tools to read/check data files (including index file, journal files, entry log files) in bookie server, which helps user finding/debugging issues. would like to contribute them back.",2012-03-08 07:40:52,2012-06-13 15:00:33
BOOKKEEPER-184,CompactionTest failing on Jenkins,Bug,1,Closed,6,Fixed,2012-03-15 09:44:36,2012-03-13 07:21:18,2012-10-22T14:50:15.000+0000,ikelly,Ivan Kelly,ikelly,"the compaction test hanging on Jenkins. 

Ivan did some investigation on this issue, and found that it wasn't hanging, it was just taking a really long time. He suggested that it is because it does a lot of I/O, theres a couple of ways we could reduce this.
1. Only create 1 bookie
2. Not inherit from BaseTestCase
3. Reduce the number of entries",2012-03-13 07:21:18,2012-03-15 09:44:36
BOOKKEEPER-185,Remove bookkeeper-server dependency on hadoop-common,Improvement,4,Closed,6,Fixed,2012-03-15 09:45:10,2012-03-13 17:42:17,2012-10-22T14:50:15.000+0000,ikelly,Ivan Kelly,ikelly,"bookkeeper-server depends on hadoop-common simply for the use of 1 class, HardLink. This clutters the pom.xml as a lot of stuff needs to be excluded from the transactive dependencies. It would be better just to copy HardLink.java into bookkeeper-server.",2012-03-13 17:42:17,2012-03-15 09:45:10
BOOKKEEPER-186,Bookkeeper throttling - permits is not released when read has failed from all replicas,Bug,1,Closed,6,Fixed,2012-03-19 14:46:04,2012-03-16 10:49:48,2012-10-22T14:50:15.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"Permit is not releasing in the case when there is no quorum available and the readEntries operation failed from all replicas.

Following is the condition where it checks the failure in quorum and invoking ReadCallback:
{noformat}
void sendRead(ArrayList<InetSocketAddress> ensemble, LedgerEntry entry, int lastErrorCode) {
   if (entry.nextReplicaIndexToReadFrom >= lh.metadata.quorumSize) {
      // we are done, the read has failed from all replicas, just fail the
      // read
      submitCallback(lastErrorCode);
      return;
   }
{noformat}",2012-03-16 10:49:48,2012-03-19 14:46:04
BOOKKEEPER-187,Create well defined interface for LedgerCache,Sub-task,7,Closed,6,Fixed,2012-03-20 11:52:22,2012-03-19 11:31:22,2012-10-22T14:50:14.000+0000,ikelly,Ivan Kelly,ikelly,"Currently the code reaches into LedgerCache to access FileInfos or read what is in the cache without going through clean interfaces. This JIRA is to define an interface for LedgerCache, so that we can reason about what accesses are legal.",2012-03-19 11:31:22,2012-03-20 11:52:22
BOOKKEEPER-188,Garbage collection code is in the wrong place,Bug,1,Closed,6,Fixed,2012-03-21 05:14:13,2012-03-20 15:10:38,2012-10-22T14:50:16.000+0000,ikelly,Ivan Kelly,ikelly,"There's a lot of garbage collection code in the wrong place in EntryLogger. extractMetaFromEntryLogs, and EntryLogMetadata are only every used in the GC Thread. So they should move there.",2012-03-20 15:10:38,2012-03-21 05:14:13
BOOKKEEPER-189,AbstractZkLedgerManager doesn't disregard cookies,Bug,1,Closed,6,Fixed,2012-03-21 05:41:15,2012-03-20 15:19:29,2012-10-22T14:50:19.000+0000,ikelly,Ivan Kelly,ikelly,"Since BOOKKEEPER-163, the zk namespace has had a cookie znode. The AbstractZkLedgerManager should disregard this when listing ledgers.",2012-03-20 15:19:29,2012-03-21 05:41:15
BOOKKEEPER-190,Add entries would fail when number of open ledgers reaches more than openFileLimit.,Bug,1,Closed,6,Fixed,2012-03-29 12:08:03,2012-03-21 07:47:40,2012-10-22T14:50:18.000+0000,ikelly,Ivan Kelly,ikelly,"
when the number of open ledgers reaches more than openFileLimit, a file info will be closed and removed from opened ledgers list. And after BOOKKEEPER-137, the ledger index file creation delayed until necessary.

suppose ledger l is removed from opened ledger list, and its index file haven't been created.
new add entries operations of other ledgers came into bookie server, a new page need to be grab for them. so bookie server may need to flush the dirty pages of ledger l(when page cache is full). and the flush would fail due to NoLedgerException (no index file found).

actually the ledger l isn't lost, it could be recovered if restarting bookie server, but the bookie server would not work well on adding entries. 

a proposal solution is that we need to force index creation when the ledger is evicted from open ledgers list.

{code}
2012-03-21 14:00:42,989 - DEBUG - [NIOServerFactory-5000:LedgerCache@235] - New ledger index file created for ledgerId: 4
2012-03-21 14:00:42,990 - INFO  - [NIOServerFactory-5000:LedgerCache@241] - Ledger 2 is evicted from file info cache.
2012-03-21 14:00:42,990 - DEBUG - [New I/O client worker #1-1:PerChannelBookieClient$2@255] - Successfully wrote request for adding entry: 0 ledger-id: 4 bookie: /10.82.129.173:5000 entry length: 70
2012-03-21 14:00:42,990 - ERROR - [NIOServerFactory-5000:BookieServer@361] - Error writing 0@4
org.apache.bookkeeper.bookie.Bookie$NoLedgerException: Ledger 2 not found
        at org.apache.bookkeeper.bookie.LedgerCache.getFileInfo(LedgerCache.java:228)
        at org.apache.bookkeeper.bookie.LedgerCache.flushLedger(LedgerCache.java:359)
        at org.apache.bookkeeper.bookie.LedgerCache.flushLedger(LedgerCache.java:292)
        at org.apache.bookkeeper.bookie.LedgerCache.grabCleanPage(LedgerCache.java:447)
        at org.apache.bookkeeper.bookie.LedgerCache.putEntryOffset(LedgerCache.java:157)
        at org.apache.bookkeeper.bookie.LedgerDescriptor.addEntry(LedgerDescriptor.java:130)
        at org.apache.bookkeeper.bookie.Bookie.addEntryInternal(Bookie.java:1059)
        at org.apache.bookkeeper.bookie.Bookie.addEntry(Bookie.java:1099)
        at org.apache.bookkeeper.proto.BookieServer.processPacket(BookieServer.java:357)
        at org.apache.bookkeeper.proto.NIOServerFactory$Cnxn.readRequest(NIOServerFactory.java:315)
        at org.apache.bookkeeper.proto.NIOServerFactory$Cnxn.doIO(NIOServerFactory.java:213)
        at org.apache.bookkeeper.proto.NIOServerFactory.run(NIOServerFactory.java:124)
2012-03-21 14:00:42,991 - DEBUG - [pool-3-thread-1:PerChannelBookieClient@576] - Got response for add request from bookie: /10.82.129.173:5000 for ledger: 4 entry: 0 rc: 101
2012-03-21 14:00:42,991 - ERROR - [pool-3-thread-1:PerChannelBookieClient@594] - Add for ledger: 4, entry: 0 failed on bookie: /10.82.129.173:5000 with code: 101
2012-03-21 14:00:42,991 - WARN  - [pool-3-thread-1:PendingAddOp@142] - Write did not succeed: 4, 0

{code}",2012-03-21 07:47:40,2012-03-29 12:08:03
BOOKKEEPER-191,"Hub server should change ledger to write, so consumed messages have chance to be garbage collected.",Improvement,4,Closed,6,Fixed,2012-08-09 15:26:55,2012-03-22 08:14:09,2013-02-13T15:46:36.000+0000,hustlmsp,Sijie Guo,hustlmsp,"currently, hub server write entries to only one ledger, if a topic doesn't change ownership, all entries will be added to this ledger. so those consumed messages don't have chance to be garbage collected.",2012-03-22 08:14:09,2012-08-09 15:26:55
BOOKKEEPER-192,Hub server should try to close ledgers when releasing topic or shutting down server,Sub-task,7,Resolved,5,Won't Do,2017-10-09 09:53:35,2012-03-22 08:16:58,2017-10-09T09:53:35.000+0000,lvfangmin,Fangmin Lv,lvfangmin,"currently, hub server doesn't close ledgers when releasing topic ownership or shutting down server. so the ledgers need to be recovered when the topic is acquired again, which introduce latency to acquire topic.",2012-03-22 08:16:58,2017-10-09 09:53:35
BOOKKEEPER-193,Ledger is garbage collected by mistake.,Bug,1,Closed,6,Fixed,2012-03-31 07:37:02,2012-03-26 02:52:51,2012-10-22T14:50:16.000+0000,hustlmsp,Sijie Guo,hustlmsp,"currently, we encountered such case: ledger is garbage collected by mistake, and following requests would fail due to NoLedgerException.

{code}
2012-03-23 19:10:47,403 - INFO  [GarbageCollectorThread:GarbageCollectorThread@234] - Garbage collecting deleted ledger index files.

2012-03-23 19:10:48,702 - INFO  [GarbageCollectorThread:LedgerCache@544] - Deleting ledgerId: 89408
2012-03-23 19:10:48,703 - INFO  [GarbageCollectorThread:LedgerCache@577] - Deleted ledger : 89408

2012-03-23 19:11:10,013 - ERROR [NIOServerFactory-3181:BookieServer@361] - Error writing 1@89408
org.apache.bookkeeper.bookie.Bookie$NoLedgerException: Ledger 89408 not found
        at org.apache.bookkeeper.bookie.LedgerCache.getFileInfo(LedgerCache.java:228)
        at org.apache.bookkeeper.bookie.LedgerCache.updatePage(LedgerCache.java:260)
        at org.apache.bookkeeper.bookie.LedgerCache.putEntryOffset(LedgerCache.java:158)
        at org.apache.bookkeeper.bookie.LedgerDescriptor.addEntry(LedgerDescriptor.java:135)
        at org.apache.bookkeeper.bookie.Bookie.addEntryInternal(Bookie.java:1059)
        at org.apache.bookkeeper.bookie.Bookie.addEntry(Bookie.java:1099)
        at org.apache.bookkeeper.proto.BookieServer.processPacket(BookieServer.java:357)
        at org.apache.bookkeeper.proto.NIOServerFactory$Cnxn.readRequest(NIOServerFactory.java:315)
        at org.apache.bookkeeper.proto.NIOServerFactory$Cnxn.doIO(NIOServerFactory.java:213)
        at org.apache.bookkeeper.proto.NIOServerFactory.run(NIOServerFactory.java:124)
{code}

",2012-03-26 02:52:51,2012-03-31 07:37:02
BOOKKEEPER-194,Get correct latency for addEntry operations for JMX.,Bug,1,Closed,6,Fixed,2012-03-29 13:42:59,2012-03-28 10:04:25,2012-10-22T14:50:16.000+0000,hustlmsp,Sijie Guo,hustlmsp,"currently we don't get the right latency value of add operations. we just compute the latency that entry added to entry log files, but the response sent back to clients only when entries are flushed to journals.
the right place to compute addEntry latency would be in the WriteCallback.",2012-03-28 10:04:25,2012-03-29 13:42:59
BOOKKEEPER-195,"HierarchicalLedgerManager doesn't consider idgen as a ""specialNode""",Bug,1,Closed,6,Fixed,2012-03-28 22:02:57,2012-03-28 20:10:48,2012-10-22T14:50:16.000+0000,ikelly,Ivan Kelly,ikelly,"From IRC: 

21:58 <johnnagro> 2012-03-28 05:15:19,669 - ERROR [main-EventThread:AbstractZkLedgerManager$2@105] - Error polling ZK for the available ledger nodes: 
21:58 <johnnagro> org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /ledgers/idgen/ID-0000106522
21:58 <johnnagro>         at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
21:58 <johnnagro>         at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
21:58 <johnnagro>         at org.apache.bookkeeper.meta.AbstractZkLedgerManager$2.processResult(AbstractZkLedgerManager.java:105)
21:58 <johnnagro>         at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:594)
21:58 <johnnagro>         at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:497)
21:58 <johnnagro> i will look for the gc one
21:59 <ivank> thats quite strange
22:00 <ivank> this occurred in the server?
22:02 <johnnagro> ah they may be related, this one has some GC stuff
22:02 <johnnagro> 012-03-24 09:17:34,419 - WARN  [GarbageCollectorThread:HierarchicalLedgerManager@376] - Exception during garbage collecting ledgers for idgen of /ledgers
22:02 <johnnagro> 2012-03-24 09:56:31,080 - ERROR [main-EventThread:AbstractZkLedgerManager$2@105] - Error polling ZK for the available ledger nodes: 
22:02 <johnnagro> org.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /ledgers/idgen/ID-0000037474
22:02 <johnnagro>         at org.apache.zookeeper.KeeperException.create(KeeperException.java:111)
22:02 <johnnagro>         at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
22:02 <johnnagro>         at org.apache.bookkeeper.meta.AbstractZkLedgerManager$2.processResult(AbstractZkLedgerManager.java:105)
22:02 <johnnagro>         at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:594)
22:02 <johnnagro>         at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:497)
22:02 <johnnagro> this happened on the server, yes.


Looking into the code, it seems that HierarchicalLedgerManager doesn't consider idgen to be special. This is a race, between the idgen node being created and the znodes underneath being listed. The znodes underneath should never be listed.",2012-03-28 20:10:48,2012-03-28 22:02:57
BOOKKEEPER-196,Define interface between bookie and ledger storage,Improvement,4,Closed,6,Fixed,2012-04-17 10:30:16,2012-03-29 15:03:38,2012-10-22T14:50:14.000+0000,ikelly,Ivan Kelly,ikelly,"EntryLogger and LedgerCache are both part of a very interdependent storage mechanism where entries are interleaved in a single log(EntryLogger) and index files are maintained (LedgerCache). I'd like to experiment with some other schemes (Im not convinced the interleaving is required for high performance). ZOOKEEPER-507 brought in these changes, but it also brought in a lot of other stuff, and I think its the other stuff (specifically taking the writing to separate files out of the critical path) which gave us the performance boost. To do this cleanly, we need a well defined storage interface for this. This JIRA is to provide this. Future work can move the interleaved implementation into another package as org.apache.bookkeeper.bookie is getting a little crowded now.",2012-03-29 15:03:38,2012-04-17 10:30:16
BOOKKEEPER-197,HedwigConsole uses the same file to load bookkeeper client config and hub server config,Bug,1,Closed,6,Fixed,2012-04-16 02:57:27,2012-03-30 00:38:41,2012-10-22T14:50:14.000+0000,hustlmsp,Sijie Guo,hustlmsp,"In the current implementation of HedwigConsole.java, The same server-cfg file (default = hedwig-server/conf/hw_server.conf) is used to load both hubServerConf and bkClientConf. This seems incorrect because both have different option names. ",2012-03-30 00:38:41,2012-04-16 02:57:27
BOOKKEEPER-198,replaying entries of deleted ledgers would exhaust ledger cache.,Bug,1,Closed,6,Fixed,2012-03-31 08:31:40,2012-03-30 07:57:34,2012-10-22T14:50:16.000+0000,hustlmsp,Sijie Guo,hustlmsp,"we found that replaying entries of deleted ledgers would exhaust ledger cache. then ledger cache would no clean page to grab, it would throw following exception.

{code}
java.util.NoSuchElementException
        at java.util.LinkedList.getFirst(LinkedList.java:109)
        at org.apache.bookkeeper.bookie.LedgerCacheImpl.grabCleanPage(LedgerCacheImpl.java:454)
        at org.apache.bookkeeper.bookie.LedgerCacheImpl.putEntryOffset(LedgerCacheImpl.java:165)
{code}

this issue is because bookie grabs a clean page but fail to updating page due to NoLedgerException, but bookie doesn't return this clean page back to ledger cache. so the ledger cache is exhausted, when new ledger want to grab a clean page, it failed to find available page.",2012-03-30 07:57:34,2012-03-31 08:31:40
BOOKKEEPER-199,"Provide bookie readonly mode, when journal/ledgers flushing has failed with IOE",Bug,1,Resolved,5,Implemented,2012-12-04 14:49:08,2012-03-30 12:18:28,2013-05-02T02:29:58.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"Bookkeeper should change to readonly(r-o) mode when the journal/ledgers flushing has failed with IOException. Later on, reject write requests on server side and will accept only the read requests from the clients, because even if flushing fails, the data in the bookie which has been flushed is still valid.",2012-03-30 12:18:28,2012-12-04 14:49:08
BOOKKEEPER-200,Fix format and comments,Improvement,4,Closed,6,Fixed,2012-04-10 23:06:23,2012-03-31 14:37:59,2012-10-22T14:50:16.000+0000,fpj,Flavio Paiva Junqueira,fpj,"Just small fixes of format and spelling in LedgerMetadata, LedgerHandle, and BookieRecoveryTest.",2012-03-31 14:37:59,2012-04-10 23:06:23
BOOKKEEPER-202,Collect bookie performance metrics,Improvement,4,Resolved,5,Done,2017-10-09 09:53:22,2012-03-31 14:46:34,2017-10-09T09:53:22.000+0000,,,,"As per a discussion with Ivan and Ben, we would like to collect two metrics related to the performance of bookies. The first one is overall average operation latency of each bookie. The second is the average latency of each disk in a bookie. ",2012-03-31 14:46:34,2017-10-09 09:53:22
BOOKKEEPER-203,improve ledger manager interface to remove zookeeper dependency on metadata operations.,Sub-task,7,Closed,6,Fixed,2012-06-19 10:40:57,2012-04-01 15:38:02,2014-07-10T14:55:50.000+0000,hustlmsp,Sijie Guo,hustlmsp,"we need to improve ledger manager interface to remove zookeeper dependency on metadata operations, so it is easy for us to implement a MetaStore based ledger manager.",2012-04-01 15:38:02,2012-06-19 10:40:57
BOOKKEEPER-204,"Provide a MetaStore interface, and a mock implementation.",Sub-task,7,Closed,6,Fixed,2012-11-09 16:14:43,2012-04-01 15:41:02,2013-02-13T15:46:53.000+0000,jiannan,Jiannan Wang,jiannan,"we need a MetaStore interface which easy for us to plugin different scalable k/v storage, such as HBase.",2012-04-01 15:41:02,2012-11-09 16:14:43
BOOKKEEPER-205,implement a MetaStore based ledger manager for bookkeeper client.,Sub-task,7,Closed,6,Fixed,2012-12-12 10:21:43,2012-04-01 15:44:28,2013-02-13T15:46:48.000+0000,jiannan,Jiannan Wang,jiannan,implement a MetaStore based ledger manager for bookkeeper client.,2012-04-01 15:44:28,2012-12-12 10:21:43
BOOKKEEPER-207,BenchBookie doesn't run correctly,Bug,1,Closed,6,Fixed,2012-04-03 16:03:45,2012-04-02 13:31:10,2012-10-22T14:50:18.000+0000,ikelly,Ivan Kelly,ikelly,"Bench bookie tests latency of addEntry to a single bookie. Currently it simply writes to a specified ledger id. If this ledger id doesn't exist in zookeeper, the ledger is GC'd from the bookie and errors occur in the bench.",2012-04-02 13:31:10,2012-04-03 16:03:45
BOOKKEEPER-208,Separate write quorum from ack quorum,New Feature,2,Closed,6,Fixed,2012-09-12 10:09:35,2012-04-04 15:34:46,2013-02-13T15:46:39.000+0000,ikelly,Ivan Kelly,ikelly,"There are use cases for bookkeeper that may require submitting add requests to a write set and returning upon receiving a confirmation from an ack set. The ack set must be a subset of the write set. An important special case is writing to all and returning upon hearing from a majority. Another important use case is avoiding *s* slow disks by writing to *f + s + 1* and returning upon receiving *f + 1* responses.

Currently, the write set and the ack set are the same for a ledger. Internal changes to support these cases include changes to LedgerHandle and PendingAddOp. We also need to add a call to the client API to accept different sizes for the write set and the ack set upon ledger creation.

It is also open for the discussion the need to implement a new distribution schedule. So far it looks like we can reuse the round robin implementation we currently have. We would need to implement a new one if, for example, the initial bookie of an add operation must be always the same.",2012-04-04 15:34:46,2012-09-12 10:09:35
BOOKKEEPER-209,Typo in ServerConfiguration for READAHEAD_ENABLED,Bug,1,Closed,6,Fixed,2012-05-15 10:29:05,2012-04-05 22:49:45,2012-10-22T14:50:15.000+0000,ikelly,Ivan Kelly,ikelly,"The variable READAHEAD_ENABLED in org.apache.hedwig.server.common.ServerConfiguration has a value ""readhead_enabled"" when it should be ""readahead_enabled"". There is an ""a"" missing. ",2012-04-05 22:49:45,2012-05-15 10:29:05
BOOKKEEPER-211,Bookie fails to to start,Bug,1,Closed,6,Fixed,2012-04-10 05:44:30,2012-04-06 11:44:12,2012-10-22T14:50:17.000+0000,hustlmsp,Sijie Guo,hustlmsp,"A number of times when I start a bookie with a clean state, it fails to start and I get the following exceptions:

{noformat}
2012-04-06 10:54:42,201 - ERROR [main:Bookie@348] - Error accessing cookie on disks
java.io.FileNotFoundException: *path*/current/VERSION (No such file or directory)
        at java.io.FileOutputStream.open(Native Method)
        at java.io.FileOutputStream.<init>(FileOutputStream.java:179)
        at java.io.FileOutputStream.<init>(FileOutputStream.java:131)
        at org.apache.bookkeeper.bookie.Cookie.writeToDirectory(Cookie.java:114)
        at org.apache.bookkeeper.bookie.Bookie.checkEnvironment(Bookie.java:337)
        at org.apache.bookkeeper.bookie.Bookie.<init>(Bookie.java:401)
        at org.apache.bookkeeper.proto.BookieServer.<init>(BookieServer.java:75)
        at org.apache.bookkeeper.proto.BookieServer.main(BookieServer.java:294)
2012-04-06 10:54:42,203 - ERROR [main:BookieServer@308] - Exception running bookie server :
org.apache.bookkeeper.bookie.BookieException$InvalidCookieException: java.io.FileNotFoundException: *path*/current/VERSION (No such file or directory)
        at org.apache.bookkeeper.bookie.Bookie.checkEnvironment(Bookie.java:349)
        at org.apache.bookkeeper.bookie.Bookie.<init>(Bookie.java:401)
        at org.apache.bookkeeper.proto.BookieServer.<init>(BookieServer.java:75)
        at org.apache.bookkeeper.proto.BookieServer.main(BookieServer.java:294)
Caused by: java.io.FileNotFoundException: *path*/current/VERSION (No such file or directory)
        at java.io.FileOutputStream.open(Native Method)
        at java.io.FileOutputStream.<init>(FileOutputStream.java:179)
        at java.io.FileOutputStream.<init>(FileOutputStream.java:131)
        at org.apache.bookkeeper.bookie.Cookie.writeToDirectory(Cookie.java:114)
        at org.apache.bookkeeper.bookie.Bookie.checkEnvironment(Bookie.java:337)

{noformat}",2012-04-06 11:44:12,2012-04-10 05:44:30
BOOKKEEPER-212,Bookie stops responding when creating and deleting many ledgers,Bug,1,Closed,6,Fixed,2012-04-09 09:44:34,2012-04-06 12:40:22,2012-10-22T14:50:14.000+0000,hustlmsp,Sijie Guo,hustlmsp,"I have written down a short app to try to reproduce one problematic case reported on the user list. The app does the following:

# It creates initially a number of ledgers, say 2000;
# Once it reaches 2000, for each new ledger it creates, it deletes the one at the head of the list;
# Before closing the ledger, it adds 5 entries of 1k, just to generate some traffic for any given ledger.

What I tried to achieve is to have thousands of active ledgers and delete new ledgers as I create new ones. I'll post a link to my test code later. 

At some point, one bookie stops responding. The bookie seems to be up, but it is not responsive. Looking at the logs, this is what I see:

{noformat}
2012-04-06 12:22:05,765 - INFO  [SyncThread:LedgerCacheImpl@682] - Ledger 1726 is evicted from file info cache.
2012-04-06 12:22:05,769 - INFO  [NIOServerFactory-3181:LedgerCacheImpl@682] - Ledger 1727 is evicted from file info cache.
2012-04-06 12:22:05,772 - INFO  [SyncThread:LedgerCacheImpl@682] - Ledger 1728 is evicted from file info cache.
2012-04-06 12:22:05,780 - INFO  [NIOServerFactory-3181:LedgerCacheImpl@682] - Ledger 1729 is evicted from file info cache.
2012-04-06 12:22:05,787 - INFO  [NIOServerFactory-3181:LedgerCacheImpl@682] - Ledger 1730 is evicted from file info cache.
2012-04-06 12:22:05,794 - INFO  [NIOServerFactory-3181:LedgerCacheImpl@682] - Ledger 1731 is evicted from file info cache.
2012-04-06 12:22:05,801 - INFO  [NIOServerFactory-3181:LedgerCacheImpl@682] - Ledger 1732 is evicted from file info cache.
2012-04-06 12:22:05,807 - INFO  [NIOServerFactory-3181:LedgerCacheImpl@682] - Ledger 1733 is evicted from file info cache.
2012-04-06 12:22:05,822 - INFO  [NIOServerFactory-3181:LedgerCacheImpl@682] - Ledger 1734 is evicted from file info cache.
2012-04-06 12:22:05,828 - INFO  [NIOServerFactory-3181:LedgerCacheImpl@682] - Ledger 1735 is evicted from file info cache.
2012-04-06 12:22:05,842 - INFO  [NIOServerFactory-3181:LedgerCacheImpl@682] - Ledger 1736 is evicted from file info cache.
2012-04-06 12:22:05,851 - INFO  [NIOServerFactory-3181:LedgerCacheImpl@682] - Ledger 1737 is evicted from file info cache.
2012-04-06 12:22:05,856 - INFO  [NIOServerFactory-3181:LedgerCacheImpl@682] - Ledger 1738 is evicted from file info cache.
2012-04-06 12:22:05,864 - INFO  [NIOServerFactory-3181:LedgerCacheImpl@682] - Ledger 1739 is evicted from file info cache.
2012-04-06 12:22:05,874 - INFO  [NIOServerFactory-3181:LedgerCacheImpl@682] - Ledger 1740 is evicted from file info cache.
2012-04-06 12:22:05,885 - INFO  [NIOServerFactory-3181:LedgerCacheImpl@682] - Ledger 1741 is evicted from file info cache.
2012-04-06 12:22:05,894 - INFO  [NIOServerFactory-3181:LedgerCacheImpl@682] - Ledger 1742 is evicted from file info cache.
2012-04-06 12:22:05,902 - INFO  [NIOServerFactory-3181:LedgerCacheImpl@682] - Ledger 1743 is evicted from file info cache.
2012-04-06 12:22:05,987 - INFO  [GarbageCollectorThread:LedgerCacheImpl@682] - Ledger 1744 is evicted from file info cache.
2012-04-06 12:22:05,987 - ERROR [GarbageCollectorThread:GarbageCollectorThread$1@244] - Exception when deleting the ledger index file on the Bookie: 
java.io.IOException: /home/fpj/bk/current/1/b/10b.idx not found
        at org.apache.bookkeeper.bookie.FileInfo.checkOpen(FileInfo.java:118)
        at org.apache.bookkeeper.bookie.FileInfo.close(FileInfo.java:194) 
        at org.apache.bookkeeper.bookie.LedgerCacheImpl.deleteLedger(LedgerCacheImpl.java:619) 
        at org.apache.bookkeeper.bookie.GarbageCollectorThread$1.gc(GarbageCollectorThread.java:242)
        at org.apache.bookkeeper.meta.AbstractZkLedgerManager.doGc(AbstractZkLedgerManager.java:274)
        at org.apache.bookkeeper.meta.FlatLedgerManager.garbageCollectLedgers(FlatLedgerManager.java:168)
        at org.apache.bookkeeper.bookie.GarbageCollectorThread.doGcLedgers(GarbageCollectorThread.java:237)
        at org.apache.bookkeeper.bookie.GarbageCollectorThread.run(GarbageCollectorThread.java:206) 
2012-04-06 12:22:05,987 - INFO  [GarbageCollectorThread:LedgerCacheImpl@682] - Ledger 1745 is evicted from file info cache.
{noformat}

There are lots of exceptions like that, but otherwise I don't see anything that could make the bookie unresponsive. I'll upload the logs as well.   ",2012-04-06 12:40:22,2012-04-09 09:44:34
BOOKKEEPER-213,PerChannelBookieClient calls the wrong errorOut function when encountering an exception,Bug,1,Closed,6,Fixed,2012-04-19 01:03:26,2012-04-06 18:58:50,2012-10-22T14:50:17.000+0000,i0exception,Aniruddha,i0exception,"In PerChannelBookieClient.java, addEntry calls errorOutReadKey on encountering an exception instead of errorOutAddKey. ",2012-04-06 18:58:50,2012-04-19 01:03:26
BOOKKEEPER-214,Throttling in NIOServerFactory is broken and potentially dangerous,Bug,1,Resolved,5,Won't Do,2017-10-09 09:53:12,2012-04-10 14:55:07,2017-10-09T09:53:12.000+0000,,,,"Throttling on the NIOServerFactory is broken. There is a variable outstandingRequests which is decremented when a request is completed, but is never incremented. If this value is greater than 2000, then no more requests are accepted. Once a bookie has received 2^31+2000 requests, the bookie will hang forever. This needs to be removed.",2012-04-10 14:55:07,2017-10-09 09:53:12
BOOKKEEPER-215,Deadlock occurs under high load,Bug,1,Closed,6,Fixed,2012-05-09 07:45:32,2012-04-11 05:16:04,2012-10-22T14:50:17.000+0000,hustlmsp,Sijie Guo,hustlmsp,"LedgerHandle uses a Semaphore(opCounterSem) with a default value of 5000 permits to implement throttling for outstanding requests. This is causing a deadlock under high load. What I've observed is the following - There are a fixed number of threads created by OrderedSafeExecutor(mainWorkerPool in BookKeeper) and this is used to execute operations by PerChannelBookieClient. Under high load, the bookies are not able to satisfy requests at the rate at which they are being generated. This exhausts all permits in the Semaphore and any further operations block on lh.opCounterSem.acquire(). In this scenario, if the connection to the bookies is shut down, channelDisconnected in PerChannelBookieClient tries to error out all outstanding entries. The errorOutReadKey and errorOutAddKey functions enqueue these operations in the same mainWorkerPool, all threads in which are blocked on acquire. So, handleBookieFailure is never executed and the server stops responding. 

Blocking operations in a fixed size thread pool doesn't sound quite right. Temporarily, I fixed this by having another ExecutorService for every PerChannelBookieClient and queuing the operations from the errorOut* functions in it, but this is just a quick fix. I feel that the server shouldn't rely on LedgerHandle to throttle connections, but do this itself. Any other ideas on how to fix this? I'd be happy to contribute a patch. ",2012-04-11 05:16:04,2012-05-09 07:45:32
BOOKKEEPER-216,Bookie doesn't exit with right exit code,Bug,1,Closed,6,Fixed,2012-04-16 14:12:33,2012-04-13 08:22:23,2012-10-22T14:50:15.000+0000,hustlmsp,Sijie Guo,hustlmsp,"there is typo in Bookie#shutdown. so it doesn't quit with right exit code when encountering exceptions.
{code}
    synchronized int shutdown(int exitCode) {
        try {
            if (running) { // avoid shutdown twice
                // the exitCode only set when first shutdown usually due to exception found
                this.exitCode = exitCode;
                // mark bookie as in shutting down progress
                shuttingdown = true;
                // shut down gc thread, which depends on zookeeper client
                // also compaction will write entries again to entry log file
                gcThread.shutdown();
                // Shutdown the ZK client
                if(zk != null) zk.close();
                this.interrupt();
                this.join();
                syncThread.shutdown();

                // Shutdown the EntryLogger which has the GarbageCollector Thread running
                entryLogger.shutdown();
                // close Ledger Manager
                ledgerManager.close();
                // setting running to false here, so watch thread in bookie server know it only after bookie shut down
                running = false;
            }    
        } catch (InterruptedException ie) {
            LOG.error(""Interrupted during shutting down bookie : "", ie); 
        }    
        return exitCode;
    }
{code}",2012-04-13 08:22:23,2012-04-16 14:12:33
BOOKKEEPER-217,NPE in hedwig client when enable DEBUG,Bug,1,Closed,6,Fixed,2012-04-24 17:42:26,2012-04-16 03:32:57,2012-10-22T14:50:18.000+0000,hustlmsp,Sijie Guo,hustlmsp,subscription options may be null. NPE may be thrown in debug message.,2012-04-16 03:32:57,2012-04-24 17:42:26
BOOKKEEPER-218,Provide journal manager to manage journal related operations,Improvement,4,Closed,6,Fixed,2012-04-17 11:16:58,2012-04-16 13:53:32,2012-10-22T14:50:15.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Currently we put all journal related operations in Bookie class. It would be better to provide a journal manager to provide journal related operations. It would make Bookie logic more clearly. 

Besides that, some admin tools like BOOKKEEPER-183 needs to provide could use JournalManager to read/check journal files directly.",2012-04-16 13:53:32,2012-04-17 11:16:58
BOOKKEEPER-219,Active Namenode shutdown after throwing 'java.io.IOException: BookKeeper error during close'.,Bug,1,Resolved,5,Invalid,2012-04-19 03:42:48,2012-04-18 06:42:03,2012-05-08T13:30:50.000+0000,,,,"scenario:

1. I am started Active namenode and backup namenode. 
2. write some file. 

Result:

ANN throwing following Error

{noformat} 
2012-04-18 10:46:04,001 WARN org.apache.bookkeeper.client.LedgerHandle: Conditional write failed: BADVERSION
2012-04-18 10:46:04,001 FATAL org.apache.hadoop.hdfs.server.namenode.FSEditLog: Error: finalize log segment 1, 8 failed for required journal (JournalAndStream(mgr=org.apache.hadoop.contrib.bkjournal.BookKeeperJournalManager@1ec3362f, stream=org.apache.hadoop.contrib.bkjournal.BookKeeperEditLogOutputStream@221a5770))
java.io.IOException: BookKeeper error during close
	at org.apache.hadoop.contrib.bkjournal.BookKeeperEditLogOutputStream.close(BookKeeperEditLogOutputStream.java:90)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet$JournalAndStream.closeStream(JournalSet.java:79)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet$2.apply(JournalSet.java:180)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.mapJournalsAndReportErrors(JournalSet.java:322)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.finalizeLogSegment(JournalSet.java:176)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.endCurrentLogSegment(FSEditLog.java:925)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.rollEditLog(FSEditLog.java:855)
	at org.apache.hadoop.hdfs.server.namenode.FSImage.rollEditLog(FSImage.java:971)
	at org.apache.hadoop.hdfs.server.namenode.FSNamesystem.rollEditLog(FSNamesystem.java:4092)
	at org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.rollEditLog(NameNodeRpcServer.java:714)
	at org.apache.hadoop.hdfs.protocolPB.NamenodeProtocolServerSideTranslatorPB.rollEditLog(NamenodeProtocolServerSideTranslatorPB.java:113)
	at org.apache.hadoop.hdfs.protocol.proto.NamenodeProtocolProtos$NamenodeProtocolService$2.callBlockingMethod(NamenodeProtocolProtos.java:8068)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:417)
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:891)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1661)
	at org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:1657)
	at java.security.AccessController.doPrivileged(Native Method)
	at javax.security.auth.Subject.doAs(Subject.java:396)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1205)
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:1655)
Caused by: org.apache.bookkeeper.client.BKException$ZKException
	at org.apache.bookkeeper.client.BKException.create(BKException.java:64)
	at org.apache.bookkeeper.client.LedgerHandle.close(LedgerHandle.java:216)
	at org.apache.hadoop.contrib.bkjournal.BookKeeperEditLogOutputStream.close(BookKeeperEditLogOutputStream.java:86)
	... 19 more
{noformat} 



BNN throwing following Error


{noformat} 
2012-04-18 10:39:09,421 ERROR org.apache.bookkeeper.client.PendingReadOp: Error: No such entry while reading entry: 1 ledgerId: 5 from bookie: /10.18.52.157:3183
2012-04-18 10:39:09,423 ERROR org.apache.bookkeeper.client.PendingReadOp: Error: No such entry while reading entry: 1 ledgerId: 5 from bookie: /10.18.52.157:3181
2012-04-18 10:39:09,457 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edits tailer failed to find any streams. Will try again later.
java.io.IOException: No ledger for fromTxnId -12344 found.
	at org.apache.hadoop.contrib.bkjournal.BookKeeperJournalManager.getInputStream(BookKeeperJournalManager.java:329)
	at org.apache.hadoop.hdfs.server.namenode.JournalSet.getInputStream(JournalSet.java:246)
	at org.apache.hadoop.hdfs.server.namenode.FSEditLog.selectInputStreams(FSEditLog.java:1100)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.doTailEdits(EditLogTailer.java:206)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer.access$700(EditLogTailer.java:59)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:318)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:276)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:293)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:504)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:289)

{noformat} 


",2012-04-18 06:42:03,2012-04-19 03:42:48
BOOKKEEPER-220,Managed Ledger proposal,New Feature,2,Resolved,5,Won't Do,2017-10-09 09:52:47,2012-04-20 01:45:35,2017-10-09T09:52:47.000+0000,mmerli,Matteo Merli,mmerli,"The ManagedLedger design is based on our need to manage a set of ledgers, with a single writer (at any point in time) and a set on consumers that read entries from it. 

The ManagedLedger also takes care of periodically closing ledgers to have a ""reasonable"" sized sets of ledgers that can individually deleted when no more needed.

I've put on github the interface proposal (along with an early WIP implementation)

http://github.com/merlimat/managed-ledger

",2012-04-20 01:45:35,2017-10-09 09:52:47
BOOKKEEPER-223,PendingReadOp tries to read all entries at once,Bug,1,Resolved,5,Won't Do,2017-06-22 00:28:26,2012-04-25 10:27:39,2017-06-22T00:28:26.000+0000,ikelly,Ivan Kelly,ikelly,"PendingReadOp tries to read all entries from the bookie ensemble at once, and fill an enumeration with what comes back. This is bad. If we have a ledger with millions of entries, and you try to read the whole thing, you're client will crap out. Of course you can get around this by only requesting a little bit at a time, but why doesn't the client do this for you, as we are effectively exposing a iterator interface anyhow?",2012-04-25 10:27:39,2017-06-22 00:28:26
BOOKKEEPER-224,Fix findbugs in bookkeeper-server component,Sub-task,7,Closed,6,Fixed,2012-05-10 12:49:57,2012-04-25 13:20:37,2012-10-22T14:50:16.000+0000,ikelly,Ivan Kelly,ikelly,fix Findbugs warnings for bookkeeper-server,2012-04-25 13:20:37,2012-05-10 12:49:57
BOOKKEEPER-226,Fix the performance related bugs.,Sub-task,7,Resolved,5,Invalid,2012-05-17 16:34:10,2012-04-25 15:46:21,2012-05-17T16:34:10.000+0000,,,,"There are around 12 issues reported by findbugs.
Lets clean all performance category of bugs here.",2012-04-25 15:46:21,2012-05-17 16:34:10
BOOKKEEPER-227,Add exclude-findbugs filter file for invalid findbugs.,Sub-task,7,Resolved,5,Invalid,2012-05-17 16:34:32,2012-04-25 15:49:21,2012-05-17T16:34:32.000+0000,,,,,2012-04-25 15:49:21,2012-05-17 16:34:32
BOOKKEEPER-228,Fix the bugs in BK benchmark,Sub-task,7,Closed,6,Fixed,2012-05-04 18:12:52,2012-04-25 16:13:26,2012-10-22T14:50:16.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,"There are 11 bugs reported by findbugs in BK bench. Lets cleanup.

[INFO] ****** FindBugsMojo executeFindbugs *******
[INFO] Temp File is E:\ZK-BK\bookkeeper-benchmark\target\findbugsTemp.xml
[INFO] Fork Value is true
     [java] Warnings generated: 11
[INFO] xmlOutput is false
[INFO] ------------------------------------------------------------------------
[INFO] BUILD SUCCESS",2012-04-25 16:13:26,2012-05-04 18:12:52
BOOKKEEPER-229,Deleted entry log files would be garbage collected again and again.,Bug,1,Closed,6,Fixed,2012-05-08 07:36:53,2012-04-26 07:22:23,2012-10-22T14:50:15.000+0000,hustlmsp,Sijie Guo,hustlmsp,"after BOOKKEEPER-188 is applied, extractMetaFromEntryLogs is moved from EntryLogger to GarbageCollectorThread with some changed.

Before BOOKKEEPER-188 is applied,  we just add the entryLogMeta to entryLogMetaMap only when we could extract the entry log file. If a log file is garbage collected, its entryLogMeta would not be put in the map.

{code}
-    protected Map<Long, EntryLogMetadata> extractMetaFromEntryLogs(Map<Long, EntryLogMetadata> entryLogMetaMap) throws IOException {
-        // Extract it for every entry log except for the current one.
-        // Entry Log ID's are just a long value that starts at 0 and increments
-        // by 1 when the log fills up and we roll to a new one.
-        long curLogId = logId;
-        for (long entryLogId = 0; entryLogId < curLogId; entryLogId++) {
-            // Comb the current entry log file if it has not already been extracted.
-            if (entryLogMetaMap.containsKey(entryLogId)) {
-                continue;
-            }
-            LOG.info(""Extracting entry log meta from entryLogId: "" + entryLogId);
-            EntryLogMetadata entryLogMeta = new EntryLogMetadata(entryLogId);
-            ExtractionScanner scanner = new ExtractionScanner(entryLogMeta);
-            // Read through the entry log file and extract the entry log meta
-            try {
-                scanEntryLog(entryLogId, scanner);
-                LOG.info(""Retrieved entry log meta data entryLogId: "" + entryLogId + "", meta: "" + entryLogMeta);
-                entryLogMetaMap.put(entryLogId, entryLogMeta);
-            } catch(IOException e) {
-              LOG.warn(""Premature exception when processing "" + entryLogId +
-                       ""recovery will take care of the problem"", e);
-            }
-
-        }
-        return entryLogMetaMap;
-    }
{code}

But after BOOKKEEPER-188 is applied,  an empty entryLogMeta would be put into entryLogMetaMap for those deleted entry log files. So GarbageCollectorThread would gc those deleted entry log files again. Then there is lots of such kind of error messages, these are noise error message but doesn't affect the logic.

{code}
+    protected Map<Long, EntryLogMetadata> extractMetaFromEntryLogs(Map<Long, EntryLogMetadata> entryLogMetaMap)
+            throws IOException {
+        // Extract it for every entry log except for the current one.
+        // Entry Log ID's are just a long value that starts at 0 and increments
+        // by 1 when the log fills up and we roll to a new one.
+        long curLogId = entryLogger.logId;
+        for (long entryLogId = 0; entryLogId < curLogId; entryLogId++) {
+            // Comb the current entry log file if it has not already been extracted.
+            if (entryLogMetaMap.containsKey(entryLogId)) {
+                continue;
+            }
+            LOG.info(""Extracting entry log meta from entryLogId: "" + entryLogId);
+
+            // Read through the entry log file and extract the entry log meta
+            entryLogMetaMap.put(entryLogId,
+                                extractMetaFromEntryLog(entryLogger, entryLogId));
+        }
+        return entryLogMetaMap;
+    }
+
+    static EntryLogMetadata extractMetaFromEntryLog(EntryLogger entryLogger, long entryLogId)
+            throws IOException {
+        EntryLogMetadata entryLogMeta = new EntryLogMetadata(entryLogId);
+        ExtractionScanner scanner = new ExtractionScanner(entryLogMeta);
+        try {
+            // Read through the entry log file and extract the entry log meta
+            entryLogger.scanEntryLog(entryLogId, scanner);
+            LOG.info(""Retrieved entry log meta data entryLogId: ""
+                     + entryLogId + "", meta: "" + entryLogMeta);
+        } catch(IOException e) {
+            LOG.warn(""Premature exception when processing "" + entryLogId +
+                     ""recovery will take care of the problem"", e);
+        }
+
+        return entryLogMeta;
+    }
{code}",2012-04-26 07:22:23,2012-05-08 07:36:53
BOOKKEEPER-231, ZKUtil.killServer not closing the FileTxnSnapLog from ZK.,Bug,1,Closed,6,Fixed,2012-04-28 09:11:57,2012-04-28 04:50:00,2012-10-22T14:50:19.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,"Trace:
java.io.IOException: Unable to delete file: C:\Users\uma\AppData\Local\Temp\zookeeper5673563636069246854test\version-2\log.1
	at org.apache.commons.io.FileUtils.forceDelete(FileUtils.java:1919)
	at org.apache.commons.io.FileUtils.cleanDirectory(FileUtils.java:1399)
	at org.apache.commons.io.FileUtils.deleteDirectory(FileUtils.java:1331)
	at org.apache.commons.io.FileUtils.forceDelete(FileUtils.java:1910)
	at org.apache.commons.io.FileUtils.cleanDirectory(FileUtils.java:1399)
	at org.apache.commons.io.FileUtils.deleteDirectory(FileUtils.java:1331)
	at org.apache.bookkeeper.test.ZooKeeperUtil.killServer(ZooKeeperUtil.java:131)
	at org.apache.bookkeeper.bookie.CookieTest.tearDownZooKeeper(CookieTest.java:59)

When I ran the tests, I found the above trace and all tests were failing.",2012-04-28 04:50:00,2012-04-28 09:11:57
BOOKKEEPER-232,AsyncBK tests failing ,Bug,1,Closed,6,Fixed,2012-05-07 16:48:37,2012-04-29 06:26:22,2012-10-22T14:50:14.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,"
Trace:
java.io.IOException: Unable to delete file: C:\Users\uma\AppData\Local\Temp\bookie7010257841258186070test\current\136fcc63892.txn
	at org.apache.commons.io.FileUtils.forceDelete(FileUtils.java:1919)
	at org.apache.commons.io.FileUtils.cleanDirectory(FileUtils.java:1399)
	at org.apache.commons.io.FileUtils.deleteDirectory(FileUtils.java:1331)
	at org.apache.commons.io.FileUtils.forceDelete(FileUtils.java:1910)
	at org.apache.commons.io.FileUtils.cleanDirectory(FileUtils.java:1399)
	at org.apache.commons.io.FileUtils.deleteDirectory(FileUtils.java:1331)
	at org.apache.bookkeeper.test.BookKeeperClusterTestCase.stopBKCluster(BookKeeperClusterTestCase.java:150)
	at org.apache.bookkeeper.test.BookKeeperClusterTestCase.tearDown(BookKeeperClusterTestCase.java:94)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	",2012-04-29 06:26:22,2012-05-07 16:48:37
BOOKKEEPER-233,BookieFailureTest#testBookieRecovery  failing,Bug,1,Resolved,5,Fixed,2012-07-26 06:26:21,2012-04-29 10:26:26,2012-07-26T14:47:23.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,"Even tough i corrected the problem of BOOKKEEPER-232, still this tests failing with the similar problem.
But the cause would be different. Let me dig into it.",2012-04-29 10:26:26,2012-07-26 06:26:21
BOOKKEEPER-234,"EntryLogger will throw NPE, if any dir does not exist or IO Errors.",Bug,1,Closed,6,Fixed,2012-05-09 08:52:38,2012-05-03 12:53:57,2012-10-22T14:50:19.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,"I think, Entry log should check the exitance of directories, before going to get the last Log entries. Because, listFiles will retunr null on non existant directories or any IO Errors. We have to add the check for directory existnace check and null checks in side getLastLogID api in EntryLogger.

We may need to handle in LedgerCacheImpl also.

Do we need to add them in bad disks list? and others will refer this list before they use the dirs.",2012-05-03 12:53:57,2012-05-09 08:52:38
BOOKKEEPER-235,Bad syncing in entrylogger degrades performance for many concurrent ledgers,Bug,1,Closed,6,Fixed,2012-05-09 11:01:13,2012-05-03 15:24:11,2012-10-22T14:50:19.000+0000,ikelly,Ivan Kelly,ikelly,"EntryLogger flush syncs on the wrong object, which really hurts performance.",2012-05-03 15:24:11,2012-05-09 11:01:13
BOOKKEEPER-236,Benchmarking improvements from latest round of benchmarking,Improvement,4,Closed,6,Fixed,2012-05-09 11:23:01,2012-05-04 12:06:00,2012-10-22T14:50:18.000+0000,ikelly,Ivan Kelly,ikelly,Improvements to the benchmark harnesses from the latest round of benchmarking which we have done.,2012-05-04 12:06:00,2012-05-09 11:23:01
BOOKKEEPER-237,Automatic recovery of under-replicated ledgers and its entries,New Feature,2,Resolved,5,Implemented,2013-01-04 11:59:50,2012-05-04 12:37:01,2013-01-14T14:23:11.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"As per the current design of BookKeeper, if one of the BookKeeper server dies, there is no automatic mechanism to identify and recover the under replicated ledgers and its corresponding entries. This would lead to losing the successfully written entries, which will be a critical problem in sensitive systems. This document is trying to describe few proposals to overcome these limitations. ",2012-05-04 12:37:01,2013-01-04 11:59:50
BOOKKEEPER-238,Add log4j.properties in conf/ for bin packages,Improvement,4,Closed,6,Fixed,2012-05-17 16:38:44,2012-05-07 09:17:21,2012-10-22T14:50:19.000+0000,ikelly,Ivan Kelly,ikelly,Add log4j for bin packages to make it easier for users to turn on logging.,2012-05-07 09:17:21,2012-05-17 16:38:44
BOOKKEEPER-239,Deadlock in ledger recovery when there is limited permits,Bug,1,Resolved,5,Invalid,2013-01-12 07:19:11,2012-05-07 13:25:59,2013-01-12T07:19:11.000+0000,,,,"per discussion in BOOKKEEPER-215, it would be better to revisit throttle mechanism currently used in bookkeeper client to avoid deadlock in ledger recovery.",2012-05-07 13:25:59,2013-01-12 07:19:11
BOOKKEEPER-240,Need a deadlock checking mechanism to avoid deadlock,Improvement,4,Resolved,5,Won't Do,2017-10-09 09:52:20,2012-05-07 13:27:34,2017-10-09T09:52:20.000+0000,,,,"per discussion on BOOKKEEPER-215, we need a deadlock checking mechanism.",2012-05-07 13:27:34,2017-10-09 09:52:20
BOOKKEEPER-243,BK JM : After restart bookkeeper continuously throwing error because BK JM create all Namenode related znode under '/ledgers' znode.,Improvement,4,Resolved,5,Won't Do,2017-10-09 09:51:51,2012-05-08 06:10:17,2017-10-09T09:51:51.000+0000,,,,"Issue :

Bookkeeper journal manager create all the Namenode related znode under '/ledgers' znode in zookeeper. When bookkeeper read all the ledgers from  '/ledgers' znode it consider this znode (version, lock, maxtxid)  as incorrect format ledger and log following error.

{noformat}
2012-04-20 11:52:25,611 - WARN  [main-EventThread:AbstractZkLedgerManager$2@123] - Error extracting ledgerId from ZK ledger node: ledgers
2012-04-20 11:52:25,611 - WARN  [main-EventThread:AbstractZkLedgerManager$2@123] - Error extracting ledgerId from ZK ledger node: lock
2012-04-20 11:52:25,612 - WARN  [main-EventThread:AbstractZkLedgerManager$2@123] - Error extracting ledgerId from ZK ledger node: maxtxid
2012-04-20 11:52:26,613 - WARN  [main-EventThread:AbstractZkLedgerManager$2@123] - Error extracting ledgerId from ZK ledger node: version
2012-04-20 11:52:26,613 - WARN  [main-EventThread:AbstractZkLedgerManager$2@123] - Error extracting ledgerId from ZK ledger node: ledgers
2012-04-20 11:52:26,613 - WARN  [main-EventThread:AbstractZkLedgerManager$2@123] - Error extracting ledgerId from ZK ledger node: lock
2012-04-20 11:52:26,613 - WARN  [main-EventThread:AbstractZkLedgerManager$2@123] - Error extracting ledgerId from ZK ledger node: maxtxid
2012-04-20 11:52:27,614 - WARN  [main-EventThread:AbstractZkLedgerManager$2@123] - Error extracting ledgerId from ZK ledger node: version
2012-04-20 11:52:27,614 - WARN  [main-EventThread:AbstractZkLedgerManager$2@123] - Error extracting ledgerId from ZK ledger node: ledgers
2012-04-20 11:52:27,614 - WARN  [main-EventThread:AbstractZkLedgerManager$2@123] - Error extracting ledgerId from ZK ledger node: lock
2012-04-20 11:52:27,615 - WARN  [main-EventThread:AbstractZkLedgerManager$2@123] - Error extracting ledgerId from ZK ledger node: maxtxid
2012-04-20 11:52:28,616 - WARN  [main-EventThread:AbstractZkLedgerManager$2@123] - Error extracting ledgerId from ZK ledger node: version
2012-04-20 11:52:28,616 - WARN  [main-EventThread:AbstractZkLedgerManager$2@123] - Error extracting ledgerId from ZK ledger node: ledgers


{noformat}

I think Namenode related znode should be create in separate znode in zookeeper.

",2012-05-08 06:10:17,2017-10-09 09:51:51
BOOKKEEPER-241,Add documentation for bookie entry log compaction,Task,3,Closed,6,Fixed,2012-05-09 07:17:08,2012-05-08 07:46:02,2012-10-22T14:50:14.000+0000,hustlmsp,Sijie Guo,hustlmsp,,2012-05-08 07:46:02,2012-05-09 07:17:08
BOOKKEEPER-242,Bookkeeper not able to connect other zookeeper when shutdown the zookeeper server where the BK has connected.,Bug,1,Closed,6,Fixed,2012-05-09 08:18:43,2012-05-08 09:50:28,2012-10-22T14:50:15.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Scenario : 
1. Start three zookeeper cluster.
2. start three bookKeeper.
3. shutdown zookeeper server where bookkeeper has connected.

Expected Result:
bookkeeper should be able to connect other zookeeper

Actual Result :
All three bookkeepers retry to connect zookeeper node which has been shutdown.



BookKeeper log for Retry :

{noformat} 
2012-04-25 13:35:15,319 - WARN  [main-EventThread:Bookie$2@456] - ZK client has been disconnected to the ZK server!
2012-04-25 13:35:17,194 - INFO  [main-SendThread(HOST-10-18-40-91:2181):ClientCnxn$SendThread@933] - Opening socket connection to server HOST-10-18-40-91/10.18.40.91:2181
2012-04-25 13:35:17,196 - WARN  [main-SendThread(HOST-10-18-40-91:2181):ClientCnxn$SendThread@1063] - Session 0x136e87b50ce0002 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:264)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1041)
2012-04-25 13:35:19,125 - INFO  [main-SendThread(HOST-10-18-40-91:2181):ClientCnxn$SendThread@933] - Opening socket connection to server HOST-10-18-40-91/10.18.40.91:2181
2012-04-25 13:35:19,126 - WARN  [main-SendThread(HOST-10-18-40-91:2181):ClientCnxn$SendThread@1063] - Session 0x136e87b50ce0002 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:264)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1041)
2012-04-25 13:35:20,276 - INFO  [main-SendThread(HOST-10-18-40-91:2181):ClientCnxn$SendThread@933] - Opening socket connection to server HOST-10-18-40-91/10.18.40.91:2181
2012-04-25 13:35:20,277 - WARN  [main-SendThread(HOST-10-18-40-91:2181):ClientCnxn$SendThread@1063] - Session 0x136e87b50ce0002 for server null, unexpected error, closing socket connection and attempting reconnect
java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:567)
	at org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:264)
	at org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1041)

{noformat} ",2012-05-08 09:50:28,2012-05-09 08:18:43
BOOKKEEPER-245,Intermittent failures in PersistanceManager tests,Bug,1,Closed,6,Fixed,2012-05-10 09:58:10,2012-05-09 10:55:32,2012-10-22T14:50:18.000+0000,ikelly,Ivan Kelly,ikelly,"TestLocalDBPersistenceManagerBlackBox sometimes fails[1]. As does TestBookKeeperPersistenceManagerWhiteBox[2].

[1] https://builds.apache.org/job/bookkeeper-trunk/481/
[2] https://builds.apache.org/job/bookkeeper-trunk/498/",2012-05-09 10:55:32,2012-05-10 09:58:10
BOOKKEEPER-246,Recording of underreplication of ledger entries,Sub-task,7,Closed,6,Fixed,2012-08-14 09:42:08,2012-05-09 15:08:49,2013-05-02T02:29:53.000+0000,ikelly,Ivan Kelly,ikelly,"This JIRA is to decide how to record that entries in a ledger are underreplicated. 

I think there is a common understanding (correct me if im wrong), that rereplication can be broken into two logically distinct phases. A) Detection of entry underreplication & B) Rereplication. 

This subtask is to handle the interaction between these two stages. Stage B needs to know what to rereplicate; how should Stage A inform it?",2012-05-09 15:08:49,2012-08-14 09:42:08
BOOKKEEPER-247,Detection of under replication,Sub-task,7,Closed,6,Fixed,2012-08-17 10:42:41,2012-05-09 15:13:42,2013-02-13T15:46:44.000+0000,ikelly,Ivan Kelly,ikelly,This JIRA discusses how the bookkeeper system will detect underreplication of ledger entries.,2012-05-09 15:13:42,2012-08-17 10:42:41
BOOKKEEPER-248,Rereplicating of under replicated data,Sub-task,7,Closed,6,Fixed,2012-08-24 20:45:29,2012-05-09 15:14:07,2013-02-13T15:46:48.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,This subtask discusses how we will rereplicate underreplicated entries.,2012-05-09 15:14:07,2012-08-24 20:45:29
BOOKKEEPER-249,Revisit garbage collection algorithm in Bookie server,Improvement,4,Resolved,5,Won't Do,2017-10-09 09:51:25,2012-05-10 00:52:57,2017-10-09T09:51:25.000+0000,,,,"Per discussion in BOOKKEEPER-181, it would be better to revisit garbage collection algorithm in bookie server. so create a subtask to focus on it.",2012-05-10 00:52:57,2017-10-09 09:51:25
BOOKKEEPER-250,Need a ledger manager like interface to manage metadata operations in Hedwig,Sub-task,7,Closed,6,Fixed,2012-07-11 17:12:03,2012-05-10 01:00:13,2013-05-02T02:29:53.000+0000,hustlmsp,Sijie Guo,hustlmsp,"it would be better to a ledger-manager like interface to manage metadata operations in Hedwig, which might be easy for use to adapt to meta store api.",2012-05-10 01:00:13,2012-07-11 17:12:03
BOOKKEEPER-251,Noise error message printed when scanning entry log files those have been garbage collected.,Improvement,4,Closed,6,Fixed,2012-05-17 17:11:55,2012-05-10 05:47:05,2012-10-22T14:50:15.000+0000,hustlmsp,Sijie Guo,hustlmsp,"currently, due to the messy scan mechanism deployed by garbage collector thread. following noise error message would be printed when scanning those entry log files has been garbage collected.

{quote}
2012-05-09 15:58:52,742 - INFO  [GarbageCollectorThread:GarbageCollectorThread@466] - Extracting entry log meta from entryLogId: 0
2012-05-09 15:58:52,743 - WARN  [GarbageCollectorThread:EntryLogger@386] - Failed to get channel to scan entry log: 0.log
2012-05-09 15:58:52,743 - WARN  [GarbageCollectorThread:GarbageCollectorThread@473] - Premature exception when processing 0recovery will take care of the problem
java.io.FileNotFoundException: No file for log 0
        at org.apache.bookkeeper.bookie.EntryLogger.findFile(EntryLogger.java:366)
        at org.apache.bookkeeper.bookie.EntryLogger.getChannelForLogId(EntryLogger.java:340)
        at org.apache.bookkeeper.bookie.EntryLogger.scanEntryLog(EntryLogger.java:384)
        at org.apache.bookkeeper.bookie.GarbageCollectorThread.extractMetaFromEntryLog(GarbageCollectorThread.java:485)
        at org.apache.bookkeeper.bookie.GarbageCollectorThread.extractMetaFromEntryLogs(GarbageCollectorThread.java:470)
        at org.apache.bookkeeper.bookie.GarbageCollectorThread.run(GarbageCollectorThread.java:189)
{quote}",2012-05-10 05:47:05,2012-05-17 17:11:55
BOOKKEEPER-252,Hedwig: provide a subscription mode to kill other subscription channel when hedwig client is used as a proxy-style server.,New Feature,2,Closed,6,Fixed,2012-09-14 16:18:30,2012-05-10 08:19:25,2013-02-13T15:46:30.000+0000,hustlmsp,Sijie Guo,hustlmsp,"In some case, we need to hedwig-client as proxy server to provide messaging service to other users.

client -> proxy server 1 -> hedwig
       \> proxy server 2 />

when client would connect to either proxy server to receive messages, the proxy server would setup subscription channel to hedwig server.

we just want client to be simple, so when the channel between client and proxy server is broken, client will try to connect to proxy servers thru VIP. it might connect to other proxy server. for example, first time client connects to proxy server 1, but the client found the connection is broken, it connects to proxy server 2. when proxy server 2 tried to setup subscription channel to hedwig, hedwig found that this subscription has existed before occupied by proxy server 1.

the panic here is that proxy server 1 only disconnect old subscription channel only when it detected the channel between client and itself is broken. The detection might be delayed due to several reasons. so it might increment the latency that messages are pushed to real client.

so we try to introduce a subscription mode called CREATE_OR_ATTACH_OR_KILL mode.

when a subscriber use this subscription mode, it would kill old existed subscription channel. when using this subscription mode, we would turn off auto-reconnect functionality in hedwig client and just tell client about the channel disconnected event so client could do its logic when channel is detected.

in order to provide some admin tool for admin guys to debug/operate, we provide ADMIN mode. if a subscriber attach to a subscription using ADMIN mode, its subscription channel would never be killed, then it is safe to guarantee admin operations.


 ",2012-05-10 08:19:25,2012-09-14 16:18:30
BOOKKEEPER-254,Bump zookeeper version in poms,Improvement,4,Closed,6,Fixed,2012-05-17 15:57:53,2012-05-10 13:08:37,2012-10-22T14:50:18.000+0000,ikelly,Ivan Kelly,ikelly,"We use zookeeper 3.4.0, in which there are serverside errors, so as a whole it's not recommended for use. We should use 3.4.x where x is the latest bug release.",2012-05-10 13:08:37,2012-05-17 15:57:53
BOOKKEEPER-257,Ability to list all ledgers,New Feature,2,Resolved,5,Fixed,2013-07-03 14:53:53,2012-05-14 15:27:48,2013-07-03T14:53:54.000+0000,fpj,Flavio Paiva Junqueira,fpj,"When an application is using bookkeeper it must keep a copy of the ledger ids it creates so that they can be used later, and once they are no longer useful, deleted. However, in the case of a crash between ledger creation and persisting the application copy of the id, the ledger will be dangling. Therefore I propose we have the ability to get a list of all ledger ids, which clients can use for garbage collection. However, I don't think it should be part of the BookKeeper class, rather part of a new BookKeeperAdmin class.",2012-05-14 15:27:48,2013-07-03 14:53:53
BOOKKEEPER-258,CompactionTest failed,Bug,1,Closed,6,Fixed,2012-05-26 17:17:46,2012-05-14 23:11:52,2012-10-22T14:50:18.000+0000,ikelly,Ivan Kelly,ikelly,"{noformat}
-------------------------------------------------------------------------------
Test set: org.apache.bookkeeper.bookie.CompactionTest
-------------------------------------------------------------------------------
Tests run: 5, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 32.557 sec <<< FAILURE!
testCompactionSmallEntryLogs(org.apache.bookkeeper.bookie.CompactionTest)  Time elapsed: 6.507 sec  <<< ERROR!
org.apache.bookkeeper.client.BKException$BKBookieHandleNotAvailableException
        at org.apache.bookkeeper.client.BKException.create(BKException.java:62)
        at org.apache.bookkeeper.client.LedgerHandle.readEntries(LedgerHandle.java:347)
        at org.apache.bookkeeper.bookie.CompactionTest.verifyLedger(CompactionTest.java:128)
        at org.apache.bookkeeper.bookie.CompactionTest.testCompactionSmallEntryLogs(CompactionTest.java:317)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at junit.framework.TestCase.runTest(TestCase.java:168)
        at junit.framework.TestCase.runBare(TestCase.java:134)
        at junit.framework.TestResult$1.protect(TestResult.java:110)
        at junit.framework.TestResult.runProtected(TestResult.java:128)
        at junit.framework.TestResult.run(TestResult.java:113)
        at junit.framework.TestCase.run(TestCase.java:124)
        at junit.framework.TestSuite.runTest(TestSuite.java:232)
        at junit.framework.TestSuite.run(TestSuite.java:227)
        at org.junit.internal.runners.JUnit38ClassRunner.run(JUnit38ClassRunner.java:83)
        at org.apache.maven.surefire.junit4.JUnit4TestSet.execute(JUnit4TestSet.java:53)
        at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:123)
        at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:104)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
        at java.lang.reflect.Method.invoke(Method.java:597)
        at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164)
        at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110)
        at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:172)
        at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcessWhenForked(SurefireStarter.java:78)
        at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:70)

{noformat}",2012-05-14 23:11:52,2012-05-26 17:17:46
BOOKKEEPER-259,Create a topic manager using versioned write for leader election,Sub-task,7,Closed,6,Fixed,2012-08-06 11:02:15,2012-05-15 03:10:55,2013-05-02T02:29:53.000+0000,hustlmsp,Sijie Guo,hustlmsp,"currently, ZkTopicManager use zookeeper ephemeral node to store the owner information of a topic. so the znode will disappear when the owner hub server is down, the leader election is quite simple based on this model.

but for most key-value storage, there is no similar concepts like ephemeral node, but just providing versioned writes. so it would be better to provide a topic manager using versioned writes.",2012-05-15 03:10:55,2012-08-06 11:02:15
BOOKKEEPER-260,Define constant for -1 (invalid entry id),Bug,1,Closed,6,Fixed,2012-05-25 15:14:36,2012-05-15 14:34:25,2012-10-22T14:50:17.000+0000,ikelly,Ivan Kelly,ikelly,"We should define a constant for -1, as we use it all over the place to signify an invalid entry id. We should call it INVALID_ENTRY_ID or NO_ENTRY or something to the same affect.",2012-05-15 14:34:25,2012-05-25 15:14:36
BOOKKEEPER-262,Implement a meta store based hedwig metadata manager.,Sub-task,7,Closed,6,Fixed,2012-12-13 17:06:27,2012-05-16 07:30:35,2013-05-02T02:29:53.000+0000,jiannan,Jiannan Wang,jiannan,We had provided a metadata manager interface by BOOKKEEPER-250 & BOOKKEEPER-259. we need a metadata manager implementation use meta store API.,2012-05-16 07:30:35,2012-12-13 17:06:27
BOOKKEEPER-263,ZK ledgers root path is hard coded,Bug,1,Closed,6,Fixed,2012-05-24 05:13:39,2012-05-16 20:55:13,2012-10-22T14:50:15.000+0000,i0exception,Aniruddha,i0exception,Currently the ZK ledger root path is not picked up from the config file (It is hardcoded). This patch fixes this. ,2012-05-16 20:55:13,2012-05-24 05:13:39
BOOKKEEPER-265,Review JMX documentation,Sub-task,7,Closed,6,Fixed,2012-05-25 14:39:00,2012-05-22 14:33:22,2012-10-22T14:50:17.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Related jiras: BOOKKEEPER-77, BOOKKEEPER-95, BOOKKEEPER-96, BOOKKEEPER-97, BOOKKEEPER-98.",2012-05-22 14:33:22,2012-05-25 14:39:00
BOOKKEEPER-266,Review versioning documentation,Sub-task,7,Closed,6,Fixed,2012-05-25 13:31:22,2012-05-22 14:35:32,2012-10-22T14:50:19.000+0000,ikelly,Ivan Kelly,ikelly,Related jira: BOOKKEEPER-165,2012-05-22 14:35:32,2012-05-25 13:31:22
BOOKKEEPER-268,Implement Metadata plugin APIs for ZooKeeper,Improvement,4,Resolved,5,Done,2017-10-09 09:51:08,2012-05-23 00:16:13,2017-10-09T09:51:08.000+0000,,,,This is related to JIRA BookKeeper 181 (scaling BookKeeper metadata storage). We propose to implement an abstract metadata plugin API s.t. different implementation of metadata store can be used in BookKeeper. The first effort is trying to have ZooKeeper metadata plugin API implemented as 1) proof of concept; 2) backward compatibility.,2012-05-23 00:16:13,2017-10-09 09:51:08
BOOKKEEPER-269,Review documentation for hedwig console client,Sub-task,7,Closed,6,Fixed,2012-05-29 20:48:14,2012-05-25 15:17:40,2012-10-22T14:50:16.000+0000,hustlmsp,Sijie Guo,hustlmsp,Check BOOKKEEPER-77.,2012-05-25 15:17:40,2012-05-29 20:48:14
BOOKKEEPER-270,Review documentation on bookie cookie,Sub-task,7,Closed,6,Fixed,2012-05-29 21:03:21,2012-05-25 15:19:47,2012-10-22T14:50:16.000+0000,ikelly,Ivan Kelly,ikelly,Check BOOKKEEPER-163.,2012-05-25 15:19:47,2012-05-29 21:03:21
BOOKKEEPER-271,Review documentation for message bounding,Sub-task,7,Closed,6,Fixed,2012-05-29 21:13:00,2012-05-25 15:21:16,2012-10-22T14:50:13.000+0000,ikelly,Ivan Kelly,ikelly,Check BOOKKEEPER-168.,2012-05-25 15:21:16,2012-05-29 21:13:00
BOOKKEEPER-272,Provide automatic mechanism to know bookie failures,Sub-task,7,Closed,6,Fixed,2012-08-27 16:03:52,2012-05-26 09:07:26,2013-02-13T15:47:02.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"The idea is to build automatic mechanism to find out the bookie failures. Setup the bookie failure notifications to start the re-replication process.

There are multiple approaches to findout bookie failures. Please refer the documents attached in BookKeeper-237.",2012-05-26 09:07:26,2012-08-27 16:03:52
BOOKKEEPER-275,[Log Improvement]: Error logs logged at the time of switch which is misleading,Bug,1,Resolved,5,Won't Do,2017-10-09 09:50:28,2012-05-28 05:45:10,2017-10-09T09:50:28.000+0000,,,,"For every switch the following error is logged at NN side


2012-05-17 11:19:46,021 ERROR org.apache.bookkeeper.client.PendingReadOp: Error: No such entry while reading entry: 1 ledgerId: 16 from bookie: /XX.XX.XX.55:3182
2012-05-17 11:19:46,022 ERROR org.apache.bookkeeper.client.PendingReadOp: Error: No such entry while reading entry: 1 ledgerId: 16 from bookie: /XX.XX.XX.55:3183
2012-05-17 11:19:46,022 ERROR org.apache.bookkeeper.client.PendingReadOp: Error: No such entry while reading entry: 1 ledgerId: 16 from bookie: /XX.XX.XX.55:3181

{noformat}
2012-05-17 11:19:45,891 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Stopping services started for standby state
2012-05-17 11:19:45,893 WARN org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer: Edit log tailer interrupted
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.doWork(EditLogTailer.java:329)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.access$200(EditLogTailer.java:274)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread$1.run(EditLogTailer.java:291)
	at org.apache.hadoop.security.SecurityUtil.doAsLoginUserOrFatal(SecurityUtil.java:512)
	at org.apache.hadoop.hdfs.server.namenode.ha.EditLogTailer$EditLogTailerThread.run(EditLogTailer.java:287)
2012-05-17 11:19:45,895 INFO org.apache.bookkeeper.proto.PerChannelBookieClient: Disconnected from bookie: /XX.XX.XX.55:3182
2012-05-17 11:19:45,895 INFO org.apache.bookkeeper.proto.PerChannelBookieClient: Disconnected from bookie: /XX.XX.XX.55:3181
2012-05-17 11:19:45,913 INFO org.apache.zookeeper.ZooKeeper: Session: 0x1375944cf250027 closed
2012-05-17 11:19:45,913 INFO org.apache.zookeeper.ClientCnxn: EventThread shut down
2012-05-17 11:19:45,913 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Starting services required for active state
2012-05-17 11:19:45,913 INFO org.apache.zookeeper.ZooKeeper: Initiating client connection, connectString=XX.XX.XX.55:2182 sessionTimeout=3000 watcher=org.apache.hadoop.contrib.bkjournal.BookKeeperJournalManager$ZkConnectionWatcher@734d246
2012-05-17 11:19:45,914 INFO org.apache.zookeeper.ClientCnxn: Opening socket connection to server /XX.XX.XX.55:2182
2012-05-17 11:19:45,915 INFO org.apache.zookeeper.ClientCnxn: Socket connection established to HOST-10-18-52-55/XX.XX.XX.55:2182, initiating session
2012-05-17 11:19:45,947 INFO org.apache.zookeeper.ClientCnxn: Session establishment complete on server HOST-10-18-52-55/XX.XX.XX.55:2182, sessionid = 0x1375944cf250029, negotiated timeout = 4000
2012-05-17 11:19:45,994 INFO org.apache.bookkeeper.proto.PerChannelBookieClient: Successfully connected to bookie: /XX.XX.XX.55:3181
2012-05-17 11:19:45,996 INFO org.apache.bookkeeper.proto.PerChannelBookieClient: Successfully connected to bookie: /XX.XX.XX.55:3183
2012-05-17 11:19:46,001 INFO org.apache.bookkeeper.proto.PerChannelBookieClient: Successfully connected to bookie: /XX.XX.XX.55:3182
2012-05-17 11:19:46,021 ERROR org.apache.bookkeeper.client.PendingReadOp: Error: No such entry while reading entry: 1 ledgerId: 16 from bookie: /XX.XX.XX.55:3182
2012-05-17 11:19:46,022 ERROR org.apache.bookkeeper.client.PendingReadOp: Error: No such entry while reading entry: 1 ledgerId: 16 from bookie: /XX.XX.XX.55:3183
2012-05-17 11:19:46,022 ERROR org.apache.bookkeeper.client.PendingReadOp: Error: No such entry while reading entry: 1 ledgerId: 16 from bookie: /XX.XX.XX.55:3181
2012-05-17 11:19:46,045 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Recovering unfinalized segments in /home/May8/hadoop-3.0.0-SNAPSHOT/hadoop-root/dfs/name/current
2012-05-17 11:19:46,049 INFO org.apache.hadoop.hdfs.server.namenode.FileJournalManager: Finalizing edits file /home/May8/hadoop-3.0.0-SNAPSHOT/hadoop-root/dfs/name/current/edits_inprogress_0000000000000000036 -> /home/May8/hadoop-3.0.0-SNAPSHOT/hadoop-root/dfs/name/current/edits_0000000000000000036-0000000000000000036
2012-05-17 11:19:46,049 INFO org.apache.hadoop.hdfs.server.namenode.FSNamesystem: Catching up to latest edits from old active before taking over writer role in edits logs.
2012-05-17 11:19:46,077 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Reading org.apache.hadoop.contrib.bkjournal.BookKeeperEditLogInputStream@38f0b51d expecting start txid #37
2012-05-17 11:19:46,128 INFO org.apache.hadoop.hdfs.server.namenode.FSImage: Edits file BookKeeper[org.apache.bookkeeper.client.ReadOnlyLedgerHandle@615e7597,first=37,last=37] of size 13 edits # 1 loaded in 0 seconds.
{noformat}",2012-05-28 05:45:10,2017-10-09 09:50:28
BOOKKEEPER-273,LedgerHandle.deleteLedger() should be idempotent,Bug,1,Closed,6,Fixed,2012-05-30 15:14:01,2012-05-30 00:09:16,2012-10-22T14:50:15.000+0000,mmerli,Matteo Merli,mmerli,"Deleting a non-existing ledger should silently succeed. 

Current behavior is to raise a ZKException, but it's not possible to know whether there was some error or the ledger does not exists anymore. 

This scenario will happen when a previous deleteLedger() call succeeded but the client crashed before updating its own ledger list.",2012-05-30 00:09:16,2012-05-30 15:14:01
BOOKKEEPER-274,Hedwig cpp client library should not link to cppunit which is just used for test.,Bug,1,Closed,6,Fixed,2012-06-12 16:37:47,2012-05-30 06:51:26,2013-02-13T15:47:02.000+0000,hustlmsp,Sijie Guo,hustlmsp,,2012-05-30 06:51:26,2012-06-12 16:37:47
BOOKKEEPER-276,Add commandline options so that Hedwig console doesn't have to use config files,Bug,1,Resolved,5,Won't Do,2017-10-09 09:49:57,2012-05-30 15:25:17,2017-10-09T09:49:57.000+0000,,,,"Hedwig console currently requires a number of config files to find the cluster. Really it should be sufficient to give it a zookeeper server and let it go from there. Also, it would be good to be able to run hedwig console commands from the commandline. 
i.e. bin/hedwig console --zookeeper zk1:2181 show topics

",2012-05-30 15:25:17,2017-10-09 09:49:57
BOOKKEEPER-278,Ability to disable auto recovery temporarily,Sub-task,7,Closed,6,Fixed,2012-10-04 10:42:52,2012-05-30 15:31:05,2013-02-13T15:46:56.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"Administrators will need to do rolling upgrades of bookies. If auto recovery is enabled during a rolling upgrade, there will be a lot of thrashing of ledgers as they recovery gets kicked off. Therefore we need a way to temporarily disable it.

",2012-05-30 15:31:05,2012-10-04 10:42:52
BOOKKEEPER-279,LocalBookKeeper is failing intermittently due to zkclient connection establishment delay,Bug,1,Closed,6,Fixed,2012-06-05 06:57:08,2012-05-31 11:25:43,2013-01-14T16:11:48.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"LocalBookKeeper is initializing the zkclient and immediately trying to create ""/ledgers"" and ""/ledgers/available"" znodes without waiting for the ZooKeeper SyncConnected state. The client operation should be guarded with ZKConnectionWatcher.

LocalBookKeeper.java
{noformat}
zkc = new ZooKeeper(""127.0.0.1"", ZooKeeperDefaultPort, new emptyWatcher());
/*	User for testing purposes, void */
static class emptyWatcher implements Watcher {
public void process(WatchedEvent event) {}
}
{noformat}
",2012-05-31 11:25:43,2012-06-05 06:57:08
BOOKKEEPER-280,LedgerHandle.addEntry() should return an entryId,Bug,1,Closed,6,Fixed,2012-06-29 16:44:19,2012-05-31 18:06:38,2013-02-13T15:46:35.000+0000,mmerli,Matteo Merli,mmerli,"LedgerHandle.asyncAddEntry callback provides the entryId of the newly added entry, but the synchronous version return void. 
",2012-05-31 18:06:38,2012-06-29 16:44:19
BOOKKEEPER-281,BKClient is failing when zkclient connection delays,Bug,1,Closed,6,Fixed,2012-06-05 06:22:17,2012-06-01 09:41:50,2013-01-14T16:12:57.000+0000,ikelly,Ivan Kelly,ikelly,"I have started the ZK cluster and when tries to create a BookKeeper client from my application, it is throwing following ZooKeeper ConnectionLossException and is exitting.



12/06/01 11:44:31 WARN client.ZooKeeperSaslClient: SecurityException: java.lang.SecurityException: Unable to locate a login configuration occurred when trying to find JAAS configuration.
12/06/01 11:44:31 INFO client.ZooKeeperSaslClient: Client will not SASL-authenticate because the default JAAS configuration section 'Client' could not be found. If you are not using SASL, you may ignore this. On the other hand, if you expected SASL to work, please fix your JAAS configuration.
12/06/01 11:44:31 INFO zookeeper.ClientCnxn: Client session timed out, have not heard from server in 4540ms for sessionid 0x0, closing socket connection and attempting reconnect
12/06/01 11:44:32 INFO zookeeper.ClientCnxn: Opening socket connection to server /10.18.40.91:2182
Exception in thread ""main"" org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss
       at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
       at org.apache.bookkeeper.client.BookieWatcher.readBookiesBlocking(BookieWatcher.java:151)
       at org.apache.bookkeeper.client.BookKeeper.<init>(BookKeeper.java:139)
       at BKClient1.main(BKClient1.java:40)
12/06/01 11:44:36 WARN client.ZooKeeperSaslClient: SecurityException: java.lang.SecurityException: Unable to locate a login configuration occurred when trying to find JAAS configuration.



When analyzed more, the root cause is:

BookKeeper.java:
--------------------
In the constructor of BookKeeper, immediately after creating the ZK client , it is going to bookieWatcher.readBookiesBlocking() for available bookies from ZK server before reaching SyncConnected event.

I think, we would properly use the existing countdown latch and wait till ZooKeeper client connection establishment before continue reading Bookies.
",2012-06-01 09:41:50,2012-06-05 06:22:17
BOOKKEEPER-283,Improve Hedwig Console to use Hedwig Metadata Manager.,Sub-task,7,Closed,6,Fixed,2012-08-17 13:57:16,2012-06-04 05:14:25,2013-02-13T15:46:52.000+0000,hustlmsp,Sijie Guo,hustlmsp,,2012-06-04 05:14:25,2012-08-17 13:57:16
BOOKKEEPER-285,"TestZkSubscriptionManager quits due to NPE, so other tests are not run in hedwig server.",Bug,1,Closed,6,Fixed,2012-06-05 10:12:18,2012-06-04 18:02:40,2013-01-14T16:14:03.000+0000,hustlmsp,Sijie Guo,hustlmsp,"{code}
2012-06-05 01:33:46,366 - ERROR - [main-EventThread:TerminateJVMExceptionHandler@28] - Uncaught exception in thread main-EventThread
java.lang.NullPointerException
        at org.apache.hedwig.server.subscriptions.AbstractSubscriptionManager.updateMessageBound(AbstractSubscriptionManager.java:457)
        at org.apache.hedwig.server.subscriptions.AbstractSubscriptionManager$AcquireOp$1.operationFinished(AbstractSubscriptionManager.java:207)
        at org.apache.hedwig.server.subscriptions.AbstractSubscriptionManager$AcquireOp$1.operationFinished(AbstractSubscriptionManager.java:157)
        at org.apache.hedwig.server.meta.ZkMetadataManager$7.safeProcessResult(ZkMetadataManager.java:352)
        at org.apache.hedwig.zookeeper.SafeAsyncZKCallback$ChildrenCallback.processResult(SafeAsyncZKCallback.java:66)
        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:594)
        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:497)
{code}

",2012-06-04 18:02:40,2012-06-05 10:12:18
BOOKKEEPER-286,Compilation warning,Bug,1,Closed,6,Fixed,2012-06-05 11:21:30,2012-06-04 21:38:52,2013-01-14T16:14:38.000+0000,ikelly,Ivan Kelly,ikelly,"I'm getting the following warning when building the project:

{noformat}
:hedwig-server fpj$ mvn clean
[INFO] Scanning for projects...
[WARNING] 
[WARNING] Some problems were encountered while building the effective model for org.apache.bookkeeper:hedwig-server:jar:4.2.0-SNAPSHOT
[WARNING] 'build.plugins.plugin.version' for org.codehaus.mojo:findbugs-maven-plugin is missing. @ line 140, column 15
[WARNING] 
[WARNING] It is highly recommended to fix these problems because they threaten the stability of your build.
[WARNING] 
[WARNING] For this reason, future Maven versions might no longer support building such malformed projects.
[WARNING] 
{noformat}

Note that this is only for hedwig-server.",2012-06-04 21:38:52,2012-06-05 11:21:30
BOOKKEEPER-287,NoSuchElementException in LedgerCacheImpl,Bug,1,Closed,6,Fixed,2012-06-06 16:38:33,2012-06-05 22:09:49,2013-01-14T16:14:57.000+0000,hustlmsp,Sijie Guo,hustlmsp,"2012-06-05 16:24:29,596 - WARN  [NIOServerFactory-3181:NIOServerFactory@128] - Exception in server socket loop: /0.0.0.0
java.util.NoSuchElementException
        at java.util.LinkedList.getFirst(LinkedList.java:109)
        at org.apache.bookkeeper.bookie.LedgerCacheImpl.grabCleanPage(LedgerCacheImpl.java:478)
        at org.apache.bookkeeper.bookie.LedgerCacheImpl.grabLedgerEntryPage(LedgerCacheImpl.java:169)
        at org.apache.bookkeeper.bookie.LedgerCacheImpl.putEntryOffset(LedgerCacheImpl.java:199)
        at org.apache.bookkeeper.bookie.InterleavedLedgerStorage.addEntry(InterleavedLedgerStorage.java:109)
        at org.apache.bookkeeper.bookie.LedgerDescriptorImpl.addEntry(LedgerDescriptorImpl.java:81)
        at org.apache.bookkeeper.bookie.Bookie.addEntryInternal(Bookie.java:656)
        at org.apache.bookkeeper.bookie.Bookie.addEntry(Bookie.java:691)
        at org.apache.bookkeeper.proto.BookieServer.processPacket(BookieServer.java:368)
        at org.apache.bookkeeper.proto.NIOServerFactory$Cnxn.readRequest(NIOServerFactory.java:310)
        at org.apache.bookkeeper.proto.NIOServerFactory$Cnxn.doIO(NIOServerFactory.java:208)
        at org.apache.bookkeeper.proto.NIOServerFactory.run(NIOServerFactory.java:123)
",2012-06-05 22:09:49,2012-06-06 16:38:33
BOOKKEEPER-288,NOTICE files don't have the correct year,Bug,1,Closed,6,Fixed,2012-06-07 14:19:02,2012-06-07 13:19:32,2013-01-14T16:15:19.000+0000,ikelly,Ivan Kelly,ikelly,NOTICE files only have 2011. They should have 2012 also.,2012-06-07 13:19:32,2012-06-07 14:19:02
BOOKKEEPER-289,mvn clean doesn't remove test output files,Improvement,4,Closed,6,Fixed,2012-06-12 15:38:13,2012-06-08 05:10:08,2013-02-13T15:46:37.000+0000,hustlmsp,Sijie Guo,hustlmsp,"some test output files are not removed when 'mvn clean'.
these files are

1. latencyDump.dat generated by bookkeeper-benchmark
2. derby.log generated by LocalDBPersistenceManager test

besides that build directory in hedwig-server used by ZooKeeper ClientBase testcase is in top-level directory of hedwig-server. it would be better to move it to target directory.",2012-06-08 05:10:08,2012-06-12 15:38:13
BOOKKEEPER-290,FileHandler leak at Bookkeeper server side - addEntry and readEntries for ledgerHandle,Bug,1,Resolved,5,Invalid,2012-06-08 13:24:49,2012-06-08 10:35:23,2012-06-08T13:24:49.000+0000,,,,"LSOF incrementing when the following 2 APIs are used

LedgerHandle.java
=================
public void addEntry(byte[] data) throws InterruptedException, BKException {

public Enumeration<LedgerEntry> readEntries(long firstEntry, long lastEntry)
throws InterruptedException, BKException {

",2012-06-08 10:35:23,2012-06-08 13:24:49
BOOKKEEPER-291,BKMBeanRegistry uses log4j directly,Bug,1,Closed,6,Fixed,2012-12-03 09:55:24,2012-06-11 16:34:38,2013-02-13T15:46:30.000+0000,fpj,Flavio Paiva Junqueira,fpj,It should use slf4j.,2012-06-11 16:34:38,2012-12-03 09:55:24
BOOKKEEPER-292,Test backward compatibility automatically between versions.,Bug,1,Closed,6,Fixed,2012-06-19 10:58:39,2012-06-11 16:45:01,2013-02-13T15:46:55.000+0000,ikelly,Ivan Kelly,ikelly,"At the moment, backward compatibility between 4.1.0 and 4.0.0 can only be tested manually. This JIRA is the set up the code base, so we can validate behaviour between versions automatically, and spot if a change breaks functionallity between versions.",2012-06-11 16:45:01,2012-06-19 10:58:39
BOOKKEEPER-293,Periodic checking of ledger replication status,Sub-task,7,Closed,6,Fixed,2013-01-04 10:36:06,2012-06-12 15:24:42,2013-05-02T02:29:58.000+0000,ikelly,Ivan Kelly,ikelly,We should periodically check all ledgers to make sure that they are fully replicated.,2012-06-12 15:24:42,2013-01-04 10:36:06
BOOKKEEPER-294,Not able to start the bookkeeper before the ZK session timeout.,Bug,1,Closed,6,Fixed,2012-07-05 13:10:09,2012-06-13 04:56:56,2013-09-11T04:27:49.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"Not able to start the bookkeeper before the ZK session timeout.

Here i killed the bookie and started again.

{noformat}
2012-06-12 20:00:25,220 - INFO  [main:LedgerCache@65] - openFileLimit is 900, pageSize is 8192, pageLimit is 456781
2012-06-12 20:00:25,238 - ERROR [main:Bookie@453] - ZK exception registering ephemeral Znode for Bookie!
org.apache.zookeeper.KeeperException$NodeExistsException: KeeperErrorCode = NodeExists for /ledgers/available/10.18.40.216:3181
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:119)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.create(ZooKeeper.java:778)
	at org.apache.bookkeeper.bookie.Bookie.registerBookie(Bookie.java:450)
	at org.apache.bookkeeper.bookie.Bookie.<init>(Bookie.java:348)
	at org.apache.bookkeeper.proto.BookieServer.<init>(BookieServer.java:64)
	at org.apache.bookkeeper.proto.BookieServer.main(BookieServer.java:249)
{noformat}",2012-06-13 04:56:56,2012-07-05 13:10:09
BOOKKEEPER-296,It's better provide stop script for bookie,Bug,1,Closed,6,Fixed,2012-08-17 09:16:30,2012-06-14 09:47:43,2013-02-13T15:46:43.000+0000,nijel,nijel,nijel,Currently there is no command to stop bookie in 4.0.0..It's better to provide stop command for bookie.,2012-06-14 09:47:43,2012-08-17 09:16:30
BOOKKEEPER-298,We run with preferIPv4Stack in the scripts but not in the tests,Bug,1,Closed,6,Fixed,2012-06-18 14:55:25,2012-06-14 13:30:34,2013-02-13T15:46:49.000+0000,ikelly,Ivan Kelly,ikelly,"Bookkeeper doesn't work with IPv6, but if it's enabled, java will try to use it. We get around this by setting the java.net.preferIPv4Stack in the startup scripts but we don't set it for the tests.",2012-06-14 13:30:34,2012-06-18 14:55:25
BOOKKEEPER-299,Provide LedgerFragmentReplicator which should replicate the fragments found from LedgerChecker,Sub-task,7,Closed,6,Fixed,2012-08-19 09:40:37,2012-06-18 14:08:08,2013-02-13T15:46:46.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,"Replication worker requires LedgerFragmentReplicator for replicating the actula fragments found from Ledger checker.

Most of the fragment replication code available in BookKeeperAdmin. We can refactor it to LedgerFragmentReplicator and use it.",2012-06-18 14:08:08,2012-08-19 09:40:37
BOOKKEEPER-300,Create Bookie format command,New Feature,2,Closed,6,Fixed,2012-09-07 05:05:25,2012-06-19 06:30:29,2013-02-13T15:46:43.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"Provide a bookie format command. Then the admin would just have to run the command on each machine, which will prepare the bookie env

+Zookeeper paths (znodes):+
- ledger's root path
- bookie's available path

+Directories:+
- Journal directories
- Ledger directories
",2012-06-19 06:30:29,2012-09-07 05:05:25
BOOKKEEPER-302,No more messages delivered when hub server scans messages over two ledgers.,Bug,1,Closed,6,Fixed,2012-06-28 17:22:05,2012-06-20 08:48:49,2013-02-13T15:46:36.000+0000,hustlmsp,Sijie Guo,hustlmsp,"This issue introduce when fixing BOOKKEEPER-215.

suppose topic T has four messages, message 1 is in ledger 1 while message 2~4
are in ledger 2. Hub server issue scan (1, 2) and scan (3, 4).

If hub server works correctly, it just tried to read entry 0 in ledger 1 and
entry 0 in ledger 2 during scan (1,2), while reading entry 1, 2 in ledger 2
during scan (3,4).

But unfortunately, after fixing BOOKKEEPER-215, scan (1,2) would read 0 in
ledger 1 and read 0, 1 in ledger 2. so reading entry 1 of ledger 2 would be
issued concurrently in different scans and one reading would fail without any callback (this issue is BOOKKEEPER-49).

Then the systems would be blocked there wait for the response of reading 1 of
ledger 2 and no messages would be delivered.


To fix this issue, two thing would be done.

1) fix scan issue in hub server to avoid overlapping scanning.
2) fix read issue in bookkeeper client.

fixing 1) could resolve this issue, but it would be better to fix 2) also. it should be in jira BOOKKEEPER-49.",2012-06-20 08:48:49,2012-06-28 17:22:05
BOOKKEEPER-303,LedgerMetadata should serialized using protobufs,Bug,1,Closed,6,Fixed,2012-06-27 13:35:40,2012-06-20 09:32:39,2013-02-13T15:47:03.000+0000,ikelly,Ivan Kelly,ikelly,"Google protobufs is a library for serializing and deserializing data. It elegantly handles the cases where new data is added to a data format. This is useful in the case of something like LedgerMetadata, which may change over time. However, at the moment, whenever we make a change to the LedgerMetadata serialization format we have to break compatibility with old clients. By using protobufs, even if we add something to the format, old clients should be able to read the ledgers. 

We should also change our protocols to use protobufs for the same reason, but this should be done in 4.3.0.

http://code.google.com/p/protobuf/",2012-06-20 09:32:39,2012-06-27 13:35:40
BOOKKEEPER-304,Prepare bookie vs ledgers cache and will be used by the Auditor,Sub-task,7,Closed,6,Fixed,2012-08-27 14:58:16,2012-06-20 11:01:16,2013-02-13T15:46:46.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"This JIRA discusses how to build bookie -> ledgers cache and this will be used by the Auditor to publish the suspected ledgers of failed bookies.
",2012-06-20 11:01:16,2012-08-27 14:58:16
BOOKKEEPER-306,Change C++ client to use gtest for testing,Bug,1,Closed,6,Fixed,2012-07-16 10:36:20,2012-06-21 12:20:48,2013-02-13T15:46:51.000+0000,ikelly,Ivan Kelly,ikelly,"http://code.google.com/p/googletest/

It looks a lot nicer to run tests with than cppunit which we are using now.",2012-06-21 12:20:48,2012-07-16 10:36:20
BOOKKEEPER-307,BookieShell introduces 4 findbugs warnings,Bug,1,Closed,6,Fixed,2012-06-27 05:11:38,2012-06-21 16:34:24,2013-02-13T15:46:47.000+0000,ikelly,Ivan Kelly,ikelly,One is an empty store. The other is about synchronized access to the journal. Easy fixes.,2012-06-21 16:34:24,2012-06-27 05:11:38
BOOKKEEPER-308,Add support for JMS implementation for hedwig,Improvement,4,Resolved,5,Fixed,2014-03-10 02:19:21,2012-06-21 20:47:55,2014-10-07T09:48:24.000+0000,mridulm80,Mridul Muralidharan,mridulm80,Umbrella bug to keep track of all constituent bugs related to the JMS provider implementation for hedwig.,2012-06-21 20:47:55,2014-03-10 02:19:21
BOOKKEEPER-309,Protocol changes in hedwig to support JMS spec,Sub-task,7,Resolved,5,Fixed,2012-07-30 15:22:24,2012-06-21 20:51:00,2013-01-14T14:44:08.000+0000,mridulm80,Mridul Muralidharan,mridulm80,"JMS spec compliance requires three changes to the protocol.

a) Support for message properties.
b) Make body optional (message contains only properties).
c) Return the published message's seq-id in the response.",2012-06-21 20:51:00,2012-07-30 15:22:24
BOOKKEEPER-310,Changes in hedwig server to support JMS spec,Sub-task,7,Closed,6,Fixed,2012-07-30 15:22:57,2012-06-21 20:57:20,2013-02-13T15:46:54.000+0000,mridulm80,Mridul Muralidharan,mridulm80,"The primary changes are :

a) Support modified protocol changes (optional body).
b) Return the published message's seq-id in the response.
c) Minor bugfix to Array indexing in bucket which was triggered in a testcase.",2012-06-21 20:57:20,2012-07-30 15:22:57
BOOKKEEPER-311,Changes in hedwig client api to support JMS spec,Sub-task,7,Resolved,5,Fixed,2012-07-30 15:23:33,2012-06-21 21:07:45,2013-01-14T14:43:39.000+0000,mridulm80,Mridul Muralidharan,mridulm80,"Primary changes are :

a) Add support for returning seq-id for a publish request. This is an api change (backwardly compatible for users).
b) Make consume a sync consume, with addition of an asyncConsume - this is to ensure that invoking consume() ensure request makes to server before returning (with what reasonable gaurantees that netty allows).
c) Ensure that explicit close'ing of session will flush buffered consume seq-id's when auto-ack is enabled (default in hedwig java client).


In addition, there are also fixes for
d) Fix NPE's observed as part of testing JMS provider.",2012-06-21 21:07:45,2012-07-30 15:23:33
BOOKKEEPER-312,Implementation of JMS provider,Sub-task,7,Resolved,5,Fixed,2013-01-31 18:33:36,2012-06-21 21:13:26,2013-02-01T00:52:06.000+0000,mridulm80,Mridul Muralidharan,mridulm80,"
The JMS provider implementation conforming to the 1.1 spec.
The limitations as of now are :



1) No support for Queue's : Hedwig currently does not have a notion of JMS queue's for us to leverage.

2) No support for noLocal : Hedwig DOES NOT conform to JMS model of connection -(n)-> session -(n)-> publisher/subscriber. Each session has a hedwig connection.

Currently I am simulating noLocal, but this IS fragile and works for the duration of connection - ONLY until the message id is still in a LRUCache. As mentioned before, this is a kludge, and not a good solution.

3) Note that everything is durable in hedwig - so we do not support NON_PERSISTENT delivery mode.

4) Calling unsubscribe on a durable subscription will fail if it was NOT created in the current session.
In hedwig, to unsubscribe, we need the subscription id and the topic ... 

To simulate unsubscribe(), we store the subscriberId to topicName mapping when a create* api is invoked. Hence, if create* was NOT called, then we have no way to infer which topic the subscription-id refers to from hedwig, and so cant unsubscribe.

The workaround is - simply create a durable subsriber just as a workaround of this limitation - the topicName will be known to the user/client anyway.


5) Explicit session recovery is not supported.
Reconnection of hedwig session (either explicitly or implicitly by underlying client implementation) will automatically trigger redelivery of un-acknowledged messages.


6) Because of the above, setting the JMSRedelivered flag is almost impossible in a consistent way.

Currently, we simulate it for redelivery due to provider side events : rollback of txn, exception in message listener (primarily).
At best we can simulate it with a kludge - at risk of potentially running out of resources ... this is being investigated : but unlikely to have a clean fix.

7) Hedwig only supports marking all messages until seq-id as received : while JMS indicates ability to acknowledge individual messages.

This distinction is currently unsupported.

8) JMS spec requires
    ""A connection's delivery of incoming messages can be temporarily stopped
using its stop() method. It can be restarted using its start() method. When the connection is stopped, delivery to all the connections MessageConsumers is inhibited: synchronous receives block, and messages are not delivered to MessageListeners.""

  We honor this for undelivered messages from server - but if stop is called while there are pending messages yet to be delivered to a listener (or buffered in subscriber for receive), then they will be delivered irrespective of stop().


",2012-06-21 21:13:26,2013-01-31 18:33:36
BOOKKEEPER-313,Bookkeeper shutdown call from Bookie thread is not shutting down server,Bug,1,Resolved,5,Fixed,2013-06-21 17:34:56,2012-06-23 07:37:33,2013-06-24T04:03:51.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"shutdown(..) call from inside Bookie#run() is not shutting down the server.

Bookie thread is waiting to join itself.

Shutdown called from here
{code} if (!shuttingdown) {
            // some error found in journal thread and it quits
            // following add operations to it would hang unit client timeout
            // so we should let bookie server exists
            LOG.error(""Journal manager quits unexpectedly."");
            shutdown(ExitCode.BOOKIE_EXCEPTION);
        }{code}


bookie thread is waiting at *this.join()* in below code
{code}// Shutdown the ZK client
                if(zk != null) zk.close();
                // Shutdown journal
                journal.shutdown();
                this.join();
                syncThread.shutdown();

                // close Ledger Manager{code}",2012-06-23 07:37:33,2013-06-21 17:34:56
BOOKKEEPER-314,Jenkins build failure,Bug,1,Resolved,5,Done,2017-10-09 09:49:15,2012-06-24 13:33:50,2017-10-09T09:49:15.000+0000,,,,"Jenkins is complaining about the following:

{noformat}
[INFO] ------------------------------------------------------------------------
[ERROR] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] The projects in the reactor contain a cyclic reference: Edge between 'Vertex{label='org.apache.bookkeeper:bookkeeper-server'}' and 'Vertex{label='org.apache.bookkeeper:bookkeeper-server-compat400'}' introduces to cycle in the graph org.apache.bookkeeper:bookkeeper-server-compat400 --> org.apache.bookkeeper:bookkeeper-server --> org.apache.bookkeeper:bookkeeper-server-compat400

{noformat}",2012-06-24 13:33:50,2017-10-09 09:49:15
BOOKKEEPER-315,Ledger entries should be replicated sequentially instead of parallel.,Sub-task,7,Closed,6,Fixed,2012-10-05 14:27:40,2012-06-25 13:32:38,2013-02-13T15:46:59.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,"Currently BookKeeperAdmin will copy the entries parallel.

This may create more load on the servers. To avoid that, we can refactor the BKAdmin code to copy the entries sequential.",2012-06-25 13:32:38,2012-10-05 14:27:40
BOOKKEEPER-317,Exceptions for replication,Sub-task,7,Closed,6,Fixed,2012-07-26 03:01:38,2012-06-25 18:04:48,2013-02-13T15:47:00.000+0000,ikelly,Ivan Kelly,ikelly,A couple of the BOOKKEEPER-237 jiras need to add new exceptions. This jira creates the umbrella exception which they can all go under.,2012-06-25 18:04:48,2012-07-26 03:01:38
BOOKKEEPER-318,Spelling mistake in MultiCallback log message.,Improvement,4,Closed,6,Fixed,2012-07-05 05:11:51,2012-06-26 06:55:45,2013-02-13T15:46:31.000+0000,surendralilhore,Surendra Singh Lilhore,surendrasingh,"{code}
@Override
        public void processResult(int rc, String path, Object ctx) {
            if (rc != successRc) {
                LOG.error(""Error in multi callback : "" + rc);
                exceptions.add(rc);
            }
            tick();
        }
{code}",2012-06-26 06:55:45,2012-07-05 05:11:51
BOOKKEEPER-319,Manage auditing and replication processes,Sub-task,7,Closed,6,Fixed,2012-10-04 16:32:15,2012-06-26 08:26:06,2013-05-02T02:29:55.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"This subtask discusses, how we will manage the whole rereplication processes.
",2012-06-26 08:26:06,2012-10-04 16:32:15
BOOKKEEPER-320,Let hedwig cpp client could publish messages using Message object instead of string.,Improvement,4,Closed,6,Fixed,2012-07-04 13:44:48,2012-06-27 05:43:51,2013-02-13T15:46:58.000+0000,jiannan,Jiannan Wang,jiannan,,2012-06-27 05:43:51,2012-07-04 13:44:48
BOOKKEEPER-321,Message Filter Support,Improvement,4,Resolved,5,Implemented,2012-12-03 09:24:57,2012-06-27 09:26:09,2013-01-14T14:44:51.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Support message filtering in hedwig.

1) add user-customized headers part in Message, which could be used for message filtering.
2) add user-customized subscription preferences, which could be used for message filtering.
3) support both server-side & client-side message filter.",2012-06-27 09:26:09,2012-12-03 09:24:57
BOOKKEEPER-322,New protobufs generates findbugs errors,Bug,1,Closed,6,Fixed,2012-06-28 17:33:05,2012-06-27 14:09:24,2013-02-13T15:46:38.000+0000,ikelly,Ivan Kelly,ikelly,"We need to exclude the protobuf generated classes from findbugs. Also, the generated sources should be excluded from the apache-rat:check.

Also, there's one other findbug in LedgerMetadata",2012-06-27 14:09:24,2012-06-28 17:33:05
BOOKKEEPER-324,Flakeyness in LedgerCreateDeleteTest,Bug,1,Closed,6,Fixed,2012-07-04 14:18:07,2012-07-03 10:35:14,2013-02-13T15:46:45.000+0000,ikelly,Ivan Kelly,ikelly,"Fails when running in a loop for about 40 minutes. Failure is a ConcurrentModificationException

{code}
  <testcase time=""3.018"" classname=""org.apache.bookkeeper.test.LedgerCreateDeleteTest"" name=""testCreateDeleteLedgers"">
    <error type=""java.util.ConcurrentModificationException"">java.util.ConcurrentModificationException
	at java.util.HashMap$HashIterator.nextEntry(HashMap.java:793)
	at java.util.HashMap$EntryIterator.next(HashMap.java:834)
	at java.util.HashMap$EntryIterator.next(HashMap.java:832)
	at org.apache.bookkeeper.bookie.LedgerCacheImpl.close(LedgerCacheImpl.java:781)
	at org.apache.bookkeeper.bookie.InterleavedLedgerStorage.shutdown(InterleavedLedgerStorage.java:73)
	at org.apache.bookkeeper.bookie.Bookie.shutdown(Bookie.java:644)
	at org.apache.bookkeeper.bookie.Bookie.shutdown(Bookie.java:630)
	at org.apache.bookkeeper.proto.BookieServer.shutdown(BookieServer.java:110)
	at org.apache.bookkeeper.test.BookKeeperClusterTestCase.stopBKCluster(BookKeeperClusterTestCase.java:146)
	at org.apache.bookkeeper.test.BookKeeperClusterTestCase.tearDown(BookKeeperClusterTestCase.java:94)
	at junit.framework.TestCase.runBare(TestCase.java:140)
	at junit.framework.TestResult$1.protect(TestResult.java:110)
{code}",2012-07-03 10:35:14,2012-07-04 14:18:07
BOOKKEEPER-325,Delay the replication of a ledger if RW found that its last fragment is in underReplication.,Sub-task,7,Closed,6,Fixed,2012-09-12 18:36:39,2012-07-03 13:53:08,2013-02-13T15:47:02.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,"When RW found that ledger's last fragment is in underReplication state, then we should delay that ledger replication for some grace period. optimally we can replicate other fragments.

The idea is, Whenever it finds the last fragement is under replicated, It can add into PendingReplication list.
There will be a small daemon, which will check for the timeouts of this ledgers. 

Once it timed out , it will trigger the normal replication process if it is not in last fragment. Otherwise, it will fence the ledger and will trigger the replication nomally.

see the discussion for more info:
http://markmail.org/message/ruhhxxgvuqnjlu2s#query:+page:1+mid:f6ifo4sizulwiaem+state:results",2012-07-03 13:53:08,2012-09-12 18:36:39
BOOKKEEPER-326,DeadLock during ledger recovery ,Bug,1,Closed,6,Fixed,2012-08-13 09:39:18,2012-07-04 04:38:34,2013-02-13T15:46:32.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,Deadlock found during ledger recovery. please find the attached thread dump.,2012-07-04 04:38:34,2012-08-13 09:39:18
BOOKKEEPER-327,System.currentTimeMillis usage in BookKeeper,Bug,1,Closed,6,Fixed,2012-07-24 17:03:58,2012-07-05 18:04:20,2013-02-13T15:46:59.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,"The following exception occured in the bookie statistics logic due to the System time changes. In our bookie cluster its running a periodic syncup scripts just to unify the SystemTime in all the machines. This is causing the problem and resulting ArrayIndexOutOfBoundException.
{code}
Exception in thread ""BookieJournal-3181"" java.lang.ArrayIndexOutOfBoundsException: -423
at org.apache.bookkeeper.proto.BKStats$OpStats.updateLatency(BKStats.java:126)
at org.apache.bookkeeper.proto.BookieServer.writeComplete(BookieServer.java:655)
at org.apache.bookkeeper.bookie.Journal.run(Journal.java:507)
{code}

This jira is raised to discuss whether to use ??System.nanoTime()?? instead of ??System.currentTimeMillis()??",2012-07-05 18:04:20,2012-07-24 17:03:58
BOOKKEEPER-328,Bookie DeathWatcher is missing thread name,Improvement,4,Closed,6,Fixed,2012-07-09 02:11:06,2012-07-06 15:41:49,2013-02-13T15:46:51.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,,2012-07-06 15:41:49,2012-07-09 02:11:06
BOOKKEEPER-329,provide stop scripts for hub server,Bug,1,Closed,6,Fixed,2012-07-11 17:25:48,2012-07-09 02:32:39,2013-02-13T15:47:01.000+0000,hustlmsp,Sijie Guo,hustlmsp,"as what we did in BOOKKEEPER-296, it would be better to provide similar script to start/stop hub server.",2012-07-09 02:32:39,2012-07-11 17:25:48
BOOKKEEPER-330,System.currentTimeMillis usage in Hedwig,Bug,1,Closed,6,Fixed,2012-07-26 03:23:25,2012-07-09 06:45:05,2013-02-13T15:46:42.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,Need same changes in hedwig server as what did in bookkeeper as BOOKKEEPER-327.,2012-07-09 06:45:05,2012-07-26 03:23:25
BOOKKEEPER-331,Let hedwig support returning message seq id for publish requests.,Sub-task,7,Closed,6,Fixed,2012-07-30 15:25:00,2012-07-09 07:40:15,2013-05-02T02:29:54.000+0000,mridulm80,Mridul Muralidharan,mridulm80,Let hedwig support returning message seq id for published messages.,2012-07-09 07:40:15,2012-07-30 15:25:00
BOOKKEEPER-332,Add SubscriptionPreferences to record all preferences for a subscription,Sub-task,7,Closed,6,Fixed,2012-08-17 15:33:12,2012-07-09 08:58:52,2013-02-13T15:47:03.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Add SubscriptionPreferences to record the preferences for a subscription. This jira includes:
1) add SubscriptionPreferences protocol.
2) separated preferences from subscription state to decouple infrequent-changed data from frequent changed data (like lastConsumedSeqId).
3) add backward testing.",2012-07-09 08:58:52,2012-08-17 15:33:12
BOOKKEEPER-333,server-side message filter,Sub-task,7,Closed,6,Fixed,2012-08-27 17:22:24,2012-07-09 09:00:09,2013-02-13T15:46:47.000+0000,hustlmsp,Sijie Guo,hustlmsp,Support running message filter on server-side.,2012-07-09 09:00:09,2012-08-27 17:22:24
BOOKKEEPER-334,client-side message filter for java client.,Sub-task,7,Closed,6,Fixed,2012-09-03 15:15:08,2012-07-09 09:00:45,2013-02-13T15:46:35.000+0000,hustlmsp,Sijie Guo,hustlmsp,Support running message filter on java client-side.,2012-07-09 09:00:45,2012-09-03 15:15:08
BOOKKEEPER-335,client-side message filter for cpp client.,Sub-task,7,Closed,6,Fixed,2012-09-03 15:28:01,2012-07-09 09:01:04,2013-02-13T15:47:01.000+0000,hustlmsp,Sijie Guo,hustlmsp,Support running message filter on cpp client-side.,2012-07-09 09:01:04,2012-09-03 15:28:01
BOOKKEEPER-336,bookie readEntries is taking more time if the ensemble has failed bookie(s),Bug,1,Closed,6,Fixed,2012-12-13 12:08:30,2012-07-10 04:49:01,2013-02-13T15:46:37.000+0000,ikelly,Ivan Kelly,ikelly,"Scenario:

1) Start three bookies. Create ledger with ensemblesize=3, quorumsize=2
2) Add 100 entries to this ledger
3) Make first bookie down and read the entries from 0-99

Output: Each entry is going to fetch from the failed bookie and is waiting for the bookie connection timeout, only after failure going to next bookie.
This is affecting the read entry performance.

Impact: Namenode switching time will be affected by adding this failed bookie readTimeOut also.",2012-07-10 04:49:01,2012-12-13 12:08:30
BOOKKEEPER-337,Add entry fails with MetadataVersionException when last ensemble has morethan one bookie failures,Bug,1,Closed,6,Fixed,2012-08-28 08:52:13,2012-07-11 14:03:38,2013-02-13T15:46:50.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"Scenario:
========
Start Five BK's
Write ledger's with ensemble three and quroum size=2
while write inprogress down two bookies(Bookies should be in ensemble)
",2012-07-11 14:03:38,2012-08-28 08:52:13
BOOKKEEPER-338,Create Version.NEW and Version.ANY static instances of Version so that were not passing around nulls,Bug,1,Closed,6,Fixed,2012-08-17 09:59:15,2012-07-12 10:02:33,2013-02-13T15:46:37.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Passing null as a parameter into a method makes the intention abiguous. It would be better to pass in defined constants, such as Version.NEW & Version.ANY. This makes the code clearer and more readable.",2012-07-12 10:02:33,2012-08-17 09:59:15
BOOKKEEPER-339,Let hedwig cpp client support returning message seq id for publish requests.,Improvement,4,Closed,6,Fixed,2012-08-06 10:11:09,2012-07-15 14:40:01,2013-05-02T02:29:54.000+0000,hustlmsp,Sijie Guo,hustlmsp,let hedwig cpp client support returning message seq id for publish requests. as what we did for BOOKKEEPER-331.,2012-07-15 14:40:01,2012-08-06 10:11:09
BOOKKEEPER-340,Test backward compatibility for hedwig between different versions.,Improvement,4,Closed,6,Fixed,2012-08-06 14:19:09,2012-07-15 14:47:40,2013-02-13T15:47:01.000+0000,hustlmsp,Sijie Guo,hustlmsp,"we should provide backward compatibility testing for hedwig between different versions. as what we did in BOOKKEEPER-292 for bookkeeper. I had did it in BOOKKEEPER-332, but it would be better to provide here. since BOOKKEEPER-331 also need it for some backward compatibility testing.",2012-07-15 14:47:40,2012-08-06 14:19:09
BOOKKEEPER-341,add documentation for bookkeeper ledger manager interface.,Sub-task,7,Closed,6,Fixed,2012-12-13 17:13:48,2012-07-15 15:26:56,2013-02-13T15:47:05.000+0000,hustlmsp,Sijie Guo,hustlmsp,"add documentation for bookkeeper ledger manager interface, which help users who are interested on providing different implementation.",2012-07-15 15:26:56,2012-12-13 17:13:48
BOOKKEEPER-342,add documentation for hedwig metadata manager interface.,Sub-task,7,Closed,6,Fixed,2012-12-18 05:52:44,2012-07-15 15:27:29,2013-02-13T15:46:31.000+0000,hustlmsp,Sijie Guo,hustlmsp,"add documentation for hedwig metadata manager interface, which help users who are interested on providing different implementation.",2012-07-15 15:27:29,2012-12-18 05:52:44
BOOKKEEPER-343,Failed to register hedwig JMX beans in test cases,Bug,1,Closed,6,Fixed,2012-08-03 17:42:42,2012-07-16 14:24:40,2013-02-13T15:46:58.000+0000,hustlmsp,Sijie Guo,hustlmsp,"failed to register jmx beans for hedwig running test cases.

the exception is as below:

{code}
2012-07-16 22:13:54,849 - WARN  - [Thread-134:ReadAheadCache@729] - Failed to register readahead cache with JMX
javax.management.InstanceAlreadyExistsException: org.apache.HedwigServer:name0=ReadAheadCache
        at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:453)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.internal_addObject(DefaultMBeanServerInterceptor.java:1484)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:963)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:917)
        at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:312)
        at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:482)
        at org.apache.zookeeper.jmx.MBeanRegistry.register(MBeanRegistry.java:98)
        at org.apache.hedwig.server.persistence.ReadAheadCache.registerJMX(ReadAheadCache.java:727)
        at org.apache.hedwig.server.netty.PubSubServer.registerJMX(PubSubServer.java:300)
        at org.apache.hedwig.server.netty.PubSubServer$3.run(PubSubServer.java:395)
        at java.lang.Thread.run(Thread.java:680)
{code}",2012-07-16 14:24:40,2012-08-03 17:42:42
BOOKKEEPER-345,Detect IOExceptions on entrylogger and bookie should consider next ledger dir(if any),Sub-task,7,Closed,6,Fixed,2012-10-18 14:41:53,2012-07-17 08:59:21,2013-02-13T15:46:23.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"This jira to detect IOExceptions in ""EntryLogger"", and will iterate over all the configured ledger(s) on IOException. Finally if no writable dirs available, will move bookie to r-o mode(if this mode is enabled). 

By default(r-o mode will be disabled) the bookie will shutdown if no writable disk available.",2012-07-17 08:59:21,2012-10-18 14:41:53
BOOKKEEPER-346,Detect IOExceptions in LedgerCache and bookie should look at next ledger dir(if any),Sub-task,7,Closed,6,Fixed,2012-10-26 10:52:32,2012-07-17 09:02:18,2013-02-13T15:46:33.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"This jira to detect IOExceptions in ""LedgerCache"" to iterate over all the configured ledger(s).",2012-07-17 09:02:18,2012-10-26 10:52:32
BOOKKEEPER-347, Provide mechanism to detect r-o bookie by the bookie clients,Sub-task,7,Closed,6,Fixed,2012-12-03 16:59:36,2012-07-17 09:04:07,2013-02-13T15:46:42.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"This jira to discuss, how the bookie client knows about the bookie running in r-o. This would be required by the client to choose writable bookies during add entries. ",2012-07-17 09:04:07,2012-12-03 16:59:36
BOOKKEEPER-348,Last entry will be lost when open an un-closed ledger ,Bug,1,Resolved,5,Not A Bug,2017-10-09 09:49:04,2012-07-22 01:58:35,2017-10-09T09:49:04.000+0000,,,,"This can be reproduced in following steps:
1) client-A created a ledger-x and write N entries to it
2) client-B open the ledger-x and try to read all entries from it. client-B can only get N-1 entries (except for the last entry)

This problem caused by, when trying to open an unclosed ledger, it will enter the ""recover"" mode, it can get correct last entry-Id judged by the size of log file. But it will set the new opened ledger's lastAddConfirmed by the previous lastAddConfirmed, and the entry-id will be ignored.
For an unclosed ledger, the lastAddConfirmed will always = (last-entry-id - 1).

A patch attached to this jira.",2012-07-22 01:58:35,2017-10-09 09:49:04
BOOKKEEPER-349,"Entry logger should close all the chennels which are there in Map, instead of closing only current channel.",Bug,1,Closed,6,Fixed,2012-07-26 02:33:46,2012-07-23 06:33:40,2013-02-13T15:46:55.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,"I have seen this on restarting the same bookies from same JVM( in one of mey testcase which I was writing for autoRecovery work), i.e, all channels are not getting closed.
When we restart the same bookie, there are 0.log channel will be a older channel. Since the current code cares about only current logChannel. So, we are not releasing the older channels on EntryLogger shutdown. ",2012-07-23 06:33:40,2012-07-26 02:33:46
BOOKKEEPER-351,asyncAddEntry should not throw an exception,Bug,1,Closed,6,Fixed,2012-12-03 05:24:04,2012-07-23 21:14:35,2013-02-13T15:46:51.000+0000,mmerli,Matteo Merli,mmerli,"There are cases where LedgerHandle.asyncAddEntry() fails with a RuntimeException that is thrown by executor.submit(). 

It should better invoke the callback with a failure result.",2012-07-23 21:14:35,2012-12-03 05:24:04
BOOKKEEPER-352,Should not use static ServerStats/BKStats instance in TestServerStats/TestBKStats,Bug,1,Closed,6,Fixed,2012-07-27 13:52:55,2012-07-26 06:58:53,2013-02-13T15:46:28.000+0000,hustlmsp,Sijie Guo,hustlmsp,"TestServers failed when running whole test. Because TestServers uses ServerStats instance directly. ServerStats is a static instance, which will be used across whole testing. so the numSuccessOps would not be zero, the assertion would fail.

Same problem occurs in TestBKStats. TestBKStats doesn't fail because statistics is turned off by default. The value happened to be zero. But it still is not a good idea to use static instance during testing.",2012-07-26 06:58:53,2012-07-27 13:52:55
BOOKKEEPER-354,[BOOKKEEPER-296] [Documentation] Modify the bookkeeper start script and document the bookkeeper stop command in bookkeeperConfig.xml,Bug,1,Closed,6,Fixed,2012-08-21 09:41:32,2012-08-07 06:00:58,2013-02-13T15:47:04.000+0000,kiran_bc,Kiran BC,kiran_bc,"Need to modify the bookkeeper start script and need to add content for bookkeeper stop.
",2012-08-07 06:00:58,2012-08-21 09:41:32
BOOKKEEPER-355,"Ledger recovery will mark ledger as closed with -1, in case of slow bookie is added to ensemble during  recovery add",Bug,1,Closed,6,Fixed,2013-01-07 11:25:54,2012-08-08 10:02:04,2013-02-13T15:46:59.000+0000,ikelly,Ivan Kelly,ikelly,"Scenario:
------------
1. Ledger is created with ensemble and quorum size as 2, written with one entry
2. Now first bookie is in the ensemble is made down.
3. Another client fence and trying to recover the same ledger
4. During this time ensemble change will happen and new bookie will be added. But this bookie is not able to connect.
5. This recovery will fail.
7. Now previously added bookie came up.
8. Another client trying to recover the same ledger.
9. Since new bookie is first in the ensemble, doRecoveryRead() is reading from that bookie and getting NoSuchLedgerException and closing the ledger with -1

i.e. Marking the ledger as empty, even though first client had successfully written one entry.",2012-08-08 10:02:04,2013-01-07 11:25:54
BOOKKEEPER-363,Re-distributing topics among newly added hubs.,Bug,1,Resolved,5,Fixed,2014-03-07 17:42:30,2012-08-14 07:00:34,2014-03-07T18:15:28.000+0000,i0exception,Aniruddha,i0exception,"When a new hub is added to an already existing hedwig cluster, that hub should pick up some of the topics. Currently the mechanism hedwig provides is to configure the time for which a topic is retained. A better approach might be to run a re-balancer thread that periodically checks if topics are distributed evenly among hubs and if not, releases some topics to balance the load. 

https://reviews.apache.org/r/6700/
There is a race condition while updating load as mentioned in the comments and that is not handled in this review.",2012-08-14 07:00:34,2014-03-07 17:42:30
BOOKKEEPER-364,re-factor hedwig java client to support both one-subscription-per-channel and multiplex-subscriptions-per-channel.,Sub-task,7,Closed,6,Fixed,2012-09-26 23:55:38,2012-08-14 13:57:33,2013-02-13T15:46:29.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Currently Hedwig client is coupled with the design of one subscription per channel. In order to multiplex multiple subscription into one channel, it would be better to refine the Hedwig java client code to provide better interface to support both mode.",2012-08-14 13:57:33,2012-09-26 23:55:38
BOOKKEEPER-365,Ledger will never recover if one of the quorum bookie is down forever and others dont have entry,Bug,1,Closed,6,Fixed,2012-12-13 11:33:40,2012-08-14 14:09:04,2013-02-13T15:46:25.000+0000,hustlmsp,Sijie Guo,hustlmsp,"As discussed in BOOKKEEPER-355, current fix to handle the below issue is not correct. Need to find out new solution
If some bookies of a quorum gone forever, some bookies of this quorum are still alive but doesn't have that entry (NoSuchEntry or NoSuchLedger), then the ledger doesn't have any evidence to recovery/close it.",2012-08-14 14:09:04,2012-12-13 11:33:40
BOOKKEEPER-367,Server-Side Message Delivery Flow Control,Sub-task,7,Closed,6,Fixed,2012-10-04 15:01:55,2012-08-16 12:48:39,2013-02-13T15:46:42.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Currently the message delivery flow control is proceed in client side. For multiplexing, we had to move the flow control to sever side.",2012-08-16 12:48:39,2012-10-04 15:01:55
BOOKKEEPER-368,Implementing multiplexing java client.,Sub-task,7,Closed,6,Fixed,2012-11-02 16:16:57,2012-08-16 12:49:51,2013-02-13T15:47:00.000+0000,hustlmsp,Sijie Guo,hustlmsp,Implement a multiplexing java client.,2012-08-16 12:49:51,2012-11-02 16:16:57
BOOKKEEPER-369,re-factor hedwig cpp client to provide better interface to support both one-subscription-per-channel and multiple-subscriptions-per-channel.,Sub-task,7,Closed,6,Fixed,2012-10-18 11:05:19,2012-08-16 12:51:27,2013-02-13T15:46:25.000+0000,hustlmsp,Sijie Guo,hustlmsp,"provide better interface to support both mode, like java client.",2012-08-16 12:51:27,2012-10-18 11:05:19
BOOKKEEPER-370,implement multiplexing cpp client.,Sub-task,7,Closed,6,Fixed,2012-11-02 20:48:33,2012-08-16 12:52:13,2013-02-13T15:46:38.000+0000,hustlmsp,Sijie Guo,hustlmsp,implement a multiplexing cpp client.,2012-08-16 12:52:13,2012-11-02 20:48:33
BOOKKEEPER-371,NPE in hedwig hub client causes hedwig hub to shut down.,Bug,1,Closed,6,Fixed,2012-08-28 12:54:28,2012-08-17 10:42:02,2013-02-13T15:47:02.000+0000,i0exception,Aniruddha,i0exception,"The hedwig client was connected to a remote region hub that restarted resulting in the channel getting disconnected. 


2012-08-15 17:47:42,443 - ERROR - [pool-20-thread-1:TerminateJVMExceptionHandler@28] - Uncaught exception in thread pool-20-thread-1
java.lang.NullPointerException
        at org.apache.hedwig.client.netty.HedwigClientImpl.getResponseHandlerFromChannel(HedwigClientImpl.java:323)
        at org.apache.hedwig.client.handlers.MessageConsumeCallback.operationFinished(MessageConsumeCallback.java:75)
        at org.apache.hedwig.client.handlers.MessageConsumeCallback.operationFinished(MessageConsumeCallback.java:41)
        at org.apache.hedwig.server.regions.RegionManager$1$1$1.operationFinished(RegionManager.java:208)
        at org.apache.hedwig.server.regions.RegionManager$1$1$1.operationFinished(RegionManager.java:202)
        at org.apache.hedwig.server.persistence.ReadAheadCache$PersistCallback.operationFinished(ReadAheadCache.java:194)
        at org.apache.hedwig.server.persistence.ReadAheadCache$PersistCallback.operationFinished(ReadAheadCache.java:171)
        at org.apache.hedwig.server.persistence.BookkeeperPersistenceManager$PersistOp$1.safeAddComplete(BookkeeperPersistenceManager.java:548)
        at org.apache.hedwig.zookeeper.SafeAsynBKCallback$AddCallback.addComplete(SafeAsynBKCallback.java:93)
        at org.apache.bookkeeper.client.PendingAddOp.submitCallback(PendingAddOp.java:165)
        at org.apache.bookkeeper.client.LedgerHandle.sendAddSuccessCallbacks(LedgerHandle.java:643)
        at org.apache.bookkeeper.client.PendingAddOp.writeComplete(PendingAddOp.java:159)
        at org.apache.bookkeeper.proto.PerChannelBookieClient.handleAddResponse(PerChannelBookieClient.java:577)
        at org.apache.bookkeeper.proto.PerChannelBookieClient$7.safeRun(PerChannelBookieClient.java:525)
        at org.apache.bookkeeper.util.SafeRunnable.run(SafeRunnable.java:31)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)
        at java.util.concurrent.FutureTask.run(FutureTask.java:166)
        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)
        at java.lang.Thread.run(Thread.java:722)


At 2012-08-15 17:47:42,443, the channel was disconnected as well. 

I believe the following code in the MessageConsumeCallback is causing this problem. 

 Channel topicSubscriberChannel = client.getSubscriber().getChannelForTopic(topicSubscriber);
        HedwigClientImpl.getResponseHandlerFromChannel(topicSubscriberChannel).getSubscribeResponseHandler()
        .messageConsumed(messageConsumeData.msg);

The channel was retrieved without checking if it was closed and then getPipeline().getLast() was called which returned a null value resulting in a NPE. Moreover, we need to check if the returned Response handler is not null because there is a race here if channel.close() is called after we retrieve the channel and before we call messageConsumed(). 

I guess the same applies for other instances where we use this.
Does the above explanation seem right? 

",2012-08-17 10:42:02,2012-08-28 12:54:28
BOOKKEEPER-372,Check service name in bookie start/stop script.,Bug,1,Closed,6,Fixed,2012-08-17 16:26:38,2012-08-17 14:02:05,2013-02-13T15:46:33.000+0000,nijel,nijel,nijel,Created a patch to check service name in start/stop script mentioned in BOOKKEEPER-296.,2012-08-17 14:02:05,2012-08-17 16:26:38
BOOKKEEPER-374,Bookkeeper doesn't search all ledger directories for index files.,Bug,1,Resolved,5,Fixed,2012-08-20 16:20:32,2012-08-19 08:35:40,2012-08-20T16:20:32.000+0000,,,,"We observed the following behavior when some of the bookkeeper jobs were abruptly restarted a few times.

When the bookies and hedwig hubs were restarted, the hubs tried to query the entries for a particular topic, but an exception was always returned and the reads never completed successfully. 

Eventually, we found that the ledger from which entries couldn't be read actually had 2 index files on disk. We use multiple ledger directories. The first file was in ledger directory number 2 and had a size of 0. The other file which actually contained all the data was in directory 4. 

It doesn't seem right that one ledger has 2 index files. Also, the findIndexFile() function returns the first found ledger index file. Should this be patched to 
1) Throw an exception if more than one file exists (if that's the expected behavior)
2) Do something else?

Any thoughts?

Edit: 
For another ledger, there were 2 files again, created within a minute of each other, on separate directories and with the same size. 

I ran bin/bookie shell ledger -m <ledger_number>. For the most recent file, all entries were N/A, but the other file had all the actual entries. 

So, returning the most recent file might not be the best approach? Should we perhaps check all files?",2012-08-19 08:35:40,2012-08-20 16:20:32
BOOKKEEPER-375,Document about Auto replication service in BK,Sub-task,7,Closed,6,Fixed,2012-12-17 14:42:58,2012-08-22 11:54:06,2013-05-02T02:29:58.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,This JIRA is for documenting the details about auto replication service in BookKeeper.,2012-08-22 11:54:06,2012-12-17 14:42:58
BOOKKEEPER-376,LedgerManagers should consider 'underreplication' node as a special Znode,Sub-task,7,Closed,6,Fixed,2012-08-28 12:26:39,2012-08-22 18:32:57,2013-02-13T15:46:55.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,"Saw this while running the RW tests:

{noformat}
2012-08-22 23:59:35,649 - WARN  - [GarbageCollectorThread:HierarchicalLedgerManager@354] - Exception during garbage collecting ledgers for underreplication of /ledgers
java.io.IOException: java.lang.NumberFormatException: For input string: ""underreplicationlocks0000""
	at org.apache.bookkeeper.meta.HierarchicalLedgerManager.getLedgerId(HierarchicalLedgerManager.java:236)
	at org.apache.bookkeeper.meta.HierarchicalLedgerManager.getStartLedgerIdByLevel(HierarchicalLedgerManager.java:254)
	at org.apache.bookkeeper.meta.HierarchicalLedgerManager.doGcByLevel(HierarchicalLedgerManager.java:388)
	at org.apache.bookkeeper.meta.HierarchicalLedgerManager.garbageCollectLedgers(HierarchicalLedgerManager.java:351)
	at org.apache.bookkeeper.bookie.GarbageCollectorThread.doGcLedgers(GarbageCollectorThread.java:226)
	at org.apache.bookkeeper.bookie.GarbageCollectorThread.run(GarbageCollectorThread.java:195)
Caused by: java.lang.NumberFormatException: For input string: ""underreplicationlocks0000""
	at java.lang.NumberFormatException.forInputString(Unknown Source)
	at java.lang.Long.parseLong(Unknown Source)
	at java.lang.Long.parseLong(Unknown Source)
	at org.apache.bookkeeper.meta.HierarchicalLedgerManager.getLedgerId(HierarchicalLedgerManager.java:234)
	... 5 more
{noformat}
",2012-08-22 18:32:57,2012-08-28 12:26:39
BOOKKEEPER-377,image folder under docs directory is missing from BookKeeper project,Bug,1,Resolved,5,Fixed,2017-10-09 09:48:09,2012-08-23 04:29:25,2017-10-09T09:48:09.000+0000,,,,"Image folder has to be under docs directory for BookKeeper project.
When I was validating the links, I got the error as file missing.
When I went to the project and checked, the image was not displayed for BookKeeper Overview.
",2012-08-23 04:29:25,2017-10-09 09:48:09
BOOKKEEPER-378,ReplicationWorker may not get ZK watcher notification on UnderReplication ledger lock deletion.,Sub-task,7,Closed,6,Fixed,2012-08-24 20:00:22,2012-08-23 10:33:49,2013-02-13T15:46:53.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,"This issue found with BK-248. see [comment|https://issues.apache.org/jira/browse/BOOKKEEPER-248?focusedCommentId=13439426&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13439426]

Issue is: 
1) Two Workers started and trying to get the lock for same ledger.
2) Both worker found that lock file does not exist.
3) both gone ahead for creating the lock node.
4) One worker failed with NodeExists exception

Then it is just removing the children from the list and go for latch wait for the watch notification.

But here unfortunately we added the watch on lockPath with exists check call. But that time lockPatch really did not exists. SO, the lock may be invalid. Then it will never get the notification when lock has been cleaned by other worker.
Here other worker partly replicated and now the current worker should take lock. But it can not get that notification as it added that watch when node does not exist.

",2012-08-23 10:33:49,2012-08-24 20:00:22
BOOKKEEPER-380,ZkLedgerUnderreplicationManager.markLedgerUnderreplicated() is adding duplicate missingReplicas while multiple bk failed for the same ledger,Sub-task,7,Closed,6,Fixed,2012-08-27 10:10:21,2012-08-24 13:55:43,2013-02-13T15:46:30.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"Scenario:-

Say L0001 has ensemble bookies BK1, BK2, BK3.
Publishing BK1 failure: replicaMgr.markLedgerUnderreplicated(L0001, BK1);
Publishing BK2 failure: replicaMgr.markLedgerUnderreplicated(L0001, BK2);

For the second invocation urLedger metadata is updating BK2 twice as follows:
1=replica: ""BK1"", 1=replica: ""BK2"", 1=replica: ""BK2""",2012-08-24 13:55:43,2012-08-27 10:10:21
BOOKKEEPER-381,ReadLastConfirmedOp's Logger class name is wrong,Bug,1,Closed,6,Fixed,2012-08-27 12:44:25,2012-08-25 08:46:03,2013-02-13T15:46:57.000+0000,surendralilhore,Surendra Singh Lilhore,surendrasingh,"In ReadLastConfirmedOp class logger name configured LedgerRecoveryOp.class.

{code}
class ReadLastConfirmedOp implements ReadEntryCallback {
static final Logger LOG = LoggerFactory.getLogger(LedgerRecoveryOp.class);
{code}

It should be ReadLastConfirmedOp.class.",2012-08-25 08:46:03,2012-08-27 12:44:25
BOOKKEEPER-382,space missed at concatenations in GarbageCollectorThread logging,Bug,1,Closed,6,Fixed,2012-08-27 13:16:50,2012-08-25 09:08:43,2013-02-13T15:46:33.000+0000,,,,,2012-08-25 09:08:43,2012-08-27 13:16:50
BOOKKEEPER-383,NPE in BookieJournalTest,Bug,1,Closed,6,Fixed,2012-09-07 13:24:43,2012-08-27 13:28:58,2013-02-13T15:46:52.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Running org.apache.bookkeeper.bookie.BookieJournalTest
Exception in thread ""GarbageCollectorThread"" java.lang.NullPointerException
	at org.apache.bookkeeper.meta.AbstractZkLedgerManager.asyncGetLedgersInSingleNode(AbstractZkLedgerManager.java:191)
	at org.apache.bookkeeper.meta.AbstractZkLedgerManager.getLedgersInSingleNode(AbstractZkLedgerManager.java:268)
	at org.apache.bookkeeper.meta.FlatLedgerManager.garbageCollectLedgers(FlatLedgerManager.java:144)
	at org.apache.bookkeeper.bookie.GarbageCollectorThread.doGcLedgers(GarbageCollectorThread.java:226)

The exception is found in https://builds.apache.org/job/bookkeeper-trunk/671/console",2012-08-27 13:28:58,2012-09-07 13:24:43
BOOKKEEPER-384,Clean up LedgerManagerFactory and LedgerManager usage in tests,Sub-task,7,Closed,6,Fixed,2012-08-31 13:26:38,2012-08-30 09:06:48,2013-02-13T15:46:39.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,This JIRA to address the [review comments|https://issues.apache.org/jira/browse/BOOKKEEPER-304?focusedCommentId=13442424&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13442424] in BOOKKEEPER-304,2012-08-30 09:06:48,2012-08-31 13:26:38
BOOKKEEPER-385,replicateLedgerFragment should throw Exceptions in error conditions,Sub-task,7,Closed,6,Fixed,2012-09-03 16:55:22,2012-08-31 15:35:25,2013-02-13T15:46:41.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,"BookKeeperAdmin#replicateLedgerFragment should throw an exception on error conditions. Currently it only returns boolean, whether it succeeded to not. It should return void, and throw Exceptions in error cases. 

This will allow code using it to possibly resolve the issue causing the exception.",2012-08-31 15:35:25,2012-09-03 16:55:22
BOOKKEEPER-386,It should not be possible to replicate a ledger fragment which is at the end of an open ledger,Sub-task,7,Closed,6,Fixed,2012-09-04 08:39:59,2012-08-31 15:37:08,2013-02-13T15:46:49.000+0000,ikelly,Ivan Kelly,ikelly,"BookKeeperAdmin#replicateLedgerFragment has introduced a code path whereby it is possible to rereplicate a fragment which is at the end of an open ledger. This is dangerous as it could cause the lose of entries, as the client could still be writing when we change the ensemble.",2012-08-31 15:37:08,2012-09-04 08:39:59
BOOKKEEPER-387,BookKeeper Upgrade is not working.,Bug,1,Closed,6,Fixed,2012-09-07 05:27:48,2012-09-04 09:27:35,2013-02-13T15:46:56.000+0000,surendralilhore,Surendra Singh Lilhore,surendrasingh,"I am trying to upgrade BK from 4.1.0 to 4.2.0, but it will log as ""Directory is current, no need to upgrade even then it will continue and fail.
and throwing following exception.
{code}
2012-09-03 17:25:12,468 - ERROR - [main:FileSystemUpgrade@229] - Error moving upgraded directories into place /home/BK4.1/bookkeeper1/ledger/upgradeTmp.2433718456734190 -> /home/BK4.1/bookkeeper1/ledger/current
org.apache.commons.io.FileExistsException: Destination '/home/BK4.1/bookkeeper1/ledger/current' already exists
        at org.apache.commons.io.FileUtils.moveDirectory(FileUtils.java:2304)
        at org.apache.bookkeeper.bookie.FileSystemUpgrade.upgrade(FileSystemUpgrade.java:225)
        at org.apache.bookkeeper.bookie.FileSystemUpgrade.main(FileSystemUpgrade.java:367)
{code}
",2012-09-04 09:27:35,2012-09-07 05:27:48
BOOKKEEPER-388,Document bookie format command,Improvement,4,Closed,6,Fixed,2012-09-21 15:48:10,2012-09-04 10:45:59,2013-02-13T15:46:34.000+0000,kiran_bc,Kiran BC,kiran_bc,"Add the document for the bookie format command implemented in BOOKKEEPER-300

* Formatting BK metadata from zookeeper
{code}<bookkeeper-server>/bin/bookkeeper shell metaformat [-nonInteractive] [-force]{code}

* Formatting Bookie Data
{code}<bookkeeper-server>/bin/bookkeeper shell bookieformat [-nonInteractive] [-force]{code}",2012-09-04 10:45:59,2012-09-21 15:48:10
BOOKKEEPER-389,add documentation for message filter.,Sub-task,7,Closed,6,Fixed,2012-11-30 15:29:30,2012-09-04 13:11:54,2013-02-13T15:46:29.000+0000,hustlmsp,Sijie Guo,hustlmsp,,2012-09-04 13:11:54,2012-11-30 15:29:30
BOOKKEEPER-390,Provide support for ZooKeeper authentication,New Feature,2,Resolved,5,Fixed,2017-03-28 20:40:47,2012-09-04 17:00:33,2017-03-29T14:17:32.000+0000,eolivelli,Enrico Olivelli,eolivelli,"This JIRA adds support for protecting the state of Bookkeeper znodes on a multi-tenant ZooKeeper cluster.

Use case: When user tries to run a ZK cluster in multitenant mode,  where more than one client service would like to share a single ZK service instance (cluster). In this case the client services typically want to protect their data (ZK znodes) from access by other services (tenants) on the cluster. Say you are running BK, HBase or ZKFC instances, etc... having authentication/authorization on the znodes is important for both security and helping to ensure that services don't interact negatively (touch each other's data).
Presently Bookkeeper does not have support for authentication or authorization while accessing to ZK. This should be added to the BK clients/server that are accessing the ZK cluster. In general it means calling addAuthInfo once after a session is established",2012-09-04 17:00:33,2017-03-28 20:40:47
BOOKKEEPER-391,Support Kerberos authentication of bookkeeper,New Feature,2,Resolved,5,Fixed,2017-05-25 11:32:52,2012-09-04 17:11:11,2017-05-25T13:23:02.000+0000,eolivelli,Enrico Olivelli,eolivelli,"This JIRA to discuss authentication mechanism of bookie clients and server. Assume ZK provides fully secured communication channel using Kerberos based authentication and authorization model. We could also manage and renew users authenticated to BK via Kerberos. There is currently no configuration or hooks for the Bookie process to obtain Kerberos credentials.

Today an unauthenticated bookie client can easily establish connection with the bookkeeper server. ",2012-09-04 17:11:11,2017-05-25 11:32:52
BOOKKEEPER-392,Racey ConcurrentMap usage in java hedwig-client,Bug,1,Closed,6,Fixed,2012-09-13 13:53:19,2012-09-04 19:25:36,2013-02-13T15:46:51.000+0000,stuhood,Stu Hood,stuhood,The java hedwig-client misuses ConcurrentMap in various ways.,2012-09-04 19:25:36,2012-09-13 13:53:19
BOOKKEEPER-394,CompositeException message is not useful,Improvement,4,Closed,6,Fixed,2012-09-07 03:13:29,2012-09-04 20:52:01,2013-02-13T15:46:59.000+0000,stuhood,Stu Hood,stuhood,"Exceptions logged via slf4j don't actually have their toString method called, so the current behaviour of overriding toString for CompositeException is rarely/never triggered in client code.

Composing a better `message` field for CompositeException would make it loggable.",2012-09-04 20:52:01,2012-09-07 03:13:29
BOOKKEEPER-395,HDFS dep transitively depends on a busted pom,Bug,1,Closed,6,Fixed,2012-09-07 05:13:35,2012-09-06 23:43:25,2013-02-13T15:47:03.000+0000,stuhood,Stu Hood,stuhood,"hadoop-hdfs-0.23.1 depends on commons-daemon-1.0.3, which has a corrupted pom. Without running artifactory in a loosey-goosey [less restrictive mode|http://wiki.jfrog.org/confluence/display/RT12/Using+Artifactory#UsingArtifactory-OvercomingPathErrors], it will refuse to cache that particular dep:
{noformat}
HTTP/1.1 409 The target deployment path 'commons-daemon/commons-daemon/1.0.3/commons-daemon-1.0.3.pom' does not match the POM's expected path prefix 'org/apache/commons/commons-daemon/1.0.3'. Please verify your POM content for correctness and make sure the source path is a valid Maven repository root path.
{noformat}

Since the bookkeeper-benchmark only uses the HDFS Filesystem and config intefaces, commons-daemon is unnecessary, and can be excluded.",2012-09-06 23:43:25,2012-09-07 05:13:35
BOOKKEEPER-396,Compilation issue in TestClient.java of BenchMark ( showing this in eclipse),Bug,1,Closed,6,Fixed,2012-09-11 08:31:52,2012-09-07 16:25:01,2013-02-13T15:46:35.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,"{code}
import java.util.concurrent.Future;;
{code}

showing here. Simply we can remove one ';'",2012-09-07 16:25:01,2012-09-11 08:31:52
BOOKKEEPER-397,Make the hedwig client in RegionManager configurable.,Bug,1,Closed,6,Fixed,2012-09-26 11:05:00,2012-09-10 20:50:25,2013-02-13T15:47:00.000+0000,i0exception,Aniruddha,i0exception,"The hedwig client used by the region manager uses default client settings. We should provide a way to make this configurable. 

Reviewboard : https://reviews.apache.org/r/7118/",2012-09-10 20:50:25,2012-09-26 11:05:00
BOOKKEEPER-398,Improving stats collection in bookkeeper,Improvement,4,Resolved,5,Fixed,2014-08-25 17:43:21,2012-09-10 23:00:53,2014-09-16T13:26:43.000+0000,i0exception,Aniruddha,i0exception,"We have been experimenting with using the Twitter stats package (http://twitter.github.com/commons/apidocs/com/twitter/common/stats/package-summary.html) for exporting hedwig stats over HTTP. This is open-sourced under the Apache license. The motivation for this was better logging of percentile latencies and requests-per-second (which are difficult to measure with the current implementation of hedwig stats). Is this something the community would be interested in? If so, I could work on a patch. 

Reviewboard : https://reviews.apache.org/r/7134/",2012-09-10 23:00:53,2014-08-25 17:43:21
BOOKKEEPER-399,Let hub server configure write quorum and ack quorum.,New Feature,2,Closed,6,Fixed,2012-12-03 21:43:11,2012-09-11 09:21:47,2013-02-13T15:46:40.000+0000,hustlmsp,Sijie Guo,hustlmsp,"since we support ack quorum in BOOKKEEPER-208, it would be better to let hub server could configure it.",2012-09-11 09:21:47,2012-12-03 21:43:11
BOOKKEEPER-403,ReReadMetadataCb is not executed in the thread responsible for that ledger,Bug,1,Closed,6,Fixed,2012-09-14 09:55:18,2012-09-13 00:18:04,2013-02-13T15:46:58.000+0000,ikelly,Ivan Kelly,ikelly,Attached a patch to execute the callback in bk.mainWorkerPool instead of on the zookeeper thread.,2012-09-13 00:18:04,2012-09-14 09:55:18
BOOKKEEPER-404,Deprecate non-SubscriptionOptions Subscriber Apis,Bug,1,Closed,6,Fixed,2012-12-13 06:27:05,2012-09-13 09:33:28,2013-02-13T15:46:51.000+0000,ikelly,Ivan Kelly,ikelly,"Add deprecation annotation. Add more doc for the SubscriptionOptions versions. Add util methods, to easily create SubscriptionOptions, so that usage is no harder than using the non-SubscriptionOptions versions",2012-09-13 09:33:28,2012-12-13 06:27:05
BOOKKEEPER-405,Let's add Thread name for ReplicationWorker thread.,Sub-task,7,Closed,6,Fixed,2012-09-19 11:04:21,2012-09-14 20:51:09,2013-02-13T15:46:43.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,,2012-09-14 20:51:09,2012-09-19 11:04:21
BOOKKEEPER-408,BookieReadWriteTest will enter the endless loop and will not leave out,Bug,1,Closed,6,Fixed,2012-12-13 17:34:35,2012-09-17 09:28:39,2013-02-13T15:46:27.000+0000,ikelly,Ivan Kelly,ikelly,"When I run the tests of BookKeeper, I found that the test running forever and cannot be finished. The log has the exception that is ""junit.framework.AssertionFailedError: Return code is not OK: -6"". 

I thought this issuse might be come from the synchronization mechanism used by the BookieReadWriteTest.

for example in BookieReadWriteTest.TestReadWriteAsyncSingleClient()
1. when called the function lh.asyncAddEntry(entry.array(), this ,sync), the call back function is addComplete(int, LedgerHandle, long, Object)
2. we can see that in addComplete(..) the function will be fail when rc != BKException.Code.OK, and the x.counter++ will not be called never.
3. we assume that the function addComplete(..) is fail. so, in TestReadWriteAsyncSingleClient(), the while loop enter endless loop because sync.counter < numEntriesToWrite is right forever.

",2012-09-17 09:28:39,2012-12-13 17:34:35
BOOKKEEPER-409,Integration Test - Perform bookie rereplication cycle by Auditor-RW processes,Sub-task,7,Closed,6,Fixed,2013-01-03 10:06:48,2012-09-20 13:16:50,2013-05-02T02:29:55.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,The idea is to perform integration testing of entire re-replication module : Auditor-RW processes,2012-09-20 13:16:50,2013-01-03 10:06:48
BOOKKEEPER-411,Add CloseSubscription Request for multiplexing support,Sub-task,7,Closed,6,Fixed,2012-10-22 11:05:56,2012-09-23 12:36:07,2013-02-13T15:47:05.000+0000,hustlmsp,Sijie Guo,hustlmsp,"for multiplexing, we could not close the underlying channel directly when closing subscription. so we need to close subscription from server side.",2012-09-23 12:36:07,2012-10-22 11:05:56
BOOKKEEPER-412,Load subscription lazily only when the subscriber creates or attaches it.,New Feature,2,Resolved,5,Won't Do,2017-10-09 09:47:57,2012-09-23 13:38:46,2017-10-09T09:47:57.000+0000,,,,"Currently we load all subscriptions into memory when the topic is acquired. But it is unnecessary, it could be improved to load the subscription only when it is created or attached. ",2012-09-23 13:38:46,2017-10-09 09:47:57
BOOKKEEPER-413,Hedwig C++ client: Rename RUN_AS_SSL_MODE to SSL_ENABLED,Bug,1,Closed,6,Fixed,2012-10-10 10:10:51,2012-10-01 13:38:03,2013-02-13T15:46:28.000+0000,ikelly,Ivan Kelly,ikelly,"Minor change, SSL_ENABLED is neater IMO.",2012-10-01 13:38:03,2012-10-10 10:10:51
BOOKKEEPER-414,"Figure out root cause of hedwig C++ ssl shutdown issues on mac, remove __APPLE__ ifdefs",Bug,1,Resolved,5,Won't Do,2017-10-09 09:47:43,2012-10-01 13:40:35,2017-10-09T09:47:43.000+0000,,,,"While using ifdefs on __APPLE__ works for now, it would be good to pin down the root cause of the crash to verify it isn't a timing bug that only manifests on Mac due to having a different scheduler.",2012-10-01 13:40:35,2017-10-09 09:47:43
BOOKKEEPER-415,Rename DeliveryThrottle to MessageWindowSize,Bug,1,Closed,6,Fixed,2012-10-10 09:46:29,2012-10-04 15:00:00,2013-02-13T15:46:56.000+0000,ikelly,Ivan Kelly,ikelly,"In hedwig server, DeliveryThrottle is a little inaccurate as it suggests that the rate is being limited, rather than a outstanding message limit being reached. I think MessageWindowSize is more accurate, and is analogous to windowing in tcp, which this mechanism actually replaces.",2012-10-04 15:00:00,2012-10-10 09:46:29
BOOKKEEPER-416,LedgerChecker returns underreplicated fragments for an closed ledger with no entries,Sub-task,7,Closed,6,Fixed,2012-10-25 14:51:05,2012-10-04 17:22:16,2013-02-13T15:46:22.000+0000,ikelly,Ivan Kelly,ikelly,"It should return no underreplicated fragments. This causes a problem because as it can never become ""fully replicated"" as there are no entries to replicate, everything hangs.",2012-10-04 17:22:16,2012-10-25 14:51:05
BOOKKEEPER-417,Hierarchical zk underreplication manager should clean up its hierarchy when done to allow for fast acquisition of underreplicated entries,Sub-task,7,Closed,6,Fixed,2012-10-16 15:02:37,2012-10-04 17:25:55,2013-02-13T15:46:31.000+0000,ikelly,Ivan Kelly,ikelly,"As we traverse the hierarchy to find a underreplicated fragment, leaving the hierarchy will cause the traversal to search in many empty znodes.",2012-10-04 17:25:55,2012-10-16 15:02:37
BOOKKEEPER-418,Store hostname of locker in replication lock,Sub-task,7,Closed,6,Fixed,2012-10-10 10:30:10,2012-10-04 17:27:44,2013-02-13T15:46:54.000+0000,ikelly,Ivan Kelly,ikelly,"This is a debugging shortcut. If a ledger isn't being processed for a long time, this allows us to find which host is trying to rereplicate, and go look at the logs there.",2012-10-04 17:27:44,2012-10-10 10:30:10
BOOKKEEPER-422,Simplify AbstractSubscriptionManager,Improvement,4,Closed,6,Fixed,2012-10-17 09:21:04,2012-10-07 03:08:52,2013-02-13T15:46:52.000+0000,stuhood,Stu Hood,stuhood,"It's difficult to maintain a duplicated/cached count of local subscribers, and we've experienced a few issues due to it getting out of sync with the actual set of subscribers. Since a count of local subscribers can be calculated from the top2sub2seq map, let's do that instead.",2012-10-07 03:08:52,2012-10-17 09:21:04
BOOKKEEPER-424,Bookie start is failing intermittently when zkclient connection delays,Bug,1,Closed,6,Fixed,2012-10-25 13:36:44,2012-10-07 08:46:52,2013-02-13T15:46:52.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"I'm seeing the following intermittent failure, when there is a delay in establishing zkclient connection with zkserver. 
{code}
org.apache.bookkeeper.bookie.BookieException$InvalidCookieException: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /ledgers/INSTANCEID
	at org.apache.bookkeeper.bookie.Bookie.checkEnvironment(Bookie.java:329)
	at org.apache.bookkeeper.bookie.Bookie.<init>(Bookie.java:378)
	at org.apache.bookkeeper.bookie.BookieInitializationTest.testStartBookieWithoutZKServer(BookieInitializationTest.java:253)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)
	at java.lang.reflect.Method.invoke(Unknown Source)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.FailOnTimeout$1.run(FailOnTimeout.java:28)
Caused by: org.apache.zookeeper.KeeperException$ConnectionLossException: KeeperErrorCode = ConnectionLoss for /ledgers/INSTANCEID
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:99)
	at org.apache.zookeeper.KeeperException.create(KeeperException.java:51)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1131)
	at org.apache.zookeeper.ZooKeeper.getData(ZooKeeper.java:1160)
	at org.apache.bookkeeper.bookie.Bookie.getInstanceId(Bookie.java:346)
	at org.apache.bookkeeper.bookie.Bookie.checkEnvironment(Bookie.java:280)
	... 11 more
{code}",2012-10-07 08:46:52,2012-10-25 13:36:44
BOOKKEEPER-425,Cleanup Bookie id generation,Bug,1,Closed,6,Fixed,2012-10-26 14:27:54,2012-10-09 08:23:14,2013-02-13T15:46:47.000+0000,ikelly,Ivan Kelly,ikelly,"Bookie id generation (InetAddress.getLocalHost().getHostAddress() + "":"" + port) is scattered all over the place. It would be better to have it centrallized somewhere in a static call.",2012-10-09 08:23:14,2012-10-26 14:27:54
BOOKKEEPER-426,Make auditor Vote znode store a protobuf containing the host that voted,Sub-task,7,Closed,6,Fixed,2012-12-14 10:19:37,2012-10-09 08:36:24,2013-02-13T15:46:28.000+0000,ikelly,Ivan Kelly,ikelly,"It currently stores a byte[], its better to use a protobuf in case we need to add more info later or actually use the info for something more than debugging.",2012-10-09 08:36:24,2012-12-14 10:19:37
BOOKKEEPER-427,TestConcurrentTopicAcquisition hangs every so often,Bug,1,Closed,6,Fixed,2012-10-23 13:24:00,2012-10-09 09:39:33,2013-02-13T15:46:39.000+0000,ikelly,Ivan Kelly,ikelly,"I'm seeing this test hang every so often. To repro:
{code}
while [ $? = 0 ]; do mvn test -Dtest=TestConcurrentTopicAcquisition; done
{code}",2012-10-09 09:39:33,2012-10-23 13:24:00
BOOKKEEPER-428,Expose command options in bookie scripts to disable/enable auto recovery temporarily,Sub-task,7,Closed,6,Fixed,2012-12-14 19:27:48,2012-10-10 03:08:09,2013-05-02T02:29:58.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,Administrators can invoke disable/enable autorecovery options through bookie shell.,2012-10-10 03:08:09,2012-12-14 19:27:48
BOOKKEEPER-429,Provide separate read and write threads in the bookkeeper server,Improvement,4,Resolved,5,Fixed,2014-01-21 04:05:37,2012-10-11 07:27:58,2014-01-21T04:28:15.000+0000,i0exception,Aniruddha,i0exception,"The current bookkeeper server is single threaded. The same thread handles reads and writes. When reads are slow (possibly because of excessive seeks), add entry operations suffer in terms of latencies. Providing separate read and write threads helps in reducing add entry latencies and increasing throughput even when we're facing slow reads. Having a single read thread also results in low disk utilization because seeks can't be ordered efficiently by the OS. Multiple read threads would help in improving the read throughput. 

Discussion on this can be found at http://mail-archives.apache.org/mod_mbox/zookeeper-bookkeeper-dev/201209.mbox/%3cCAOLhyDQpzn-v10zyNFwUd_h0qzRxtmJgTTx7a9eoFoHYytyJbA@mail.gmail.com%3e

Reviewboard : https://reviews.apache.org/r/7560/",2012-10-11 07:27:58,2014-01-21 04:05:37
BOOKKEEPER-430,Remove manual bookie registration from overview,Improvement,4,Closed,6,Fixed,2012-10-31 10:41:53,2012-10-12 15:28:17,2013-02-13T15:46:49.000+0000,fpj,Flavio Paiva Junqueira,fpj,"The documentation suggests that a user needs to manually register a bookie, which is not right.",2012-10-12 15:28:17,2012-10-31 10:41:53
BOOKKEEPER-431,Duplicate definition of COOKIES_NODE,Improvement,4,Closed,6,Fixed,2012-12-08 10:19:39,2012-10-12 15:50:46,2013-02-13T15:46:25.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,"Is it necessary two definitions of COOKIES_NODE, one in cookie.java and one in AbstractZkLedgerManager?",2012-10-12 15:50:46,2012-12-08 10:19:39
BOOKKEEPER-432,Improve performance of entry log range read per ledger entries ,Improvement,4,Resolved,5,Fixed,2014-03-12 20:27:59,2012-10-13 00:55:06,2014-03-12T20:58:27.000+0000,yx3zhu@gmail.com,Yixue Zhu,yx3zhu@gmail.com,"We observed random I/O reads when some subscribers fall behind (on some topics), as delivery needs to scan the entry logs (thru ledger index), which are interleaved with ledger entries across all ledgers being served.

Essentially, the ledger index is a non-clustered index. It is not effective when a large number of ledger entries need to be served, which tend to be scattered around due to interleaving.

Some possible improvements:
1. Change the ledger entries buffer to use a SkipList (or other suitable), sorted on (ledger, entry sequence). When the buffer is flushed, the entry log is written out in the already-sorted order. 

The ""active"" ledger index can point to the entries buffer (SkipList), and fixed up with entry-log position once latter is persisted.

Or, the ledger index can be just rebuilt on demand. The entry log file tail can have index attached (light-weight b-tree, similar with big-table). We need to track per ledger which log files contribute entries to it, so that in-memory index can be rebuilt from the tails of corresponding log files.

2. Use affinity concept to make ensembles of ledgers (belonging to same topic) as identical as possible. This will help above 1. be more effective.
 ",2012-10-13 00:55:06,2014-03-12 20:27:59
BOOKKEEPER-434,[Hedwig CPP Client] Delay resolving default host until necessary.,Bug,1,Closed,6,Fixed,2012-10-31 17:19:07,2012-10-15 10:22:11,2013-02-13T15:47:05.000+0000,hustlmsp,Sijie Guo,hustlmsp,"1) default host might a VIP like name, we could delay resolving default host until necessary. so we could leverage the round-robin mechanism behind default server.

2) we should not fail the process (throwing exception) when the default server isn't reachable temporary. we could fail the request at that time.",2012-10-15 10:22:11,2012-10-31 17:19:07
BOOKKEEPER-435,Create SubscriptionChannelManager to manage all subscription channel,Sub-task,7,Closed,6,Fixed,2012-10-22 10:15:26,2012-10-15 12:54:10,2013-02-13T15:46:47.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Currently SubscriberHandle is too heavy to manage all subscription channels in it. Make a SubscriptionChannelManager to manage all subscription channels to easy things, which makes it clearly.",2012-10-15 12:54:10,2012-10-22 10:15:26
BOOKKEEPER-436,Journal#rollLog may leak file handler,Bug,1,Closed,6,Fixed,2012-10-16 21:21:32,2012-10-16 17:38:19,2013-02-13T15:46:50.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,"Just seen the peice of code in Jouranl#rollLog 
{code}
try {
                    FileOutputStream fos = new FileOutputStream(file);
                    fos.write(buff);
                    fos.getChannel().force(true);
                    fos.close();
                } catch (IOException e) {
                    LOG.error(""Problems writing to "" + file, e);
                }
{code}

On exception It is just logging and continuing.
Even though FileOutputStream provides finalize implementation and which will clean streams, I don't think it's a good idea to depend on it as it will not be garanteed.

cleaning with more care would avoid this.",2012-10-16 17:38:19,2012-10-16 21:21:32
BOOKKEEPER-438,Move ledger id generation out of LedgerManager,Sub-task,7,Closed,6,Fixed,2015-12-02 07:40:23,2012-10-17 03:28:31,2016-02-01T21:10:16.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Move id generation out of LedgerManager to ensure different ledger manager implementation shared same ledger id space in ZooKeeper, which is necessary for migration between different ledger managers.",2012-10-17 03:28:31,2015-12-02 07:40:23
BOOKKEEPER-439,No more messages delivered after deleted consumed ledgers.,Bug,1,Closed,6,Fixed,2012-10-26 13:17:45,2012-10-19 10:08:27,2013-02-13T15:46:55.000+0000,hustlmsp,Sijie Guo,hustlmsp,"We encountered exception as below:

{quote}

2012-10-18 09:27:27,248 - DEBUG [CacheThread:BookkeeperPersistenceManager$RangeScanOp@247] - Issuing a bk read for ledger: L2 from entry-id: 100 to entry-id: 103
2012-10-18 09:27:27,248 - ERROR [CacheThread:BookkeeperPersistenceManager$RangeScanOp$2@261] - Error while reading from ledger: L2 for topic: TOPIC
org.apache.bookkeeper.client.BKException$BKReadException
        at org.apache.bookkeeper.client.BKException.create(BKException.java:48)
        at org.apache.hedwig.server.persistence.BookkeeperPersistenceManager$RangeScanOp$2.safeReadComplete(BookkeeperPersistenceManager.java:260)
        at org.apache.hedwig.zookeeper.SafeAsynBKCallback$ReadCallback.readComplete(SafeAsynBKCallback.java:61)
        at org.apache.bookkeeper.client.LedgerHandle.asyncReadEntries(LedgerHandle.java:380)
        at org.apache.hedwig.server.persistence.BookkeeperPersistenceManager$RangeScanOp.read(BookkeeperPersistenceManager.java:252)
        at org.apache.hedwig.server.persistence.BookkeeperPersistenceManager$RangeScanOp.startReadingFrom(BookkeeperPersistenceManager.java:327)
        at org.apache.hedwig.server.persistence.BookkeeperPersistenceManager$RangeScanOp.runInternal(BookkeeperPersistenceManager.java:217)
        at org.apache.hedwig.server.common.TopicOpQueuer$SynchronousOp.run(TopicOpQueuer.java:77)
        at org.apache.hedwig.server.common.TopicOpQueuer.pushAndMaybeRun(TopicOpQueuer.java:105)
        at org.apache.hedwig.server.persistence.BookkeeperPersistenceManager.scanMessages(BookkeeperPersistenceManager.java:336)
        at org.apache.hedwig.server.persistence.ReadAheadCache$ScanRequestWrapper.performRequest(ReadAheadCache.java:704)
        at org.apache.hedwig.server.persistence.ReadAheadCache.run(ReadAheadCache.java:291)
        at java.lang.Thread.run(Thread.java:662)

{quote}

topic TOPIC has 2 ledgers L1, L2, each ledger has 100 entries.

1) all the 100 entries in L1 has been delivered and consumed.
2) 100 entries have been wrote to L2 but not delivered.
3) L1 is deleted since all its entries have been consumed.
4) hub server shuts down
5) TOPIC recovered L2 and started delivering from 101.

TOPIC was expected to issue a read [0-3] from L2, but a read [100-103] was issued from the exception log, so no entries would be expected to read from L2 at [100-103].

The problem of this issue is that we used 0 and 1 for the start of message id and ledger id even we had some consumed ledgers deleted.

{code}
        void processTopicLedgerRanges(final LedgerRanges ranges, final Version version) {
            Iterator<LedgerRange> lrIterator = ranges.getRangesList().iterator();
            TopicInfo topicInfo = new TopicInfo();

            long startOfLedger = 1;

            while (lrIterator.hasNext()) {
                LedgerRange range = lrIterator.next();

                if (range.hasEndSeqIdIncluded()) {
                    // this means it was a valid and completely closed ledger
                    long endOfLedger = range.getEndSeqIdIncluded().getLocalComponent();
                    topicInfo.ledgerRanges.put(endOfLedger, new InMemoryLedgerRange(range,           startOfLedger));                             startOfLedger = endOfLedger + 1;
                    continue;
                }        

                // If it doesn't have a valid end, it must be the last ledger
                if (lrIterator.hasNext()) {
                    String msg = ""Ledger-id: "" + range.getLedgerId() + "" for topic: "" + topic.       toStringUtf8()                                            + "" is not the last one but still does not have an end seq-id"";
                    logger.error(msg);
                    cb.operationFailed(ctx, new PubSubException.UnexpectedConditionException(msg));
                    return;                }

                // The last ledger does not have a valid seq-id, lets try to
                // find it out
                recoverLastTopicLedgerAndOpenNewOne(range.getLedgerId(), version, topicInfo);
                return;
            }
{code}

{code}
                            long prevLedgerEnd = topicInfo.ledgerRanges.isEmpty() ? 0 : topicInfo.   ledgerRanges
                                                 .lastKey();
                            LedgerRange lr = LedgerRange.newBuilder().setLedgerId(ledgerId)
                                             .setEndSeqIdIncluded(lastMessage.getMsgId()).build();
                            topicInfo.ledgerRanges.put(lr.getEndSeqIdIncluded().getLocalComponent(),
                                    new InMemoryLedgerRange(lr, prevLedgerEnd + 1, lh));
{code}",2012-10-19 10:08:27,2012-10-26 13:17:45
BOOKKEEPER-440,Make Write/Delete SubscriptionData Restricted to Version,Sub-task,7,Closed,6,Fixed,2012-11-26 17:51:07,2012-10-23 10:22:38,2013-02-13T15:47:03.000+0000,lvfangmin,Fangmin Lv,lvfangmin,Using conditional write/delete will make operating metadata more safely. It is also a requirement for metadata migration.,2012-10-23 10:22:38,2012-11-26 17:51:07
BOOKKEEPER-441,InMemorySubscriptionManager should back up top2sub2seq before change it,Bug,1,Closed,6,Fixed,2012-10-26 10:13:38,2012-10-24 16:37:10,2013-02-13T15:46:40.000+0000,yx3zhu@gmail.com,Yixue Zhu,yx3zhu@gmail.com,"On topic loss, InMemorySubscriptionManager currently does not clear top2sub2seq. The intent is to allow readSubscription to get the information there. This introduce dependency outside the class, evidence is that general ReleaseOp has to use a boolean parameter which targets this implementation detail. Further, this prevents Acquire-topic to notify listeners (notifyFirstLocalSubscribe is not called) of first subscription to act appropriately.",2012-10-24 16:37:10,2012-10-26 10:13:38
BOOKKEEPER-442,Failed to deliver messages due to inconsistency between SubscriptionState and LedgerRanges.,Bug,1,Closed,6,Fixed,2012-12-03 15:28:33,2012-10-25 05:10:57,2013-02-13T15:46:42.000+0000,jiannan,Jiannan Wang,jiannan,"The problems encountered when failed to updateSubscriptionState but deleted consumed ledgers. 

The issue is described as below:

1) A subscriber setLastConsumeSeqId to move consume ptr. If the consume ptr is moved over consume interval, an update subscription state operation is issued to update to ZooKeeper.

{code}

AbstractSubscriptionManager:

            
            if (subState.setLastConsumeSeqId(consumeSeqId, cfg.getConsumeInterval())) {                updateSubscriptionState(topic, subscriberId, subState, cb, ctx);
            }
{code}

2) when move consume ptr, it also changed in-memory subscription state before the subscription state is persisted to ZooKeeper.

{code}
    public boolean setLastConsumeSeqId(MessageSeqId lastConsumeSeqId, int consumeInterval) {
        long interval = lastConsumeSeqId.getLocalComponent() - subscriptionState.getMsgId().          getLocalComponent();
        if (interval <= 0) {
            return false;
        }

        // set consume seq id when it is larger
        this.lastConsumeSeqId = lastConsumeSeqId;
        if (interval < consumeInterval) {
            return false;
        }

        // subscription state will be updated, marked it as clean
        subscriptionState = SubscriptionState.newBuilder(subscriptionState).                          setMsgId(lastConsumeSeqId).build();
        return true;
    }
{code}

3) MessageConsumedTask runs periodically to delete consumed ledgers. it would use in-memory subscription state to perform such deletion. so if ledger is deleted first and failed to update subscription state. it would cause inconsistent state, when hub restarts and subscriber reconnects, it would use old seq id to start delivering but the ledger has messages with old seq id has been deleted.

{code}
for (InMemorySubscriptionState curSubscription : topicSubscriptions.values()) {
                    if (curSubscription.getSubscriptionState().getMsgId().getLocalComponent() <       minConsumedMessage)
                        minConsumedMessage = curSubscription.getSubscriptionState().getMsgId().       getLocalComponent();
                    hasBound = hasBound && curSubscription.getSubscriptionPreferences().              hasMessageBound();
                }
{code} 

The fix would be let message consume task only use persistence state to performance deletions only. ",2012-10-25 05:10:57,2012-12-03 15:28:33
BOOKKEEPER-444,Refactor pending read op to make speculative reads possible,Sub-task,7,Closed,6,Fixed,2012-11-07 16:28:10,2012-10-25 15:01:26,2013-02-13T15:46:26.000+0000,ikelly,Ivan Kelly,ikelly,The code to handle the state of a single entry read request is scattered all over PendingReadOp. Some even leaks into LedgerEntry. This jira is to refactor this code into one place to make speculative reads easier to implement.,2012-10-25 15:01:26,2012-11-07 16:28:10
BOOKKEEPER-446,BookKeeper.createLedger(..) should not mask the error with ZKException,Bug,1,Resolved,5,Fixed,2013-09-10 13:15:15,2012-10-29 08:32:02,2013-09-10T13:43:08.000+0000,hustlmsp,Sijie Guo,hustlmsp,"in {{BookKeeper.createLedger()}} following code is masking the error with ZKException. Should throw the original exception to client.

{code}        if (counter.getLh() == null) {
            LOG.error(""ZooKeeper error: "" + counter.getrc());
            throw BKException.create(Code.ZKException);
        }{code}

",2012-10-29 08:32:02,2013-09-10 13:15:15
BOOKKEEPER-447,Bookie can fail to recover if index pages flushed before ledger flush acknowledged,Bug,1,Closed,6,Fixed,2012-12-24 05:23:50,2012-10-30 01:30:46,2013-02-13T15:46:25.000+0000,ikelly,Ivan Kelly,ikelly,"Bookie index page steal (LedgerCacheImpl::grabCleanPage) can cause index file to reflect unacknowledged entries (due to flushLedger). Suppose ledger and entry fail to flush due to Bookkeeper server crash, it will cause ledger recovery not able to use the bookie afterward, due to InterleavedStorageLedger::getEntry throws IOException.
If the ackSet bookies all experience this problem (DC environment), the ledger will not be able to recover.
The problem here essentially a violation of WAL. One reasonable fix is to track ledger flush progress (either per-ledger entry, or per-topic message). Do not flush index pages which tracks entries whose ledger (log) has not been flushed.",2012-10-30 01:30:46,2012-12-24 05:23:50
BOOKKEEPER-448,Reduce publish latency when changing ledgers,Sub-task,7,Resolved,5,Won't Do,2017-10-09 09:47:31,2012-10-31 07:26:28,2017-10-09T09:47:31.000+0000,,,,"As in BOOKKEEPER-191, we changed ledgers to let consumed messages be garbage collected. But introduced latency in publishing, when changing ledgers, the published messages would be queued until finished created ledger and update ledger ranges. All the queued messages's latency would be affected by the metadata operations.",2012-10-31 07:26:28,2017-10-09 09:47:31
BOOKKEEPER-449,"Zombie ledgers, how to deal with them?",Improvement,4,Reopened,4,,,2012-10-31 07:33:42,2017-10-17T21:29:44.000+0000,,,,"Currently, when acquiring topic or changing ledgers for a topic, hub server created ledger first and updated ledger ranges later. if hub server crashed between created ledger and update ledger ranges. the created ledger would become a zombie.",2012-10-31 07:33:42,
BOOKKEEPER-450,It would be better to remove bookie related data from ZooKeeper after bookie recover.,Improvement,4,Reopened,4,,,2012-10-31 07:47:38,2017-10-17T21:29:41.000+0000,,,,"Currently we had some bookie related data stored in ZooKeeper liked cookie. When we run BookKeeperAdmin to manually recover a bookie, it would be better to remove its related bookie data from ZooKeeper after recover successfully. otherwise, its zombie data would be still in ZooKeeper even we retired that bookie node.",2012-10-31 07:47:38,
BOOKKEEPER-452,Rename ClientConfiguration multiplexing_enabled to subscription_connection_sharing_enabled,Sub-task,7,Closed,6,Fixed,2012-11-07 11:00:36,2012-11-02 16:21:21,2013-02-13T15:46:31.000+0000,hustlmsp,Sijie Guo,hustlmsp,"multiplexing is quite cryptic, and would be hard for someone not associated with hedwig to understand. Something like subscription connection sharing, or subscription channel sharing is clearer. Or even channel sharing alone.",2012-11-02 16:21:21,2012-11-07 11:00:36
BOOKKEEPER-453,Extract commonality from MultiplexSubscribeResponseHandler and SimpleSubscribeResponseHandler and put into an abstract class,Sub-task,7,Closed,6,Fixed,2012-12-07 11:22:38,2012-11-02 16:24:20,2013-02-13T15:46:36.000+0000,hustlmsp,Sijie Guo,hustlmsp,"SimpleSubscribeResponseHandler seems to be a special case of MultiplexSubscribeResponseHandler (i.e, a multiplex subscribe response handler with only one topic subscriber).

It would be good to take advantage of this to reduce future maintenance costs.",2012-11-02 16:24:20,2012-12-07 11:22:38
BOOKKEEPER-454,hedwig c++ tester script assumes sh is bash,Bug,1,Closed,6,Fixed,2012-11-22 17:36:49,2012-11-02 20:42:50,2013-02-13T15:46:24.000+0000,ikelly,Ivan Kelly,ikelly,"in debian, sh is dash. so the tests fail.",2012-11-02 20:42:50,2012-11-22 17:36:49
BOOKKEEPER-457,Create a format command for Hedwig to cleanup its metadata.,Bug,1,Closed,6,Fixed,2012-11-29 14:20:42,2012-11-06 06:51:54,2013-02-13T15:46:54.000+0000,hustlmsp,Sijie Guo,hustlmsp,Create a format command for Hedwig to cleanup metadata for a clean setup. similar as BOOKKEEPER-300.,2012-11-06 06:51:54,2012-11-29 14:20:42
BOOKKEEPER-458,Annoy BKReadException error when changing ledger.,Bug,1,Closed,6,Fixed,2012-12-13 11:52:50,2012-11-06 14:37:32,2013-02-13T15:46:27.000+0000,jiannan,Jiannan Wang,jiannan,"Some annoy BKReadException are found when changing ledger.

1) suppose Topic T has ledger L1, storing messages starting from 1 - 100.
2) T changed ledger to write entry to ledger L2.
3) Before the entry is added successfully, Subscribe s subscribed topic T. ReadAhead cache tried to schedule a ReadAhead request to scan (103, 104).
4) RangeScanOp in BookKeeperPersistentManager executed to read entry 2 & 3 from L2. but actually there was no entries in L2.

{code:title=BookKeeperPersistentManager.java}
// None of the old ledgers have this seq-id, we must use the
                // current ledger
                long endSeqId = topicInfo.currentLedgerRange.getStartSeqIdIncluded()
                                + topicInfo.lastEntryIdAckedInCurrentLedger;

                if (endSeqId < startSeqId) {
                    request.getCallback().scanFinished(request.ctx, ReasonForFinish.NO_MORE_MESSAGES);                    return;
                }
{code} 

The code in BookKeeperPersistentManager is supposed to not scan any messages whose seq id is larger than lastEntryIdAckedInCurrentLedger. But lastEntryIdAckedInCurrentLedger isn't reset when changing ledger. so when RangeScanOp is executed, last entry id acked in previous ledger was used which causing calculating an error seq id for the boundary checking in RangeScanOp.

The fix would be quite easy to reset lastEntryIdAckedInCurrentLedger when changing ledger. But we need a test case to cover this case.",2012-11-06 14:37:32,2012-12-13 11:52:50
BOOKKEEPER-459,Rename metastore mock implementation to InMemory implementation,Sub-task,7,Closed,6,Fixed,2012-12-03 13:55:57,2012-11-09 16:15:13,2013-02-13T15:46:34.000+0000,jiannan,Jiannan Wang,jiannan,"It's a test component, so it should really be in the test tree.",2012-11-09 16:15:13,2012-12-03 13:55:57
BOOKKEEPER-460,LedgerDeleteTest checks wrong place for log file,Test,6,Closed,6,Fixed,2012-11-26 15:43:33,2012-11-10 10:51:55,2013-02-13T15:46:39.000+0000,lvfangmin,Fangmin Lv,lvfangmin,"A minor problem, it seems forgot to update LedgerDeleteTest after upgrade bookkeeper filesystem.
{code:xml}
// Verify that the first entry log (0.log) has been deleted from all of the Bookie Servers.
for (File ledgerDirectory : tmpDirs) {
    for (File f : ledgerDirectory.listFiles()) {
        assertFalse(""Found the entry log file (0.log) that should have been deleted in ledgerDirectory: "" 
            + ledgerDirectory, f.isFile() && f.getName().equals(""0.log""));
    }
}
{code} 
Solution:
Just reuse the checkLogFiles method in CompactionTest.",2012-11-10 10:51:55,2012-11-26 15:43:33
BOOKKEEPER-461,Delivery throughput degrades when there are lots of publishers w/ high traffic.,Bug,1,Closed,6,Fixed,2012-12-04 17:56:12,2012-11-11 14:39:41,2013-02-13T15:46:49.000+0000,hustlmsp,Sijie Guo,hustlmsp,"When running benchmarking over the hub server, found that delivery throughput degrades when there are lots of publishers publishing messages. And the delivery throughput will goes up when there is no publishes.

This issue is introduced due to ReadAheadCache only runs a single thread. So when the netty workers are busy handling publish requests, they are pushing lots of messages into ReadAheadCache's queue to put them in to read ahead cache. So the readahead cache is busy on updating keys.",2012-11-11 14:39:41,2012-12-04 17:56:12
BOOKKEEPER-463,Refactor garbage collection code for ease to plugin different GC algorithm.,Sub-task,7,Closed,6,Fixed,2012-12-24 04:51:17,2012-11-12 12:39:29,2013-05-02T02:29:58.000+0000,lvfangmin,Fangmin Lv,lvfangmin,,2012-11-12 12:39:29,2012-12-24 04:51:17
BOOKKEEPER-464,Provide an improved GC algorithm,Sub-task,7,Resolved,5,Won't Do,2017-10-09 09:44:39,2012-11-12 12:40:19,2017-10-09T09:44:39.000+0000,lvfangmin,Fangmin Lv,lvfangmin,,2012-11-12 12:40:19,2017-10-09 09:44:39
BOOKKEEPER-465,CreateNewLog may overwrite lastLogId with smaller value ,Bug,1,Closed,6,Fixed,2012-12-10 10:04:46,2012-11-14 05:51:14,2013-02-13T15:46:41.000+0000,yx3zhu@gmail.com,Yixue Zhu,yx3zhu@gmail.com,"In createNewLog(), only one directory is searched to check for duplicate log id.
Then the id is used to overwrite lastLogId.

It looks like regression from BOOKKEEPER-345. 

     // It would better not to overwrite existing entry log files
    File newLogFile = null;
        do {
            String logFileName = Long.toHexString(++logId) + "".log"";
            File dir = ledgerDirsManager.pickRandomWritableDir();
            newLogFile = new File(dir, logFileName);
            currentDir = dir;
            if (newLogFile.exists()) {
                LOG.warn(""Found existed entry log "" + newLogFile
                        + "" when trying to create it as a new log."");
                newLogFile = null;
                continue;
            }
        } while (newLogFile == null);",2012-11-14 05:51:14,2012-12-10 10:04:46
BOOKKEEPER-466,ZooKeeper test utility sets the port number as the tickTime,Bug,1,Closed,6,Fixed,2012-11-21 11:24:50,2012-11-19 10:51:46,2013-05-02T02:29:58.000+0000,ikelly,Ivan Kelly,ikelly,"This causes issues if the zookeeper port, is very high, as the minSessionTimeout is 2*tickTime by default. ",2012-11-19 10:51:46,2012-11-21 11:24:50
BOOKKEEPER-467,Allocate ports for testing dynamically,Bug,1,Closed,6,Fixed,2012-11-23 10:51:18,2012-11-19 10:53:29,2013-05-02T02:29:58.000+0000,ikelly,Ivan Kelly,ikelly,"We're getting a lot of failures in jenkins because we use hardcoded ports. If another build is using these ports (jenkins runs builds in parallel), we get a failure. The ZooKeeper port is particularly bad as a lot of apache projects use zookeeper, and therefore use it for testing.",2012-11-19 10:53:29,2012-11-23 10:51:18
BOOKKEEPER-468,Remove <echo> from protobuf generation in hedwig,Bug,1,Closed,6,Fixed,2012-11-21 09:32:09,2012-11-19 10:54:13,2013-02-13T15:46:50.000+0000,ikelly,Ivan Kelly,ikelly,There's some debugging <echo> tags in the pom.xml script for generating the protobuf scripts. They should be removed.,2012-11-19 10:54:13,2012-11-21 09:32:09
BOOKKEEPER-469,Remove System.out.println from TestLedgerManager,Bug,1,Closed,6,Fixed,2012-12-10 09:59:12,2012-11-19 10:55:20,2013-02-13T15:46:30.000+0000,ikelly,Ivan Kelly,ikelly,TestLedgerManager has a System.out.println in it. Tests should only ever go through slf4j.,2012-11-19 10:55:20,2012-12-10 09:59:12
BOOKKEEPER-470,Possible infinite loop in simple.SubscribeReconnectCallback,Bug,1,Closed,6,Fixed,2012-12-04 17:28:39,2012-11-19 10:59:34,2013-02-13T15:47:00.000+0000,ikelly,Ivan Kelly,ikelly,"SubscribeReconnectCallback#operationFailed calls
SubscribeReconnectCallback#retrySubscribeRequest calls
channelManager#submitOpAfterDelay calls
SubscribeReconnectCallback#operationFailed (if closed is true).",2012-11-19 10:59:34,2012-12-04 17:28:39
BOOKKEEPER-471,Add scripts for preCommit testing,Bug,1,Closed,6,Fixed,2012-11-27 09:52:59,2012-11-19 12:28:44,2013-05-02T02:29:58.000+0000,ikelly,Ivan Kelly,ikelly,We should have jenkins test patches automatically before submission. This JIRA is to set that up.,2012-11-19 12:28:44,2012-11-27 09:52:59
BOOKKEEPER-472,Provide an option to start Autorecovery along with Bookie Servers,Sub-task,7,Closed,6,Fixed,2013-01-14 16:03:06,2012-11-19 12:45:14,2013-02-13T15:46:38.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,"We can also have an option to start the Autorecovery along with Bookie servers.
If some users are not having too much load on the servers, they can even start them along the Bookie servers. If they feel, Auditor would disturb Bookie performance, they can anyway start as separate process.

In another case, deployment overhead will reduce a bit as Monitoring process need not monitor one more process in their lifcycles etc.

Thoughts?",2012-11-19 12:45:14,2013-01-14 16:03:06
BOOKKEEPER-473,Improve write performance which compete with read on disk I/O,Bug,1,Resolved,5,Done,2017-10-09 09:44:28,2012-11-20 17:28:20,2017-10-09T09:44:28.000+0000,yx3zhu@gmail.com,Yixue Zhu,yx3zhu@gmail.com,"BOOKKEEPER-432 introduced SkipList to sort entries before adding them to entry log file, to improve ledger read performance.

This task is to eliminate/reduce Index files, which contribute to sync write I/O spike (thousands of index files corresponding to active ledgers per bookie server).

The write I/O contend with disk read I/O.",2012-11-20 17:28:20,2017-10-09 09:44:28
BOOKKEEPER-474,BookieReadWriteTest#testShutdown doesn't make sense,Bug,1,Closed,6,Fixed,2012-12-08 15:15:22,2012-11-21 10:17:40,2013-05-02T02:29:58.000+0000,ikelly,Ivan Kelly,ikelly,"This test was created to catch the BOOKKEEPER-5, which is where we hang due to orphaned netty connections. Netty connections are made when we first send an add entry to the bookie. 

The creates 10000 ledgers, and writes 200 entries to across these (note, this is not 200 each, but 200 across all ledgers). Therefore, a maximum 200 connections could be created. So the test isn't doing what it think it is doing.

The test takes between 4 & 7 minutes (most of this time creating unused ledgers) on jenkins. It is then run 4 times as BookieReadWriteTest is a Parameterized test.

This adds up to 28 minutes to a build on jenkins. This test should take no longer than 30 seconds.",2012-11-21 10:17:40,2012-12-08 15:15:22
BOOKKEEPER-475,BookieRecoveryTest#testSyncBookieRecoveryToRandomBookiesCheckForDupes() iterates too much,Bug,1,Closed,6,Fixed,2012-12-04 21:16:45,2012-11-21 13:28:17,2013-02-13T15:46:39.000+0000,ikelly,Ivan Kelly,ikelly,"This test exists to detect the case where a bookie is taken down, and the same another bookie is selected to replace it, but the other bookie is already in the ensemble. BOOKKEEPER-106 fixed this, so it shouldn't happen. However we still need to check. We iterate 10 times, but this is a parametered test, so effectively we iterate 40 times. There's 3 possible bookies to select, two of which are already in the ensemble, so a single iteration, if selecting randomly has a 66% chance of selecting a bad bookie. We have to run four times anyhow because it's a parameterized test, giving us a 66*4 % chance of hitting the bug if we only have one iteration. 

Therefore, we should only iterate once. Also, we don't need to write much data. We only care about whats in zk for this test really.
",2012-11-21 13:28:17,2012-12-04 21:16:45
BOOKKEEPER-476,Log to file during tests,Improvement,4,Closed,6,Fixed,2012-11-27 20:46:16,2012-11-23 16:23:45,2013-02-13T15:47:04.000+0000,ikelly,Ivan Kelly,ikelly,We should log to file during tests to allow us to debug flakey tests more easily.,2012-11-23 16:23:45,2012-11-27 20:46:16
BOOKKEEPER-477,"In ReadOnlyBookieTest, we should wait for the bookie to die before asserting on it",Bug,1,Closed,6,Fixed,2012-11-27 15:53:13,2012-11-23 16:26:32,2013-02-13T15:47:02.000+0000,ikelly,Ivan Kelly,ikelly,"Right now we assert immediately, so the bookie thread has no chance to die. We should only assert after giving it a chance.",2012-11-23 16:26:32,2012-11-27 15:53:13
BOOKKEEPER-479,Fix apache-rat issues in tree,Bug,1,Closed,6,Fixed,2012-11-27 14:36:53,2012-11-27 11:05:11,2013-02-13T15:46:33.000+0000,ikelly,Ivan Kelly,ikelly,"On an absolutely clean branch, mvn apache-rat:check fails. There are two test sources without license. Fix this.",2012-11-27 11:05:11,2012-11-27 14:36:53
BOOKKEEPER-480,Fix javac warnings,Bug,1,Closed,6,Fixed,2012-11-30 03:57:10,2012-11-27 11:05:35,2013-02-13T15:47:00.000+0000,ikelly,Ivan Kelly,ikelly,Precommit is reporting javac warnings. ,2012-11-27 11:05:35,2012-11-30 03:57:10
BOOKKEEPER-481,Fix javadoc warnings,Bug,1,Closed,6,Fixed,2012-11-30 03:54:44,2012-11-27 11:05:50,2013-02-13T15:46:28.000+0000,ikelly,Ivan Kelly,ikelly,Precommit is reporting javadoc warnings. ,2012-11-27 11:05:50,2012-11-30 03:54:44
BOOKKEEPER-482,Precommit is reporting findbugs errors in trunk,Bug,1,Closed,6,Fixed,2012-12-01 05:33:23,2012-11-27 11:18:22,2013-02-13T15:46:23.000+0000,ikelly,Ivan Kelly,ikelly,Precommit is reporting findbugs warnings. ,2012-11-27 11:18:22,2012-12-01 05:33:23
BOOKKEEPER-483,"precommit tests only check toplevel rat file, not the one for submodules.",Bug,1,Closed,6,Fixed,2012-12-13 15:44:59,2012-11-27 14:25:25,2013-02-13T15:46:47.000+0000,ikelly,Ivan Kelly,ikelly,"Therefore, not all rat errors are detected.",2012-11-27 14:25:25,2012-12-13 15:44:59
BOOKKEEPER-484,Misc fixes for test scripts,Bug,1,Closed,6,Fixed,2012-12-03 20:32:43,2012-11-27 15:14:46,2013-02-13T15:46:34.000+0000,ikelly,Ivan Kelly,ikelly,"Catchup patch for some annoying issues I've notices with patch test scripts.

# SCM cleanup happens after dir creation (effectively undoing it)
# patch link is displayed wrong
# posts empty message to jira if patch is not in patch available state",2012-11-27 15:14:46,2012-12-03 20:32:43
BOOKKEEPER-485,TestFencing hung,Bug,1,Closed,6,Fixed,2012-12-01 14:05:06,2012-11-27 15:33:54,2013-05-02T02:29:58.000+0000,ikelly,Ivan Kelly,ikelly,"... while testing BOOKKEEPER-477, but I think they are unrelated.",2012-11-27 15:33:54,2012-12-01 14:05:06
BOOKKEEPER-487,Add existed hub server settings to configuration template file,Task,3,Closed,6,Fixed,2012-11-29 16:55:38,2012-11-29 08:11:30,2013-02-13T15:46:37.000+0000,hustlmsp,Sijie Guo,hustlmsp,Add existed hub server settings to the configuration template file (conf/hw_server.conf) as what we did in BookKeeper.,2012-11-29 08:11:30,2012-11-29 16:55:38
BOOKKEEPER-488,Provide a in-memory implementation for Hedwig MetadataManagerFactory,Bug,1,Resolved,5,Won't Do,2017-10-09 09:44:11,2012-12-01 03:01:05,2017-10-09T09:44:11.000+0000,,,,refer the discussion here: https://issues.apache.org/jira/browse/BOOKKEEPER-482?focusedCommentId=13507105&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13507105,2012-12-01 03:01:05,2017-10-09 09:44:11
BOOKKEEPER-490,add documentation for MetaStore interface,Sub-task,7,Closed,6,Fixed,2012-12-18 05:48:52,2012-12-04 05:39:56,2013-02-13T15:46:34.000+0000,hustlmsp,Sijie Guo,hustlmsp,We need documentation for metastore interface.,2012-12-04 05:39:56,2012-12-18 05:48:52
BOOKKEEPER-491,Hedwig doc for configuration,Improvement,4,Closed,6,Fixed,2012-12-11 10:23:17,2012-12-04 12:05:06,2013-02-13T15:46:42.000+0000,fpj,Flavio Paiva Junqueira,fpj,"Unless I'm not looking properly into it, I can's see any doc describing the configuration parameters of hedwig-server. ",2012-12-04 12:05:06,2012-12-11 10:23:17
BOOKKEEPER-492,An ZooKeeper Helper API for Consistent Setting,Improvement,4,Resolved,5,Won't Do,2017-10-09 09:43:14,2012-12-05 08:43:48,2017-10-09T09:43:14.000+0000,jiannan,Jiannan Wang,jiannan,"To make sure all servers adopt consistent settings on some parameters (such as LedgerManagerFactory), we leverage zookeeper for coordination. And as there are more settings (MetaStoreImplClass in MSLedgerManagerFactory and MsMetadataManagerFactory, LedgerIdGeneratorClass etc) needs to make similar global consistent guarantee, a common interface to do this job would make things easier.",2012-12-05 08:43:48,2017-10-09 09:43:14
BOOKKEEPER-493,moveLedgerIndexFile might have chance pickup same directory,Bug,1,Closed,6,Fixed,2012-12-12 17:27:53,2012-12-06 18:21:59,2013-02-13T15:46:40.000+0000,hustlmsp,Sijie Guo,hustlmsp,"{code}

    public void addToFilledDirs(File dir) {
        if (!filledDirs.contains(dir)) {
            LOG.warn(dir + "" is out of space.""
                    + "" Adding it to filled dirs list"");
            // Update filled dirs list
            List<File> updatedFilledDirs = new ArrayList<File>(filledDirs);
            updatedFilledDirs.add(dir);
            filledDirs = updatedFilledDirs;
            // Update the writable ledgers list
            List<File> newDirs = new ArrayList<File>(writableLedgerDirectories);
            newDirs.removeAll(filledDirs);
            writableLedgerDirectories = newDirs;
            // Notify listeners about disk full
            for (LedgerDirsListener listener : listeners) {
                listener.diskFull(dir);
            }   
        }   
    }

{code}

When a directory is putting into filledDirs, it might not be removed from writableLedgerDirectories. The directory still has chance to be picked up to move index file.

we need same synchronization and check to guarantee that we don't move to same directory.",2012-12-06 18:21:59,2012-12-12 17:27:53
BOOKKEEPER-494,Ability to add new ledger disk to a bookie,New Feature,2,Resolved,5,Won't Do,2017-06-22 00:25:25,2012-12-07 05:26:07,2017-06-22T00:25:25.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"Currently we had *Cookie* for each bookie to record the directories it used for ledgers. So when the admin wants to add a new disk for a bookie, we can't change the configuration and restart it simply. an admin command would be added to help admin guys adding a new disk to a bookie and upgrading its *Cookie*.

Adding a brand new disk would be quite easy. But if we want to remove a disk or replace a disk, it isn't trivial. BOOKKEEPER-201 would take care of removing/replace a disk.

",2012-12-07 05:26:07,2017-06-22 00:25:25
BOOKKEEPER-495,Revise BK config doc,Improvement,4,Closed,6,Fixed,2012-12-11 17:59:56,2012-12-07 11:23:44,2013-02-13T15:47:03.000+0000,fpj,Flavio Paiva Junqueira,fpj,There are a few missing config parameters. ,2012-12-07 11:23:44,2012-12-11 17:59:56
BOOKKEEPER-496,Ensure that the auditor and replication worker will shutdown if they lose their ZK session,Sub-task,7,Closed,6,Fixed,2012-12-18 11:02:35,2012-12-07 17:04:23,2013-05-02T02:29:58.000+0000,ikelly,Ivan Kelly,ikelly,"Once the session is lost, the zookeeper client is invalid. Therefore, we should shut down.",2012-12-07 17:04:23,2012-12-18 11:02:35
BOOKKEEPER-497,GcLedgersTest has a potential race,Bug,1,Closed,6,Fixed,2012-12-12 05:54:48,2012-12-10 10:50:42,2013-02-13T15:46:24.000+0000,ikelly,Ivan Kelly,ikelly,"The callbacks use Object#wait/notify without checking a condition. If the callback completes very quickly, the notify will happen before wait is ever called. The best solution is to use a CountDownLatch. Im seeing this problem when applying patch for BOOKKEEPER-205, probably due to a change in timing on the test.",2012-12-10 10:50:42,2012-12-12 05:54:48
BOOKKEEPER-498,BookieRecoveryTest.tearDown NPE,Bug,1,Closed,6,Fixed,2012-12-10 15:04:18,2012-12-10 14:29:56,2013-02-13T15:46:38.000+0000,fpj,Flavio Paiva Junqueira,fpj,Jenkins build is complaining among other things about this NPE.,2012-12-10 14:29:56,2012-12-10 15:04:18
BOOKKEEPER-500,Fencing doesn't work when restarting bookies.,Bug,1,Closed,6,Fixed,2012-12-18 12:05:21,2012-12-11 06:31:48,2013-02-13T15:46:36.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Currently we just record fence state in memory. If the bookies are restarted, all fence states are gone. It would break the correctness that we guarantee about fencing.

We should record the fence state in the file info to make it persistent.

A test case added to produce this issue.",2012-12-11 06:31:48,2012-12-18 12:05:21
BOOKKEEPER-502,Hedwig client utils to avoid protobuf boilerplate,Bug,1,Resolved,5,Won't Do,2017-10-09 09:42:58,2012-12-12 11:54:01,2017-10-09T09:42:58.000+0000,,,,"Doing anything with the hedwig java client requires a lot of boilerplate protobuf code.

For example
{code}
SubscriptionOptions options = SubscriptionOptions.newBuilder()
     .setCreateOrAttach(CreateOrAttach.CREATE).build();
client.getSubscriber().asyncSubscribe(ByteString.copyFromUtf8(""myTopic""),
                                      ByteString.copyFromUtf8(""mySubscription""),
                                      options,
                                      myCallback,
                                      myContext);
{code}
It would be nice to be able to write something like
{code}
client.getSubscriber().asyncSubscriber(_s(""myTopic""), _s(""mySubscription""), 
                                       _subOpts(CreateOrAttach.CREATE),
                                       myCallback, myContext);
{code}

For this we need a ClientUtils class with statics. This JIRA is to create that class and discuss what should be in it.
",2012-12-12 11:54:01,2017-10-09 09:42:58
BOOKKEEPER-503,The test case of TestThrottlingDelivery#testServerSideThrottle failed sometimes,Bug,1,Closed,6,Fixed,2013-01-12 17:55:49,2012-12-13 17:11:05,2013-02-13T15:46:45.000+0000,jiannan,Jiannan Wang,jiannan,"Running follow script in hedwig-server project
{code:java}
while mvn test -Dtest=TestThrottlingDelivery; do echo .; done
{code}
We may get assertion failure:
{code:java}
testServerSideThrottle[0](org.apache.hedwig.server.delivery.TestThrottlingDelivery)  Time elapsed: 14.922 sec  <<< FAILURE!
junit.framework.AssertionFailedError: Timed out waiting for messages 31
	at junit.framework.Assert.fail(Assert.java:47)
	at junit.framework.Assert.assertTrue(Assert.java:20)
	at org.apache.hedwig.server.delivery.TestThrottlingDelivery.throttleX(TestThrottlingDelivery.java:159)
	at org.apache.hedwig.server.delivery.TestThrottlingDelivery.testServerSideThrottle(TestThrottlingDelivery.java:206)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:601)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.FailOnTimeout$1.run(FailOnTimeout.java:28)
{code}

This is a race issue which may cause messages been throttled by mistake, the root cause is ActiveSubscriberState.messageConsumed() and ActiveSubscriberState.deliverNextMessage() may be executed in different threads by AbstractSubscriptionManager and FIFODeliveryManager.

Read the log in attachement around Line 2420 if you want to get more information, here I replay the logs onto the code (Line XX denotes code listed below):
# Messages 1-30 are to be delivered and the message window size in Hub server is 10.
# Messages 1-10 are delivered to subscriber while message 11-30 is throttled by the window size limitation.
# Subscriber calls consume 1-10 asynchronously.
# CONSUME 1 is handled and FIFODeliveryManager continue to deliver message 11.
# Subscriber receive message 11 and quickly ack CONSUME 11 to Hub.
# Now there are two threads operate on a same ActiveSubscriberState:
#* Thread in AbstractSubscriptionManager: call ActiveSubscriberState.messageConsumed() for message 2, 3, 11 (4-10 is still on the way since it's asynchronous consume). Let's assume this thread happen to run in Line (14) for message 11.
#* Thread in FIFODeliveryManager:  Coincidently, it's in Line (36) now (with last delivered 11, last consumed 1 and variable isThrottled is still false).
# If thread in AbstractSubscriptionManager executed before FIFODeliveryManager, then consume operator for 11 does nothing more.
# CONSUME [4-10] will be just ignored by the if statement in Line (2) since lastSeqIdConsumedUtil is now 11.
# Further messages like 12 have no chance to been delivered at this time.

{code:java}
(01) protected void messageConsumed(long newSeqIdConsumed) {
(02)     if (newSeqIdConsumed <= lastSeqIdConsumedUtil) {
(03)         return;
(04)     }
(05)     if (logger.isDebugEnabled()) {
(06)         logger.debug(""Subscriber ({}) moved consumed ptr from {} to {}."",
(07)                      va(this, lastSeqIdConsumedUtil, newSeqIdConsumed));
(08)     }
(09)     lastSeqIdConsumedUtil = newSeqIdConsumed;
(10)     // after updated seq id check whether it still exceed msg limitation
(11)     if (msgLimitExceeded()) {
(12)         return;
(13)     }
(14)     if (isThrottled) {
(15)         isThrottled = false;
(16)         logger.info(""Try to wake up subscriber ({}) to deliver messages again : last delivered {}, last consumed {}."",
(17)                     va(this, lastLocalSeqIdDelivered, lastSeqIdConsumedUtil));
(18) 
(19)         enqueueWithoutFailure(new DeliveryManagerRequest() {
(20)             @Override
(21)             public void performRequest() {
(22)                 // enqueue 
(23)                 clearRetryDelayForSubscriber(ActiveSubscriberState.this);            
(24)             }
(25)         });
(26)     }
(27) }
(28) 
(29) public void deliverNextMessage() {
(30)     if (!isConnected()) {
(31)         return;
(32)     }
(33) 
(34)     // check whether we have delivered enough messages without receiving their consumes
(35)     if (msgLimitExceeded()) {
(36)         logger.info(""Subscriber ({}) is throttled : last delivered {}, last consumed {}."",
(37)                     va(this, lastLocalSeqIdDelivered, lastSeqIdConsumedUtil));
(38)         isThrottled = true;
(39)         // do nothing, since the delivery process would be throttled.
(40)         // After message consumed, it would be added back to retry queue.
(41)         return;
(42)     }
(43) 
(44)     localSeqIdDeliveringNow = persistenceMgr.getSeqIdAfterSkipping(topic, lastLocalSeqIdDelivered, 1);
(45) 
(46)     ScanRequest scanRequest = new ScanRequest(topic, localSeqIdDeliveringNow,
(47)             /* callback= */this, /* ctx= */null);
(48) 
(49)     persistenceMgr.scanSingleMessage(scanRequest);
(50) }
{code}

By the way, we should also take care of thread-safe issue in other methods for ActiveSubscriberState, which implements some other callback interface.",2012-12-13 17:11:05,2013-01-12 17:55:49
BOOKKEEPER-504,Fix findbugs warning in PendingReadOp,Bug,1,Closed,6,Fixed,2012-12-14 14:15:24,2012-12-13 21:44:00,2013-02-13T15:46:49.000+0000,fpj,Flavio Paiva Junqueira,fpj,,2012-12-13 21:44:00,2012-12-14 14:15:24
BOOKKEEPER-506,Provide better topic release algorithm,Sub-task,7,Resolved,5,Fixed,2013-03-25 16:27:06,2012-12-14 08:53:11,2013-03-25T16:59:45.000+0000,hustlmsp,Sijie Guo,hustlmsp,Currently time-based topic ownership release algorithm doesn't work well. A better algorithm is to release based on its traffic and the total memory usage by hub server.,2012-12-14 08:53:11,2013-03-25 16:27:06
BOOKKEEPER-507,Race condition happens if closeSubscription and subscribe happened at the same time (in multiplexed client).,Bug,1,Closed,6,Fixed,2013-01-03 11:09:07,2012-12-14 08:55:54,2013-02-13T15:46:48.000+0000,hustlmsp,Sijie Guo,hustlmsp,"1) closesub first
2) sub late
3) closesub succeed, but response is delayed to client.
4) since closesub succeed in server side, so sub succeed and tried to deliver message.
5) sub response is back
6) client checked and found that there is already a subscriber there.
7) client failed the subscribe request
8) but the message would still be delivered to same channel. since the sub state is not be cleared. message is still be received.
9) closesub response is back.
10) it clear the subscribe state.
11) message continue delivering but found there is no subscriber state.
at step 11) the problem happened.

this race condition is introduced in multiplexed client (BOOKKEEPER-70).",2012-12-14 08:55:54,2013-01-03 11:09:07
BOOKKEEPER-509,TestBookKeeperPersistenceManager failed on latest trunk,Bug,1,Closed,6,Fixed,2012-12-18 10:55:55,2012-12-14 09:19:48,2013-02-13T15:46:36.000+0000,hustlmsp,Sijie Guo,hustlmsp,"latest trunk failed at TestBookKeeperPersistenceManager.

sees that it caused by uncaught exception:
{code}
java.util.NoSuchElementException
        at java.util.AbstractQueue.remove(AbstractQueue.java:90)
        at org.apache.bookkeeper.client.PendingReadOp.nextElement(PendingReadOp.java:345)
        at org.apache.bookkeeper.client.PendingReadOp.nextElement(PendingReadOp.java:53)
        at org.apache.bookkeeper.client.LedgerRecoveryOp.readComplete(LedgerRecoveryOp.java:100)
        at org.apache.bookkeeper.client.PendingReadOp.submitCallback(PendingReadOp.java:338)
        at org.apache.bookkeeper.client.PendingReadOp.readEntryComplete(PendingReadOp.java:327)
        at org.apache.bookkeeper.proto.PerChannelBookieClient.handleReadResponse(PerChannelBookieClient.java:627)
        at org.apache.bookkeeper.proto.PerChannelBookieClient$7.safeRun(PerChannelBookieClient.java:529)
        at org.apache.bookkeeper.util.SafeRunnable.run(SafeRunnable.java:31)
        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
        at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
        at java.util.concurrent.FutureTask.run(FutureTask.java:138)
        at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
        at java.lang.Thread.run(Thread.java:680)
{code}",2012-12-14 09:19:48,2012-12-18 10:55:55
BOOKKEEPER-510,LedgerRecoveryOp updates metadata before it needs to,Bug,1,Resolved,5,Won't Do,2017-10-09 09:42:49,2012-12-14 10:04:35,2017-10-09T09:42:49.000+0000,,,,"This could lead to an issue if there are a lot of errors in a specific order.

You have a ledger with ensemble (B1, B2, B3)

# B1 brought down for maintenance
# Ledger recovery started
# B2 answers read last confirmed.
# B1 replaced in ensemble by B4
# Write to B4 fails for some reason
# B1 comes back up.
# B2 goes down for maintenance.
# Ledger recovery starts (ledger is now unavailable)


See BOOKKEEPER-355",2012-12-14 10:04:35,2017-10-09 09:42:49
BOOKKEEPER-511,BookieShell is very noisy,Bug,1,Closed,6,Fixed,2012-12-15 01:45:28,2012-12-14 15:56:02,2013-02-13T15:46:29.000+0000,ikelly,Ivan Kelly,ikelly,Bookie shell prints out a lot of stuff it for zookeeper and bookkeeper and the actually shell messages get lost. This JIRA makes zookeeper and bookkeeper only print ERROR level messages for BookieShell. Other commands stay as they are.,2012-12-14 15:56:02,2012-12-15 01:45:28
BOOKKEEPER-512,BookieZkExpireTest fails periodically,Bug,1,Closed,6,Fixed,2012-12-15 02:08:50,2012-12-14 16:44:56,2013-02-13T15:47:01.000+0000,ikelly,Ivan Kelly,ikelly,"BookieZkExpireTest is too timing sensitive. It fails periodically due to simply having a 3 second wait for watchers to trigger. It's better to wait 1 second, and check if they have have run and if not wait again.",2012-12-14 16:44:56,2012-12-15 02:08:50
BOOKKEEPER-513,TestMessageFilter fails periodically,Bug,1,Closed,6,Fixed,2013-01-14 12:46:41,2012-12-14 16:56:23,2013-02-13T15:46:46.000+0000,ikelly,Ivan Kelly,ikelly,"Running org.apache.hedwig.server.filter.TestMessageFilter
Tests run: 9, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 6.779 sec <<< FAILURE!

Results :

Tests in error: 
  testChangeSubscriptionPreferences(org.apache.hedwig.server.filter.TestMessageFilter): Server responded with a status code of: TOPIC_BUSY
  testChangeSubscriptionPreferencesForClientFilter(org.apache.hedwig.server.filter.TestMessageFilter): Server responded with a status code of: TOPIC_BUSY
",2012-12-14 16:56:23,2013-01-14 12:46:41
BOOKKEEPER-514,TestDeadLock hanging sometimes,Bug,1,Closed,6,Fixed,2012-12-28 11:33:12,2012-12-14 17:17:45,2013-02-13T15:46:44.000+0000,ikelly,Ivan Kelly,ikelly,"I've attached the logs.

Looks to be something with the new channel manager. Also, the test itself is bad because its doing an assert from a callback.",2012-12-14 17:17:45,2012-12-28 11:33:12
BOOKKEEPER-520,BookieFailureTest hangs on precommit build,Bug,1,Closed,6,Fixed,2012-12-27 22:17:13,2012-12-18 17:05:04,2013-02-13T15:46:31.000+0000,hustlmsp,Sijie Guo,hustlmsp,https://builds.apache.org/job/bookkeeper-trunk-precommit-build/142/,2012-12-18 17:05:04,2012-12-27 22:17:13
BOOKKEEPER-521,Move metastore and versioning package to bookkeeper-common module,Task,3,Resolved,5,Done,2017-10-09 09:42:19,2012-12-20 07:48:03,2017-10-09T09:42:19.000+0000,,,,"It would be better to move versioning and metastore package and other common things to a separated module 'bookkeeper-common'. in this module, they are common classes could be shared crossing bookkeeper-server and hedwig.",2012-12-20 07:48:03,2017-10-09 09:42:19
BOOKKEEPER-522,TestHedwigHub is failing silently on Jenkins,Bug,1,Closed,6,Fixed,2012-12-24 05:06:19,2012-12-20 16:43:47,2013-02-13T15:47:04.000+0000,ikelly,Ivan Kelly,ikelly,"See
https://builds.apache.org/job/bookkeeper-trunk2/2/console

This is probably because something is calling System.exit(). ",2012-12-20 16:43:47,2012-12-24 05:06:19
BOOKKEEPER-523,Every test should have a timeout,Improvement,4,Closed,6,Fixed,2012-12-29 15:33:04,2012-12-20 18:28:29,2013-02-13T15:47:05.000+0000,ikelly,Ivan Kelly,ikelly,Otherwise it will run forever.,2012-12-20 18:28:29,2012-12-29 15:33:04
BOOKKEEPER-524,Bookie journal filesystem gets full after SyncThread is terminated with exception,Bug,1,Closed,6,Fixed,2013-01-07 02:48:49,2012-12-21 01:29:44,2013-02-13T15:46:27.000+0000,mmerli,Matteo Merli,mmerli,"The SyncThread get a NPE while the rest of the bookie is still running. This causes the journal gc to be stopped and the filesystem get full.

Tue Dec 18 17:01:18 2012: Exception in thread ""SyncThread"" java.lang.NullPointerException
Tue Dec 18 17:01:18 2012:       at org.apache.bookkeeper.bookie.LedgerCacheImpl.getLedgerEntryPage(LedgerCacheImpl.java:153)
Tue Dec 18 17:01:18 2012:       at org.apache.bookkeeper.bookie.LedgerCacheImpl.flushLedger(LedgerCacheImpl.java:421)
Tue Dec 18 17:01:18 2012:       at org.apache.bookkeeper.bookie.LedgerCacheImpl.flushLedger(LedgerCacheImpl.java:363)
Tue Dec 18 17:01:18 2012:       at org.apache.bookkeeper.bookie.InterleavedLedgerStorage.flush(InterleavedLedgerStorage.java:148)
Tue Dec 18 17:01:18 2012:       at org.apache.bookkeeper.bookie.Bookie$SyncThread.run(Bookie.java:221)",2012-12-21 01:29:44,2013-01-07 02:48:49
BOOKKEEPER-525,Should not using Junit Assert in CallBack method in BK test.,Bug,1,Resolved,5,Won't Do,2017-10-09 09:42:07,2012-12-24 02:18:50,2017-10-09T09:42:07.000+0000,,,,"There are many jiras to solve the problem of running forever of bk test.
Many of them are coming from the using 'Junit Assert' in callback. The using must be revised through the entire test project. ",2012-12-24 02:18:50,2017-10-09 09:42:07
BOOKKEEPER-526,multiple threads for delivery manager,Improvement,4,Resolved,5,Fixed,2013-02-06 15:31:40,2012-12-29 00:31:54,2013-03-17T23:53:26.000+0000,hustlmsp,Sijie Guo,hustlmsp,"similar as BOOKKEEPER-461. there is only one thread running processing delivery, which would be bottleneck when sub/closesub or throttle became frequently.",2012-12-29 00:31:54,2013-02-06 15:31:40
BOOKKEEPER-529,stopServingSubscriber in delivery manager should remove stub callbacks in ReadAheadCache,Improvement,4,Closed,6,Fixed,2013-01-09 16:47:51,2012-12-29 00:50:20,2013-02-13T15:46:48.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Currently each subscriber would insert stub callback to wait newly published messages or scanning result. for waiting scan result, it was OK. the callback would be triggered and removed after scan callback arrived. but if it was wait newly published, it would be a problem. if sub/closesub/sub become frequent, closesub doesn't remove the installed callback, so the stub callbacks are accumulated, which cause the memory increased, finally OOM.

it would be better to remove its installed stub callback when closesub.",2012-12-29 00:50:20,2013-01-09 16:47:51
BOOKKEEPER-530,data might be lost during compaction.,Bug,1,Closed,6,Fixed,2013-01-10 14:34:08,2012-12-29 07:38:31,2013-02-13T15:46:35.000+0000,ikelly,Ivan Kelly,ikelly,"{code}
        try {
            entryLogger.scanEntryLog(entryLogId, new CompactionScanner(entryLogMeta));
            // after moving entries to new entry log, remove this old one
            removeEntryLog(entryLogId);
        } catch (IOException e) {
            LOG.info(""Premature exception when compacting "" + entryLogId, e); 
        } finally {
            // clear compacting flag
            compacting.set(false);
        }
{code}

currently compaction code has a bit problem: as the code described above, old entry log is removed after new entries are added to new entry log, but new entry log might not be flushed. if failures happened after removal but before flush, data would be lost.

when I implemented compaction feature in BOOKKEEPER-160, I remembered that I took care of letting entry go back to normal addEntry flow to reflect journal and index. But seems that the addEntry doesn't go thru journal, just move entries between entry log files w/o any flush guarantee.

there are two ideas for this solution:

simple one is to let compaction going to normal addEntry flow (adding entry to ledger storage and putting it in journal). the other one is GC thread either wait for ledger storage to flush in sync thread in one flush interval or force a ledger storage flush before removing entry log files.

BTW, it was hard to design a test case by simulating bookie abnormally shut down itself after entry log files are removed.",2012-12-29 07:38:31,2013-01-10 14:34:08
BOOKKEEPER-531,Cache thread should wait until old entries are collected,Bug,1,Closed,6,Fixed,2013-01-09 11:30:00,2013-01-05 08:04:48,2013-02-13T15:46:50.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Ivan commented this issue in BOOKKEEPER-461, but seems that the last patch I attached doesn't address this comment.

https://issues.apache.org/jira/browse/BOOKKEEPER-461?focusedCommentId=13503945&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13503945

so when publish speed is larger than deliver/consume speed, it might overwhelm readAhead cache and putting lots of collectOldEntries operations in request queue, finally it OOM.
",2013-01-05 08:04:48,2013-01-09 11:30:00
BOOKKEEPER-532,AbstractSubscriptionManager#AcquireOp read subscriptions every time even it already owned the topic,Bug,1,Closed,6,Fixed,2013-01-07 23:45:41,2013-01-05 08:12:40,2013-02-13T15:46:55.000+0000,hustlmsp,Sijie Guo,hustlmsp,"{code}
    private class AcquireOp extends TopicOpQueuer.AsynchronousOp<Void> {
        public AcquireOp(ByteString topic, Callback<Void> callback, Object ctx) {
            queuer.super(topic, callback, ctx);
        }   

        @Override
        public void run() {
            if (top2sub2seq.containsKey(topic)) {
                cb.operationFinished(ctx, null);
            }   

            readSubscriptions(topic, new Callback<Map<ByteString, InMemorySubscriptionState>>() {
{code}

it doesn't return after it found subscriptions and callback.",2013-01-05 08:12:40,2013-01-07 23:45:41
BOOKKEEPER-533,TestSubAfterCloseSub fails strangely in tests,Bug,1,Closed,6,Fixed,2013-01-09 16:18:49,2013-01-05 12:52:03,2013-02-13T15:46:41.000+0000,ikelly,Ivan Kelly,ikelly,"Example https://builds.apache.org/job/bookkeeper-trunk-precommit-build/204/

It looks like the maven surefire process exits, as if System.exit() is being called. This should be the case since BOOKKEEPER-522, which removes all calls to System.exit()",2013-01-05 12:52:03,2013-01-09 16:18:49
BOOKKEEPER-534,Flakeyness in AuditorBookieTest,Bug,1,Closed,6,Fixed,2013-01-07 21:54:14,2013-01-05 13:01:04,2013-02-13T15:46:34.000+0000,umamaheswararao,Uma Maheswara Rao G,umamaheswararao,See https://builds.apache.org/job/bookkeeper-trunk2/35/,2013-01-05 13:01:04,2013-01-07 21:54:14
BOOKKEEPER-537,Handling session expire event,Improvement,4,Closed,6,Fixed,2016-04-10 04:26:56,2013-01-08 03:29:19,2016-05-16T21:47:42.000+0000,hustlmsp,Sijie Guo,hustlmsp,"This is a master jira to provide better session expire handling for both BOOKKEEPER and Hedwig.

This task could be divided into several tasks:

1) provide a reconnectable zookeeper client, which wrap the zookeeper client. when session is expired, it created a new zookeeper client to replace the expired one.

2) session handling for bookie server

3) session handling for bookkeeper client.

4) session handling for Hedwig. when session is expired, hedwig should disable ensemble change and ledger change. when the client is recovered from session expired state, hedwig enables ensemble change and ledger change, and it would try to reclaim its owned topic.

the works are available in https://github.com/sijie/bookkeeper/commits/retryable_zk_2. will try to generate the patches after 4.2.0 release.
",2013-01-08 03:29:19,2016-04-10 04:26:56
BOOKKEEPER-538,Race condition in BookKeeper#close,Bug,1,Closed,6,Fixed,2013-01-10 18:14:34,2013-01-08 18:37:21,2013-02-13T15:46:41.000+0000,ikelly,Ivan Kelly,ikelly,"I've seen this with BookieAutoRecoveryTest. Basically, we interrupt and join the replicationworker thread, and then close the BookKeeper instance. This can have caused a bookkeeper operation that never finished. The executor runs it after #close has closed the BookieClient. The operation opens a connection and therefore we get a hang on releaseExternalResources(). 

Solution is pretty simple. We should shutdown all executors before closing the bookieClient. I'll attach a patch which does this.",2013-01-08 18:37:21,2013-01-10 18:14:34
BOOKKEEPER-539,ClientNotSubscribedException & doesn't receive enough messages in TestThrottlingDelivery#testServerSideThrottle,Bug,1,Closed,6,Fixed,2013-01-11 04:17:14,2013-01-09 06:16:05,2013-02-13T15:46:32.000+0000,hustlmsp,Sijie Guo,hustlmsp,"ClientNotSubscribedException & doesn't receive enough messages failure in TestThrottlingDelivery#testServerSideThrottle.

{code}
-------------------------------------------------------------------------------
Test set: org.apache.hedwig.server.delivery.TestThrottlingDelivery
-------------------------------------------------------------------------------
Tests run: 2, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 18.544 sec <<< FAILURE!
testServerSideThrottle[1](org.apache.hedwig.server.delivery.TestThrottlingDelivery)  Time elapsed: 6.776 sec  <<< FAILURE!   junit.framework.AssertionFailedError: Should be expected messages with only 6 expected:<6> but was:<2>
        at junit.framework.Assert.fail(Assert.java:47)
        at junit.framework.Assert.failNotEquals(Assert.java:283)
        at junit.framework.Assert.assertEquals(Assert.java:64)
        at junit.framework.Assert.assertEquals(Assert.java:195)
        at org.apache.hedwig.server.delivery.TestThrottlingDelivery.throttleX(TestThrottlingDelivery.java:151)
        at org.apache.hedwig.server.delivery.TestThrottlingDelivery.testServerSideThrottle(TestThrottlingDelivery.java:216)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:601)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
        at org.junit.internal.runners.statements.FailOnTimeout$1.run(FailOnTimeout.java:28)
{code}

{code}
-------------------------------------------------------------------------------
Test set: org.apache.hedwig.server.delivery.TestThrottlingDelivery
-------------------------------------------------------------------------------
Tests run: 2, Failures: 0, Errors: 1, Skipped: 0, Time elapsed: 18.294 sec <<< FAILURE!
testServerSideThrottle[1](org.apache.hedwig.server.delivery.TestThrottlingDelivery)  Time elapsed: 6.763 sec  <<< ERROR!
org.apache.hedwig.exceptions.PubSubException$ClientNotSubscribedException: Client is not yet subscribed to Topic:            testServerSideThrottleWithHigherValue, SubscriberId: serverThrottleSub
        at org.apache.hedwig.client.netty.impl.multiplex.MultiplexHChannelManager.startDelivery(MultiplexHChannelManager.    java:221)
        at org.apache.hedwig.client.netty.impl.multiplex.MultiplexHChannelManager.startDelivery(MultiplexHChannelManager.    java:199)
        at org.apache.hedwig.client.netty.HedwigSubscriber.startDelivery(HedwigSubscriber.java:358)
        at org.apache.hedwig.server.delivery.TestThrottlingDelivery.throttleX(TestThrottlingDelivery.java:113)
        at org.apache.hedwig.server.delivery.TestThrottlingDelivery.testServerSideThrottle(TestThrottlingDelivery.java:226)          at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:601)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
        at org.junit.internal.runners.statements.FailOnTimeout$1.run(FailOnTimeout.java:28)
{code}",2013-01-09 06:16:05,2013-01-11 04:17:14
BOOKKEEPER-540,#stopServingSubscriber when channel is disconnected.,Improvement,4,Closed,6,Fixed,2013-01-10 09:42:43,2013-01-09 07:06:31,2013-02-13T15:46:43.000+0000,lvfangmin,Fangmin Lv,lvfangmin,"as BOOKKEEPER-539 and , some test cases failed due to #stopServingSubscriber issue. Although BOOKKEEPER-529 works out a patch to fix such race condition, it would be better to ensure #stopServingSubscriber when channel is disconnected, to avoid other kind of race and also cleanup the memory.

(I don't mean to block 4.2.0 release, but there are some test cases found failed related #stopServingSubscriber. so it would be better to handle it before 4.2.0)",2013-01-09 07:06:31,2013-01-10 09:42:43
BOOKKEEPER-541,Add guava to notice file,Improvement,4,Closed,6,Fixed,2013-01-09 15:34:56,2013-01-09 12:23:01,2013-02-13T15:46:23.000+0000,ikelly,Ivan Kelly,ikelly,Add guava to the notice file for binary packages.,2013-01-09 12:23:01,2013-01-09 15:34:56
BOOKKEEPER-542,Remove trailing spaces in IndexCorruptionTest,Improvement,4,Closed,6,Fixed,2013-01-09 17:49:16,2013-01-09 16:38:48,2013-02-13T15:46:23.000+0000,fpj,Flavio Paiva Junqueira,fpj,,2013-01-09 16:38:48,2013-01-09 17:49:16
BOOKKEEPER-543,Read zk host list in a wrong way in hedwig server,Bug,1,Closed,6,Fixed,2013-01-10 09:39:53,2013-01-10 07:49:39,2013-02-13T15:46:24.000+0000,lvfangmin,Fangmin Lv,lvfangmin,"In ServerConfiguration#getZkHost we use conf.getString(ZK_HOST, ""localhost"") to get the zk host string which will only return the part before comma, need to change to getList.",2013-01-10 07:49:39,2013-01-10 09:39:53
BOOKKEEPER-544,Modify hedwig server tests to allow client testcases to start/stop them as part of their tests,Bug,1,Resolved,5,Fixed,2013-06-06 17:04:35,2013-01-11 11:36:07,2013-06-06T17:04:35.000+0000,mridulm80,Mridul Muralidharan,mridulm80,Allow client testcases to start/stop hedwig server as part of their setup/teardown.,2013-01-11 11:36:07,2013-06-06 17:04:35
BOOKKEEPER-546,Too many SyncThread and GC thread logs in DEBUG logging level,Improvement,4,Resolved,5,Won't Do,2017-10-09 09:41:45,2013-01-11 22:27:15,2017-10-09T09:41:45.000+0000,jiannan,Jiannan Wang,jiannan,"I find there are too many SyncThread and GC thread logs in DEBUG logging level, which may not been cared about mostly. And these logs may cause more time to find the actual logs one may interest in, so I suggest to disable logging for these two thread in src/test/resources/log4j.properties by default.",2013-01-11 22:27:15,2017-10-09 09:41:45
BOOKKEEPER-548,Document about periodic ledger checker configuration,Bug,1,Resolved,5,Fixed,2013-02-19 15:17:41,2013-01-16 09:59:43,2013-02-19T15:59:10.000+0000,ikelly,Ivan Kelly,ikelly,regarding 'auditorPeriodicCheckInterval',2013-01-16 09:59:43,2013-02-19 15:17:41
BOOKKEEPER-549,Documentation missed for readOnlyMode support,Bug,1,Resolved,5,Fixed,2013-02-19 15:20:22,2013-01-16 10:12:56,2013-02-19T16:46:11.000+0000,ikelly,Ivan Kelly,ikelly,"Need documentation for below items
{code}
    //ReadOnly mode support on all disk full
    protected final static String READ_ONLY_MODE_ENABLED = ""readOnlyModeEnabled"";
    //Disk utilization
    protected final static String DISK_USAGE_THRESHOLD = ""diskUsageThreshold"";
    protected final static String DISK_CHECK_INTERVAL = ""diskCheckInterval"";
{code}",2013-01-16 10:12:56,2013-02-19 15:20:22
BOOKKEEPER-552,64 Bits Ledger ID Generation,Sub-task,7,Resolved,5,Fixed,2017-05-02 21:10:20,2013-01-20 07:07:05,2017-05-03T00:50:16.000+0000,knusbaum,Kyle Nusbaum,knusbaum,This task aims to find and implement 64 bits global unique ledger id generation mechanisms.,2013-01-20 07:07:05,2017-05-02 21:10:20
BOOKKEEPER-553,New LedgerManager for 64 Bits Ledger ID Management in ZooKeeper,Sub-task,7,Resolved,5,Fixed,2017-01-31 01:42:51,2013-01-20 07:15:41,2017-02-08T21:49:30.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,"Once we extend the ledger id space to 64 bits, the 2-4-4 ledger id partition (see HierarchicalLedgerManager) is not suitable any more. So we need a new LedgerManager for 64 bits ledger id management in ZooKeeper.",2013-01-20 07:15:41,2017-01-31 01:42:51
BOOKKEEPER-554,fd leaking when move ledger index file,Bug,1,Resolved,5,Fixed,2013-02-12 05:00:39,2013-01-20 07:32:38,2013-02-13T17:37:49.000+0000,hustlmsp,Sijie Guo,hustlmsp,"a file info is get when moving ledger index, but it doesn't release after use. so the reference counting for file info stays more than zero, the file channel would never be closed even the file is evicted from ledger cache.",2013-01-20 07:32:38,2013-02-12 05:00:39
BOOKKEEPER-555,Make BookieServer use Netty rather than a custom IO server,Sub-task,7,Resolved,5,Fixed,2013-02-12 10:17:39,2013-01-24 16:49:32,2013-05-02T02:30:00.000+0000,ikelly,Ivan Kelly,ikelly,Move from the custom NIO server to netty. This will make it easier to do things like add more server side threads and support SSL.,2013-01-24 16:49:32,2013-02-12 10:17:39
BOOKKEEPER-556,BookieServerMXBean#getServerState makes no sense,Bug,1,Resolved,5,Fixed,2013-02-09 08:00:05,2013-01-24 16:52:40,2013-06-06T17:43:24.000+0000,ikelly,Ivan Kelly,ikelly,This got carried over from zookeeper during a copy paste. In ZooKeeper it's used to specify whether a server is standalone or not. This isn't relevant for BookKeeper.,2013-01-24 16:52:40,2013-02-09 08:00:05
BOOKKEEPER-557,Compiler error showing up badly with jdk 7,Bug,1,Resolved,5,Fixed,2013-03-25 05:27:46,2013-01-24 17:16:47,2013-03-25T06:14:18.000+0000,ikelly,Ivan Kelly,ikelly,"JDK 7 changed the error format, and the version of the maven compiler plugin we use doesn't like it. The fix is to update the maven compiler plugin.",2013-01-24 17:16:47,2013-03-25 05:27:46
BOOKKEEPER-559,Fix occasional failure in AuditorBookieTest,Bug,1,Resolved,5,Fixed,2013-03-05 17:47:48,2013-01-28 08:30:50,2013-06-07T08:49:15.000+0000,ikelly,Ivan Kelly,ikelly,"Ivan reported this:
I've seen failure in AuditorBookieTest on jenkins, and I think I've
> > also seen it once locally.
> >
> > https://builds.apache.org/job/bookkeeper-trunk/lastCompletedBuild/testReport/

Current, build does not have that failure and so, we can not see from logs as of now. I will check the test code closely and by that time if Jenkins also reports that will help in checking from the trace.",2013-01-28 08:30:50,2013-03-05 17:47:48
BOOKKEEPER-560,Create readme for hedwig-client-jms ,Task,3,Resolved,5,Won't Do,2017-10-09 09:41:28,2013-01-31 18:43:23,2017-10-09T09:41:29.000+0000,,,,"This module needs a readme describing it as an experimental component and what parts of jms are supported and not supported.

It would also be good to have a bit more detail on why they can't be supported with hedwig as it is today. A lot of this can be taken verbatim from the package-info.html",2013-01-31 18:43:23,2017-10-09 09:41:28
BOOKKEEPER-561,Findbugs reports errors with openjdk,Bug,1,Resolved,5,Fixed,2013-02-08 18:09:49,2013-02-05 17:53:28,2013-02-08T18:45:15.000+0000,ikelly,Ivan Kelly,ikelly,"Findbugs reports a lot of error about a null pointer dereference for System.out

http://sourceforge.net/p/findbugs/bugs/918/?page=0

The solution is to upgrade to a newer findbugs, but this is a bit stricter, so there's some fixes needed. This jira is for the upgrade and those fixes, and also to fix/exclude the errors introduced by BOOKKEEPER-312.",2013-02-05 17:53:28,2013-02-08 18:09:49
BOOKKEEPER-562,Ability to tell if a ledger is closed or not,New Feature,2,Resolved,5,Fixed,2013-06-12 18:22:54,2013-02-07 22:34:08,2013-06-12T18:22:54.000+0000,fpj,Flavio Paiva Junqueira,fpj,"We need to be able to differentiate between open and closed ledgers, because we want to persist ledgers which are closed and wait for ledgers that are open to close.

There doesn't seem to be an easy way to get a list of closed / open ledgers or to query bk to ask if a specific ledger is open or closed.",2013-02-07 22:34:08,2013-06-12 18:22:54
BOOKKEEPER-563,Avoid Journal polluting page cache,Improvement,4,Resolved,5,Fixed,2013-07-20 18:00:31,2013-02-09 04:44:17,2013-07-20T18:00:31.000+0000,robindhamankar,Robin Dhamankar,robindhamankar,"writing data into journal which force the data in os buffer cache being used for hot reads, which could have negative affect on performance.

similar solution is as CASSANDRA-1470.",2013-02-09 04:44:17,2013-07-20 18:00:31
BOOKKEEPER-564,Better checkpoint mechanism,Improvement,4,Resolved,5,Fixed,2013-05-04 12:23:20,2013-02-09 04:52:54,2013-05-07T04:01:51.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Currently, SyncThread made a checkpoint too frequently, which affects performance. data is writing to entry logger file might be blocked by syncing same entry logger file, which affect bookie to achieve higher throughput. We could schedule checkpoint only when rotating an entry log file. so new incoming entries would be written to newer entry log file and old entry log file could be synced.",2013-02-09 04:52:54,2013-05-04 12:23:20
BOOKKEEPER-565,Make an option to separate storing entry log files from index files.,Sub-task,7,Resolved,5,Fixed,2013-12-02 17:46:15,2013-02-09 04:59:11,2013-12-02T18:18:24.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Currently, the add operation will go throughput ledger storage first and journal later. the latency of an add operation would be affected by two parts, one is ledger disk and the other one is journal disk. And flushing ledger index files might cause random i/o, which would affect adding entries to ledger storage in a higher workload.

there are several ideas to resolve this problem, one is aggregate the per-file index into several files to make flushing more sequential.

this jira is a simple solution to separate the disks to avoid disk contention. it is a straightforward way w/ less risk, but not a perfect way which might waste an extra disk and bandwidth. ",2013-02-09 04:59:11,2013-12-02 17:46:15
BOOKKEEPER-567,ReadOnlyBookieTest hangs on shutdown,Bug,1,Resolved,5,Fixed,2013-02-19 15:55:04,2013-02-09 08:57:19,2013-02-19T16:29:07.000+0000,hustlmsp,Sijie Guo,hustlmsp,ReadOnlyBookieTest hangs on shutdown. It occurs when I run bookie tests.,2013-02-09 08:57:19,2013-02-19 15:55:04
BOOKKEEPER-568,NPE during GC with HierarchicalLedgerManager,Bug,1,Resolved,5,Fixed,2013-02-15 04:32:07,2013-02-11 22:33:44,2013-02-15T05:15:31.000+0000,mmerli,Matteo Merli,mmerli,"{noformat}
2013-02-11 14:06:28,904 - WARN  - [GarbageCollectorThread:ScanAndCompareGarbageCollector@103] - Exception when iterating over the metadata {}
java.io.IOException: Error when check more elements
	at org.apache.bookkeeper.meta.HierarchicalLedgerManager$HierarchicalLedgerRangeIterator.hasNext(HierarchicalLedgerManager.java:423)
	at org.apache.bookkeeper.bookie.ScanAndCompareGarbageCollector.gc(ScanAndCompareGarbageCollector.java:75)
	at org.apache.bookkeeper.bookie.GarbageCollectorThread.doGcLedgers(GarbageCollectorThread.java:302)
	at org.apache.bookkeeper.bookie.GarbageCollectorThread.run(GarbageCollectorThread.java:271)
Caused by: java.lang.NullPointerException
	at org.apache.bookkeeper.meta.HierarchicalLedgerManager$HierarchicalLedgerRangeIterator.hasNext(HierarchicalLedgerManager.java:419)
	... 3 more
{noformat}

In the code below, l2NodesIter appears to be null.

{code}
public boolean hasNext() throws IOException {
   try {
      if (l1NodesIter == null) {
          l1NodesIter = zk.getChildren(ledgerRootPath, null).iterator();
          hasMoreElement = nextL1Node();
      } else if (!l2NodesIter.hasNext()) {
          hasMoreElement = nextL1Node();
      }
   } catch (Exception e) {
      throw new IOException(""Error when check more elements"", e);
   }
   return hasMoreElement;
}
{code}",2013-02-11 22:33:44,2013-02-15 04:32:07
BOOKKEEPER-569,Critical performance bug in InterleavedLedgerStorage,Bug,1,Resolved,5,Fixed,2013-02-16 15:04:17,2013-02-13 17:00:14,2013-02-16T15:44:19.000+0000,ikelly,Ivan Kelly,ikelly,"There's a synchronization on InterleavedLedgerStorage#flush(), which kills performance when you're writing to many ledgers on a single bookie. Both #flush and #addEntry are synchronized, which blocks any adds being serviced while the sync thread is running.

The sync on #addEntry has always been there, but on #flush it has only existed since BOOKKEEPER-293. The addition was obviously a mistake.

Fix is simply to remove it.",2013-02-13 17:00:14,2013-02-16 15:04:17
BOOKKEEPER-571,Change ledgers based on total size rather than number of messages.,New Feature,2,Resolved,5,Won't Do,2017-10-09 09:41:18,2013-02-21 09:08:14,2017-10-09T09:41:18.000+0000,,,,"currently hedwig changes ledger based on the number of messages had for each ledger. it would be better that changing ledger could be based on the total size of messages a ledger had. size is a better unit for resource estimation.

future more, the change ledger behaviors could be abstracted as a LedgerChangePolicy and could be customized.",2013-02-21 09:08:14,2017-10-09 09:41:18
BOOKKEEPER-573,Script to start a bookkeeper cluster,Improvement,4,Resolved,5,Fixed,2013-03-17 23:40:27,2013-02-22 17:12:06,2013-03-18T00:14:53.000+0000,ikelly,Ivan Kelly,ikelly,"It would be nice to be able to put a list of slaves in a file, and start bookies on them all with one command (like is possible with hbase and hadoop).",2013-02-22 17:12:06,2013-03-17 23:40:27
BOOKKEEPER-574,Extend the bookkeeper shell to get a list of available bookies,Sub-task,7,Resolved,5,Fixed,2013-02-26 03:14:33,2013-02-22 17:13:44,2013-02-26T03:44:06.000+0000,ikelly,Ivan Kelly,ikelly,"This can be used in scripts to see what bookies are available. It's also useful from the commandline, rather than having to hunt down a zk install.",2013-02-22 17:13:44,2013-02-26 03:14:33
BOOKKEEPER-575,Bookie SSL support,New Feature,2,Resolved,5,Fixed,2017-08-02 08:49:07,2013-02-26 14:26:52,2017-08-02T08:49:07.000+0000,ikelly,Ivan Kelly,ikelly,Support SSL for Bookies.,2013-02-26 14:26:52,2017-08-02 08:49:07
BOOKKEEPER-576,Bookie client should use netty Decoder/Encoder,Sub-task,7,Resolved,5,Fixed,2013-03-17 23:31:51,2013-02-26 14:34:37,2013-05-02T02:30:00.000+0000,ikelly,Ivan Kelly,ikelly,"Current it encodes and decodes in an adhoc manner in PerChannelBookieClient. It would be better to have the request encoding and decoding in the same place and it should also be done with a OneToOne*coder like is done with the server. 

This will make it easier to add a versioning decoder, which will make it much easier to extend the bookie protocol.",2013-02-26 14:34:37,2013-03-17 23:31:51
BOOKKEEPER-577,BookieFailureTest uses sync/wait()/notify() incorrectly,Bug,1,Resolved,5,Fixed,2013-05-07 19:49:57,2013-02-26 14:36:01,2013-06-10T08:30:23.000+0000,ikelly,Ivan Kelly,ikelly,"This makes it susceptible to spurious wakeup issues, which seem to hit very regularly on my laptop.",2013-02-26 14:36:01,2013-05-07 19:49:57
BOOKKEEPER-578,LedgerCacheImpl is reserving 1/3 of Heap size but allocates NonHeap memory,Bug,1,Closed,6,Fixed,2016-04-05 06:51:08,2013-02-27 01:02:28,2016-05-16T21:47:34.000+0000,mmerli,Matteo Merli,mmerli,"By default the page limit parameter is set to -1, which means to assign 1/3 of Heap space to the LedgerCache. Each LedgerEntryPage is then allocating the memory outside the heap (ByteBuffer.allocateDirect()).

This makes BK to use more memory than the -XmxNN configured setting. Is there any particular reason for the LedgerEntryPage buffer to be allocated outside the java heap? Could that be changed?
",2013-02-27 01:02:28,2016-04-05 06:51:08
BOOKKEEPER-579,TestSubAfterCloseSub was put in a wrong package,Bug,1,Resolved,5,Fixed,2013-03-08 23:43:18,2013-02-27 05:52:28,2013-06-07T08:56:16.000+0000,hustlmsp,Sijie Guo,hustlmsp,TestSubAfterCloseSub is put in wrong package.,2013-02-27 05:52:28,2013-03-08 23:43:18
BOOKKEEPER-580,improve close logic,Bug,1,Resolved,5,Fixed,2013-08-23 17:20:28,2013-02-27 05:59:21,2013-08-23T17:26:36.000+0000,ikelly,Ivan Kelly,ikelly,"currently, bookkeeper client still write ledger metadata to metadata storage even the metadata is already closed or undergoing closing. which would cause lots of bad version metadata update encountering unrecoverable errors in ledger handle. e.g. NotEnoughtBookiesException.",2013-02-27 05:59:21,2013-08-23 17:20:28
BOOKKEEPER-581,Ledger recovery doesn't work correctly when recovery adds force changing ensembles.,Bug,1,Resolved,5,Fixed,2013-03-25 17:03:03,2013-03-05 20:31:50,2013-06-07T10:47:44.000+0000,hustlmsp,Sijie Guo,hustlmsp,"currently read and write use same ledger metadata during ledger recovery, which is bad. since write will cause changing ensemble which modified ensembles map to introducing brand new bookies. those brand new bookies would mislead following recovery reads, cause recovery is proceeded in a wrong way.

E.g.

3 bookies, quorums size 2. A, B, C.

read 0 from A, B.
recovery add 0: A, B becomes slow. D, E are brought into the ensemble to replace A, B.
so following recovery read would be proceed in ensemble (D, E, C), then we would lost all the entries added in A and B.

this issue is similar as BOOKKEEPER-355.",2013-03-05 20:31:50,2013-03-25 17:03:03
BOOKKEEPER-582,Make bookie and client use protobuf for requests (non-wire part),Sub-task,7,Resolved,5,Fixed,2014-07-24 22:35:14,2013-03-06 00:38:25,2014-10-05T16:31:04.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Make the client and the bookie use protobufs internally. This is the first step to using protobufs on the wire, but for the moment, BookieRequestHandler decodes the old wire protocol into the protobuf messages. Once this is in, enabling on the wire will be very simple, and the old manual serialization can be made ""legacy"" (still supported, but deprecated).",2013-03-06 00:38:25,2014-07-24 22:35:14
BOOKKEEPER-583,Read from a ReadOnlyBookie fails if index fileinfo is not in ledger cache,Bug,1,Resolved,5,Fixed,2013-03-25 05:48:57,2013-03-07 06:33:57,2013-06-06T17:06:06.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"Read from a ReadOnlyBookie fails is the Bookie is restarted after writing a ledger.

i.e. fileInfo for the ledger to be read is not present in the fileInfoCache",2013-03-07 06:33:57,2013-03-25 05:48:57
BOOKKEEPER-584,Data loss when ledger metadata is overwritten,Bug,1,Resolved,5,Fixed,2013-04-26 16:39:41,2013-03-12 06:05:43,2013-06-07T19:44:24.000+0000,hustlmsp,Sijie Guo,hustlmsp,"this is an issue introduced when fixing BOOKKEEPER-337. the original #resolveConflicts logic was removed by just checking state and current ensemble, which tends to fixing multiple bookies changed in same ensemble.

the issue could be reproduce by a test case in following steps:

1. Ledger L writing several entries to ensemble A, B, C.
2. C succeed, B failed with slow responses and A failed with unrecoverable issue.
3. L would fail all the pending add ops and close the ledger with lastEntryId = -1. (since no add operations succeed).
4. The ownership of this Ledger is released and transferred to other machines (it is the normal use case for Hedwig).
5. the new owner tried to open Ledger L and recover the ensemble, suppose A, B is back to normal at this case. so L is closed with lastEntryId is not -1.
6. the old owner although closed the ledger, but doesn't blocking the responses for already failed pending add ops. so failures for B would kick in some ensemble changes and since the ledger metadata is already changed by new owner, so it needs to resolve the conflicts and update the ledger metadata with lastEntryId = -1 again. so we get different lastEntryId at different time, which cause inconsistency and data loss.

for details of this sequence, a test case could describe it more clearly.",2013-03-12 06:05:43,2013-04-26 16:39:41
BOOKKEEPER-585,Auditor logs noisily when a ledger has been deleted,Bug,1,Resolved,5,Fixed,2013-03-17 23:34:16,2013-03-14 19:04:38,2013-06-07T09:46:40.000+0000,ikelly,Ivan Kelly,ikelly,"The auditor logs very noisily when it tries to check a ledger which has been deleted. Ledgers being deleted is very normal, so this shouldn't log noisily.",2013-03-14 19:04:38,2013-03-17 23:34:16
BOOKKEEPER-586,Remove recursive call in delivery manager,Bug,1,Resolved,5,Fixed,2013-03-25 15:10:47,2013-03-20 06:35:03,2013-06-07T09:51:20.000+0000,hustlmsp,Sijie Guo,hustlmsp,there is a recursive call in fifo delivery manager.,2013-03-20 06:35:03,2013-03-25 15:10:47
BOOKKEEPER-587,Make BK use protobufs on the wire,Sub-task,7,Resolved,5,Implemented,2014-07-26 06:55:19,2013-03-20 13:14:57,2014-10-07T09:51:29.000+0000,ikelly,Ivan Kelly,ikelly,"Building on BOOKKEEPER-582, make bookkeeper use protobufs for on wire transmission.",2013-03-20 13:14:57,2014-07-26 06:55:19
BOOKKEEPER-588,SSL support,Sub-task,7,Resolved,5,Fixed,2017-08-02 08:47:12,2013-03-20 13:15:33,2017-08-02T08:47:12.000+0000,kishorekasi,Kishore Kasi Udayashankar,kishorekasi,SSL support using startTLS,2013-03-20 13:15:33,2017-08-02 08:47:12
BOOKKEEPER-589,Release notes update for non-BC changes,Sub-task,7,Resolved,5,Done,2014-10-08 08:48:14,2013-03-20 13:18:43,2014-10-08T13:10:45.000+0000,hustlmsp,Sijie Guo,hustlmsp,"4.3.0 client will not be able to connect to 4.2.0 servers, due to something stupid in the protocol version handling. 4.2.0 and lower will blindly reject any messages which have a protocolVersion higher than that it's current version, even if the data format has not changed. The release notes should reflect this. Also, think about how the protocolVersion is used some more.",2013-03-20 13:18:43,2014-10-08 08:48:14
BOOKKEEPER-590,Another Scan-And-Compare GC Implementation,Improvement,4,Resolved,5,Won't Do,2017-10-09 09:40:44,2013-03-21 09:33:17,2017-10-09T09:40:44.000+0000,jiannan,Jiannan Wang,jiannan,"The idea of Scan-And-Compare GC is as below:
   * Assume the ledger id list in local bookie server is *LocalLedgers*
   * At the same time, the ledger id list at metadata storage is *LiveLedgers*
   * Then the ledgers require garbage collection are *LocalLedgers - LiveLedgers*

Under current implementation, an ledger id order guarantee is required when obtain *LiveLedgers* from metadata storage. However, this is unnecessary: we get *LocalLedgers* and we can just remove elements that in *LiveLedgers* one by one in any order.

What's more, without the order requirement when scan all ledger ids, some things become simple:
   * We even don't need radix tree to maintain 64-bits ledger metadata, a hierarchical hash tree is enough (just as what topic metadata management does).
   * Easy to handle 64-bit ledger id backward compatibility for MSLedgerManager:
      ** Currently, for MSLedgerManager, we format ledger id to a fixed length (it's 10 now) digit string to make order scan
      ** When a 64-bit ledger id is used we need to enlarge the fixed length, then old ledger id backward compatibility turns to be a trouble if we require this order guarantee.

As above reasons, it would better to remove specific order requirement from current Scan-And-Compare GC implementation.",2013-03-21 09:33:17,2017-10-09 09:40:44
BOOKKEEPER-591,64-bit Ledger Id Support for MSLedgerManager,Sub-task,7,Open,1,,,2013-03-21 12:53:27,2017-10-17T21:29:38.000+0000,jiannan,Jiannan Wang,jiannan,"Currently, MSLedgerManager use String.format(""%010d"", id) as the key for ledger metadata management. We need to extend it to support 64-bit, backward compatibility should also be taken into account.",2013-03-21 12:53:27,
BOOKKEEPER-592,allow application to recommend ledger data locality,Improvement,4,Resolved,5,Fixed,2013-06-12 16:42:22,2013-03-22 10:04:34,2016-04-07T09:26:39.000+0000,hustlmsp,Sijie Guo,hustlmsp,"For application like hbase WAL, it will be useful if application like hbase can give a hint to bk about application's preferred ledger location. In that way, application can fail over to specific machines where one of the ledger replica is located; the recovery time will be faster. Another scenario is hbase's support for hot standby region server where read request can be served from a different machine other than the active region server. That requires the hot standby region server to read from ledger. If the ledger is on the same machine as standby region server, the performance will be better.",2013-03-22 10:04:34,2013-06-12 16:42:22
BOOKKEEPER-593,use the application machine as one of bookies for ledger write if possible,Improvement,4,Resolved,5,Won't Do,2017-10-09 09:40:06,2013-03-22 10:22:08,2017-10-09T09:40:06.000+0000,hustlmsp,Sijie Guo,hustlmsp,"In the scenario where bk applications run on the same set of machines as bookies, it will be useful if bk can put one of the ledger replica on the same machine as the application. In that way one of the ledger writes will be local and could improve the performance.",2013-03-22 10:22:08,2017-10-09 09:40:06
BOOKKEEPER-594,AutoRecovery shutting down on SyncDisconnected,Bug,1,Closed,6,Fixed,2016-03-16 03:51:42,2013-03-26 18:27:12,2016-05-16T21:47:52.000+0000,mmerli,Matteo Merli,mmerli,"Currently the AutoRecovery daemon will shut down on SyncDisconnected. This is the wrong behaviour. It should wait until it gets a expired signal before shutting down. If autoRecoveryDaemonEnabled=true, then the autorecovery deamon is running in the same process as the bookie, the bookie death watcher will take down the bookie at this point also, but as the bookie hasn't shutdown, exit code will be 0, which is confusing to any monitoring app.
",2013-03-26 18:27:12,2016-03-16 03:51:42
BOOKKEEPER-595,Crash of inprocess autorecovery daemon should not take down the bookie,Sub-task,7,Resolved,5,Fixed,2013-04-02 15:39:31,2013-03-27 11:00:17,2013-06-07T12:14:21.000+0000,ikelly,Ivan Kelly,ikelly,Autorecovery is a new feature. We should not bind the stability of the relatively mature bookie daemon to this new daemon.,2013-03-27 11:00:17,2013-04-02 15:39:31
BOOKKEEPER-596,Ledgers are gc'ed by mistake in MSLedgerManagerFactory.,Bug,1,Resolved,5,Fixed,2013-07-26 19:36:10,2013-03-28 18:59:04,2013-07-26T19:36:10.000+0000,hustlmsp,Sijie Guo,hustlmsp,details: https://issues.apache.org/jira/browse/BOOKKEEPER-590?focusedCommentId=13616397&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13616397,2013-03-28 18:59:04,2013-07-26 19:36:10
BOOKKEEPER-597,Add flag to output test logs to stdout,Bug,1,Resolved,5,Fixed,2013-04-02 14:15:29,2013-04-02 12:04:04,2013-04-02T14:46:35.000+0000,ikelly,Ivan Kelly,ikelly,"Logs are currently piped to a file. However, if a test is hanging, its useful to get the logs sent to stdout in as they happen, to see where the test is hanging. We should enable this with a mvn profile, instead of requiring the person to edit out the <redirectOutputToFile> flag.",2013-04-02 12:04:04,2013-04-02 14:15:29
BOOKKEEPER-598,Fails to compile - RESUBSCRIBE_EXCEPTION conflict,Bug,1,Resolved,5,Fixed,2013-04-07 18:11:58,2013-04-04 16:48:51,2013-06-07T16:58:08.000+0000,farrellee,Matthew Farrellee,farrellee,"0. cd hedwig-client/src/main/cpp
1. autoreconf -fi
2. ./configure
3. make

(3) fails with subscriberimpl.cpp:150:48: error: no match for 'operator==' in '(Hedwig::StatusCode)407u == *(const std::type_info*)(*(exception.std::exception::_vptr.exception + -8u))'

The static const RESUBSCRIBE_EXCEPTION is conflicting with an enum from hedwig-client/src/main/cpp/inc/hedwig/protocol.h (line 153 RESUBSCRIBE_EXCEPTION = 407).",2013-04-04 16:48:51,2013-04-07 18:11:58
BOOKKEEPER-599,NPE in PerChannelBookieClient,Bug,1,Resolved,5,Fixed,2013-04-07 18:07:32,2013-04-05 04:25:28,2013-06-07T16:51:32.000+0000,jiannan,Jiannan Wang,jiannan,"When log level is DEBUG, a failure read will cause NPE in PerChannelBookieClient (rr.getData() is null):
{code:java}
void handleReadResponse(BookieProtocol.ReadResponse rr) {
    if (LOG.isDebugEnabled()) {
        LOG.debug(""Got response for read request {} entry length: {}"",
                  rr, rr.getData().readableBytes());
    }
    ...
}
{code}",2013-04-05 04:25:28,2013-04-07 18:07:32
BOOKKEEPER-600,shouldClaim flag isn't cleared for hedwig multiplex java client,Bug,1,Resolved,5,Fixed,2013-07-14 22:56:46,2013-04-05 18:37:17,2013-07-14T23:25:53.000+0000,hustlmsp,Sijie Guo,hustlmsp,"shouldClaim flag isn't cleared when resubscribing in multiplex java client. so it would continue claiming topic ownership in one hub, which is bad for load balancing.",2013-04-05 18:37:17,2013-07-14 22:56:46
BOOKKEEPER-601,readahead cache size isn't updated correctly ,Bug,1,Resolved,5,Fixed,2013-07-13 15:24:08,2013-04-05 18:39:02,2013-07-13T15:55:40.000+0000,hustlmsp,Sijie Guo,hustlmsp,we should update cache size only when first time adding message to a cache stub.,2013-04-05 18:39:02,2013-07-13 15:24:08
BOOKKEEPER-602,we should have request timeouts rather than channel timeout in PerChannelBookieClient,Bug,1,Resolved,5,Fixed,2014-03-10 02:00:08,2013-04-05 19:03:48,2014-03-10T02:00:08.000+0000,i0exception,Aniruddha,i0exception,"currently we only have readTimeout in netty channel, it timeouts only when there is no activities in that channel, but it can't track timeouts of individual requests. if a channel continues having read entry activities, it might shadow a slow add entry response, which is bad impacting add latency.",2013-04-05 19:03:48,2014-03-10 02:00:08
BOOKKEEPER-603,Support Boost 1.53 for Hedwig Cpp Client,Bug,1,Resolved,5,Fixed,2013-06-03 11:04:13,2013-04-08 02:39:19,2013-06-07T17:00:42.000+0000,jiannan,Jiannan Wang,jiannan,"The latest boost version 1.53 does not compatible with current hedwig-client cpp code for ""shared_dynamic_cast"" function is moved out of shared_ptr.hpp at this release. Boost 1.52 and before version is ok.

FYI: https://bitbucket.org/osrf/gazebo/issue/581/boost-shared_-_cast-are-deprecated-removed",2013-04-08 02:39:19,2013-06-03 11:04:13
BOOKKEEPER-604,Ledger storage can log an exception if GC happens concurrently.,Bug,1,Resolved,5,Fixed,2013-08-12 17:01:46,2013-04-08 16:56:29,2013-08-12T17:26:59.000+0000,hustlmsp,Sijie Guo,hustlmsp,"If a ledger is flushing, and part way through,GC kicks in, it can delete the index file before we try and flush it.",2013-04-08 16:56:29,2013-08-12 17:01:46
BOOKKEEPER-605,Use static Logger objects everywhere for bookkeeper,Improvement,4,Resolved,5,Fixed,2013-10-14 14:44:09,2013-04-11 19:34:48,2013-10-14T15:15:00.000+0000,mmerli,Matteo Merli,mmerli,"There are some classes where the SLF4J Logger is not declared as static. Some of them are classes that will have many instances LedgerEntry, PendingReadOp : 

{noformat}
$ git grep LoggerFactory.getLogger | grep -v static
bookkeeper-server/src/main/java/org/apache/bookkeeper/client/LedgerEntry.java:    Logger LOG = LoggerFactory.getLogger(LedgerEntry.class);
bookkeeper-server/src/main/java/org/apache/bookkeeper/client/PendingReadOp.java:    Logger LOG = LoggerFactory.getLogger(PendingReadOp.class);
bookkeeper-server/src/main/java/org/apache/bookkeeper/proto/NIOServerFactory.java:    Logger LOG = LoggerFactory.getLogger(NIOServerFactory.class);
bookkeeper-server/src/main/java/org/apache/bookkeeper/streaming/LedgerInputStream.java:    Logger LOG = LoggerFactory.getLogger(LedgerInputStream.class);
bookkeeper-server/src/main/java/org/apache/bookkeeper/streaming/LedgerOutputStream.java:    Logger LOG = LoggerFactory.getLogger(LedgerOutputStream.class);
bookkeeper-server/src/test/java/org/apache/bookkeeper/test/LoopbackClient.java:    Logger LOG = LoggerFactory.getLogger(LoopbackClient.class);
hedwig-client/src/main/java/org/apache/hedwig/client/conf/ClientConfiguration.java:    Logger logger = LoggerFactory.getLogger(ClientConfiguration.class);
hedwig-client/src/main/java/org/apache/hedwig/client/handlers/CloseSubscriptionResponseHandler.java:        LoggerFactory.getLogger(CloseSubscriptionResponseHandler.class);
hedwig-client/src/main/java/org/apache/hedwig/client/netty/impl/AbstractSubscribeResponseHandler.java:        LoggerFactory.getLogger(AbstractSubscribeResponseHandler.class);
hedwig-client/src/main/java/org/apache/hedwig/client/netty/impl/multiplex/MultiplexSubscribeResponseHandler.java:        LoggerFactory.getLogger(MultiplexSubscribeResponseHandler.class);
hedwig-server/src/test/java/org/apache/hedwig/server/persistence/TestBookkeeperPersistenceManagerWhiteBox.java:        LoggerFactory.getLogger(TestBookkeeperPersistenceManagerWhiteBox.class);
{noformat}
",2013-04-11 19:34:48,2013-10-14 14:44:09
BOOKKEEPER-607,Filtered Messages Require ACK from Client Causes User Being Throttled Incorrectly Forever,Bug,1,Resolved,5,Fixed,2013-07-22 17:30:13,2013-04-22 03:50:37,2013-07-22T17:30:13.000+0000,hustlmsp,Sijie Guo,hustlmsp,"In current FIFODeliveryManager, once a message is filtered in ActiveSubscriberState#messageScanned(), it just call ActiveSubscriberState#sendingFinished() and wait client's acknowledgement. However, the message isn't being delivered to client side, and once the number of such filtered messages larger than the delivery window size, the user cannot receive messages anymore!",2013-04-22 03:50:37,2013-07-22 17:30:13
BOOKKEEPER-608,Make SyncThread a reusable component,Sub-task,7,Resolved,5,Fixed,2013-05-09 09:42:09,2013-05-06 12:49:27,2013-05-09T10:14:59.000+0000,ikelly,Ivan Kelly,ikelly,"The sync thread is currently a inner class of Bookie. This means it's not possible to test the functionality of the sync thread and ledger storage without creating a full bookie, and when you do that you also have to create a journal etc. ",2013-05-06 12:49:27,2013-05-09 09:42:09
BOOKKEEPER-609,"""How to contribute"" page",Improvement,4,Resolved,5,Done,2017-10-09 09:39:29,2013-05-09 13:47:15,2017-10-09T09:39:29.000+0000,fpj,Flavio Paiva Junqueira,fpj,"We currently point to the zookeeper page. However, the way a contributor is supposed to test a patch is not the same in zookeeper and bookkeeper. Just to give an example, ""ant test"" is not going to work with bookkeeper.",2013-05-09 13:47:15,2017-10-09 09:39:29
BOOKKEEPER-610,Make SyncThread use an executor,Bug,1,Resolved,5,Fixed,2013-07-20 18:06:54,2013-05-10 09:45:22,2013-07-20T18:06:54.000+0000,ikelly,Ivan Kelly,ikelly,"Currently we have a bunch of boolean variables to control the lifecycle of the SyncThread. We're effectively replicating what an Executor does, so we should just use an executor.",2013-05-10 09:45:22,2013-07-20 18:06:54
BOOKKEEPER-611,Speed up bookkeeper tests,Improvement,4,Resolved,5,Fixed,2013-05-31 10:03:44,2013-05-15 15:53:25,2013-05-31T10:40:34.000+0000,ikelly,Ivan Kelly,ikelly,"Some tests use addEntry when they should be using asyncAddEntry, leading to the tests taking much to long. Others have timeouts set too high for cases which are expected to fail. ",2013-05-15 15:53:25,2013-05-31 10:03:44
BOOKKEEPER-612,RegionAwarePlacement Policy,Improvement,4,Resolved,5,Fixed,2016-10-13 05:51:51,2013-05-21 06:18:34,2016-10-13T13:09:49.000+0000,robindhamankar,Robin Dhamankar,robindhamankar,"after BOOKKEEPER-592, it would be better to let ack quorum cover at least of two racks, so a rack failure would not make an entry unavailable.",2013-05-21 06:18:34,2016-10-13 05:51:51
BOOKKEEPER-613,Package refactor on ledger storages,Improvement,4,Open,1,,,2013-05-27 15:55:23,2017-10-17T21:29:35.000+0000,ikelly,Ivan Kelly,ikelly,"Currently all the code for interleaved ledger storage is in the bookie package. Likewise, the tests are in the bookie package. This makes it unclear what is a test of the ledger storage and what is a test of the bookie in general.

This JIRA is to move both of these into a subpackage of bookie, o.a.b.bookie.ills. BOOKKEEPER-432 will then go into o.a.b.bookie.sls, and each of the tests in the ills package will have a corresponding test in sls.",2013-05-27 15:55:23,
BOOKKEEPER-614,"Generic stats interface, which multiple providers can be plugged into",Improvement,4,Resolved,5,Fixed,2013-10-29 09:10:16,2013-05-31 16:25:10,2013-10-29T09:43:19.000+0000,ikelly,Ivan Kelly,ikelly,"Currently we collect stats though JMX. Adding a new stat to JMX is cumbersome, and reading the stats out of JMX is painful if you're not on the same machine. As a consequence, we aren't measuring a fraction of the stuff we should be.

There are a couple of nice stats packages out there, such as twitter-stats[1] and codahale metrics[2], which would make collection of stats much easier.

This JIRA is to provide a generic interface, which a metrics backend can be plugged into.

[1] https://github.com/twitter/commons/tree/master/src/java/com/twitter/common/stats
[2] http://metrics.codahale.com/",2013-05-31 16:25:10,2013-10-29 09:10:16
BOOKKEEPER-615,Twitter stats implementation of stats interface,Sub-task,7,Resolved,5,Fixed,2013-10-30 15:42:27,2013-05-31 16:27:05,2013-10-30T15:42:27.000+0000,hustlmsp,Sijie Guo,hustlmsp,Implementation of the generic stats interface using twitter stats.,2013-05-31 16:27:05,2013-10-30 15:42:27
BOOKKEEPER-617,BOOKKEEPER-544 breaks hedwig-server/bin/hedwig script,Bug,1,Resolved,5,Fixed,2013-06-05 09:49:31,2013-06-03 11:02:09,2013-06-06T17:03:47.000+0000,ikelly,Ivan Kelly,ikelly,"BOOKKEEPER-544 made hedwig generate a tests jar in hedwig-server/target. When hedwig-server/bin/hedwig tries to find the hedwig-server jar in target, it will find the test jar rather than the main jar.",2013-06-03 11:02:09,2013-06-05 09:49:31
BOOKKEEPER-618,Better resolution of bookie address,Improvement,4,Resolved,5,Fixed,2013-07-13 00:03:14,2013-06-04 15:55:59,2013-07-15T15:21:45.000+0000,ikelly,Ivan Kelly,ikelly,"Bookie#getBookieAddress uses the following code:

{code:title=Bookie.java}
    /**
     * Return the configured address of the bookie.
     */
    public static InetSocketAddress getBookieAddress(ServerConfiguration conf)
            throws UnknownHostException {
        return new InetSocketAddress(InetAddress.getLocalHost()
                .getHostAddress(), conf.getBookiePort());
    }
{code}

This code is subject to the contents of one's /etc/hosts file, in that if they have an entry like {{127.0.0.1 myhostname}}, this method will return the same 127.0.0.1 address on all bookie servers.  This causes conflicts due to the way bookies register in zookeeper.

There should be an optional bk_server.conf setting to allow one to select their preferred network interface to use for the bookie.  Then you could use something like {{NetworkInterface.getByName(PREFERRED_INTERFACE).getInetAddresses()}} instead.  This method is not effected by the /etc/hosts.

An alternative method of registering the bookie that does not rely on the local address would be another possible solution, such as using the DNS like other apache projects (hbase).",2013-06-04 15:55:59,2013-07-13 00:03:14
BOOKKEEPER-619,Bookie should not create local cookie files if zookeeper is uninitialized,Bug,1,Resolved,5,Fixed,2013-06-21 16:55:35,2013-06-06 16:34:23,2013-06-21T17:25:58.000+0000,ikelly,Ivan Kelly,ikelly,"If you download a distribution of bookkeeper-4.2.1 and try to start the bookie before initializing zookeeper, then the bookie will fail to start, but write the local cookie files with a null instance id. If you then initialize zookeeper with the ""bin/bookkeeper shell metaformat"", you will not be able to start the bookie as instance id of in zk will not match the null instance id in the bookie files.",2013-06-06 16:34:23,2013-06-21 16:55:35
BOOKKEEPER-620,PerChannelBookieClient race during channel disconnect,Bug,1,Resolved,5,Fixed,2013-06-28 16:00:01,2013-06-07 00:58:41,2013-08-06T17:25:30.000+0000,ikelly,Ivan Kelly,ikelly,channel & state are not synchronized in PerChannelBookieClient#closeInternal. so it might cause state is set to CONNECTED but the netty channel is closed by mistake in closeInternal.,2013-06-07 00:58:41,2013-06-28 16:00:01
BOOKKEEPER-621,NPE in FileInfo.moveToNewLocation,Bug,1,Resolved,5,Fixed,2013-07-20 18:13:39,2013-06-07 09:15:23,2013-07-20T18:13:39.000+0000,ikelly,Ivan Kelly,ikelly,"See attached test failure. This was fixed in BOOKKEEPER-564, but we can't pull back that whole patch. The fix is self contained though.",2013-06-07 09:15:23,2013-07-20 18:13:39
BOOKKEEPER-622,Add BookKeeper to Bigtop,Wish,5,Resolved,5,Won't Do,2017-10-09 09:39:19,2013-06-07 16:38:48,2017-10-09T09:39:19.000+0000,,,,We have had a discussion on the dev list about adding BookKeeper to the Bigtop distribution. This JIRA is to track the steps necessary to add BookKeeper to the Bigtop distribution.,2013-06-07 16:38:48,2017-10-09 09:39:19
BOOKKEEPER-623,LedgerChecker should avoid segments of closed ledger with higher start entryId than closed entry.,Bug,1,Resolved,5,Fixed,2013-06-26 01:27:33,2013-06-12 04:45:20,2013-06-26T01:55:47.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"With the almost same testcase mentioned in the BOOKKEEPER-584, Ledger metadata is getting added with extra segment during failure handling of bookies along with fencing. 

Only difference in the testcase is .
1. Before bookie failures some entries were already written
2. And after bookies failed ( First bookie will throw LedgerFenced/Unauthorized exception, and second bookie is slow/dead bookie ), Number of entries written asynchrounously is n*ensembleSize+1

Note that, Unauthorized/FencedException callback comes first, then other bookie failure callback comes.

I will attach a TestCase along with patch for this shortly. Testcase is modified version of attached testcase in BOOKKEEPER-584
",2013-06-12 04:45:20,2013-06-26 01:27:33
BOOKKEEPER-624,Reduce logs generated by ReplicationWorker,Bug,1,Resolved,5,Fixed,2013-08-20 11:03:32,2013-06-12 06:49:22,2013-08-20T11:52:37.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"Reduce the amount of logs generated by the ReplicationWorker. 
Move the unnecessary logs to DEBUG.",2013-06-12 06:49:22,2013-08-20 11:03:32
BOOKKEEPER-625,On OutOfMemoryError in NIOServerFactory thread bookie should shutdown,Bug,1,Resolved,5,Fixed,2013-07-24 12:16:30,2013-06-14 04:45:58,2013-07-24T12:16:30.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"Observed OutOfMemoryError in NIOServerFactory, but it didnt bring down the bookie and it continued to run without serving. 

On OOME in any thread, bookie should shutdown.",2013-06-14 04:45:58,2013-07-24 12:16:30
BOOKKEEPER-626,BOOKIE_EXTRA_OPTS are added twice,Bug,1,Resolved,5,Fixed,2013-06-15 14:58:06,2013-06-14 05:40:38,2013-06-17T03:53:01.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"BOOKIE_EXTRA_OPTS are added twice to JVM Opts.

It will not create problem for usual options like -Xmx, -Xms, etc.

But for Debug options (-Xdebug) we can specify only once. In this case it will create problems.",2013-06-14 05:40:38,2013-06-15 14:58:06
BOOKKEEPER-627,LedgerDirsMonitor is missing thread name,Improvement,4,Resolved,5,Fixed,2013-06-15 15:08:51,2013-06-14 19:15:11,2013-09-10T21:35:28.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,Simplifies debugging,2013-06-14 19:15:11,2013-06-15 15:08:51
BOOKKEEPER-628,Improve bookie registration interface,Improvement,4,Open,1,,,2013-06-17 18:49:52,2017-10-17T21:29:33.000+0000,,,,The idea is to improve/generalize the bookie registration process,2013-06-17 18:49:52,
BOOKKEEPER-629,Support hostname based ledger metadata to help users to change IP with existing installation,Sub-task,7,Resolved,5,Fixed,2014-05-12 06:31:34,2013-06-18 04:25:08,2014-05-12T06:31:34.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"Register the bookie with *hostname:port* and also store the bookie addresses as *hostname:port* in ledger metadata files instead of *ip:port*

This will help users to change the machine IP if they want without loosing their data.

Supporting hostname based installation/functionality is one of the important requirement of users.

Any thoughts?",2013-06-18 04:25:08,2014-05-12 06:31:34
BOOKKEEPER-630,"Add tag to o.a.b.net.* to indict which release of hadoop they came from, move DNS to o.a.b.net.* and indent",Improvement,4,Resolved,5,Fixed,2014-08-18 21:03:56,2013-06-18 08:12:59,2014-08-19T00:36:28.000+0000,hustlmsp,Sijie Guo,hustlmsp,We didn't reformat the code before bringing it in from hadoop commons in the patch of BOOKKEEPER-618.,2013-06-18 08:12:59,2014-08-18 21:03:56
BOOKKEEPER-632,AutoRecovery should consider read only bookies,Bug,1,Resolved,5,Fixed,2013-08-21 13:55:26,2013-06-20 10:02:07,2013-08-21T17:07:14.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"Autorecovery Auditor should consider the readonly bookies as Available Bookies  while publishing the under-replicated ledgers.

Also AutoRecoveryDaemon should shutdown if the local bookie is readonly",2013-06-20 10:02:07,2013-08-21 13:55:26
BOOKKEEPER-633,ConcurrentModificationException in RackawareEnsemblePlacementPolicy when a bookie is removed from available list,Bug,1,Resolved,5,Fixed,2013-06-26 01:35:40,2013-06-25 09:42:57,2013-06-26T02:20:19.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"Got below exception while running one of the tests from TestReplicationWorker

{noformat}2013-06-25 15:09:28,546 - ERROR - [main-EventThread:ClientCnxn$EventThread@623] - Caught unexpected throwable
java.util.ConcurrentModificationException
	at java.util.HashMap$HashIterator.nextEntry(HashMap.java:793)
	at java.util.HashMap$KeyIterator.next(HashMap.java:828)
	at com.google.common.collect.Iterators$8.computeNext(Iterators.java:735)
	at com.google.common.collect.AbstractIterator.tryToComputeNext(AbstractIterator.java:143)
	at com.google.common.collect.AbstractIterator.hasNext(AbstractIterator.java:138)
	at org.apache.bookkeeper.client.RackawareEnsemblePlacementPolicy.onClusterChanged(RackawareEnsemblePlacementPolicy.java:380)
	at org.apache.bookkeeper.client.BookieWatcher.processResult(BookieWatcher.java:135)
	at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:591)
	at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:497){noformat}",2013-06-25 09:42:57,2013-06-26 01:35:40
BOOKKEEPER-634,Provide admin tool to rename bookie identifier in ledger metadata,Sub-task,7,Closed,6,Fixed,2015-01-13 12:09:14,2013-06-25 18:42:05,2016-05-16T21:47:40.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,This JIRA to discuss about admin tool for changing the bookie's IP to hostname.,2013-06-25 18:42:05,2015-01-13 12:09:14
BOOKKEEPER-635,jenkins build should highlight which lines of the patch cause raw analysis errors,Bug,1,Resolved,5,Fixed,2013-07-20 18:17:06,2013-06-26 14:14:32,2013-07-20T18:19:33.000+0000,ikelly,Ivan Kelly,ikelly,Currently it doesn't and this makes it hard to track the errors down.,2013-06-26 14:14:32,2013-07-20 18:17:06
BOOKKEEPER-636,Latest txn logs might be deleted in a race condition which is not recoverable if BK goes down before next txn log created.,Bug,1,Resolved,5,Fixed,2013-07-04 15:19:46,2013-06-26 17:47:06,2013-07-04T15:19:46.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"With the following scenario latest transaction log can be deleted.

1. more than {{journalMaxBackups}} txn logs are there in journal dir.
2. BK machine was up for long time and the latest txn log id is some what huge number
3. Now reboot the machine.
4. after reboot BK restarted.
5. Now, Immediately after startup, One entry is added, due to which Synthread rolled the lastMark in ledger dirs before the lastLogId updated by Journal thread. (this lastMark was having the old logId which was before reboot). 
6. Now after roll, old journal txn logs were gc'ed. *Now latest created the txn log was deleted.*
7. After this Journal thread updated the lastLogMark, also some more rolls happened.
8. Now BK restarted again. But BK was not able to start because it was not able to find the latest txn log file in journal directory.

{noformat}java.io.IOException: Recovery log 264564 is missing
        at org.apache.bookkeeper.bookie.Journal.replay(Journal.java:424)
        at org.apache.bookkeeper.bookie.Bookie.readJournal(Bookie.java:547)
        at org.apache.bookkeeper.bookie.Bookie.start(Bookie.java:603)
        at org.apache.bookkeeper.proto.BookieServer.start(BookieServer.java:111){noformat}",2013-06-26 17:47:06,2013-07-04 15:19:46
BOOKKEEPER-637,NoSuchEntry exception when reading an entry from a bookie should not print ERROR level message,Improvement,4,Resolved,5,Fixed,2013-07-03 10:00:37,2013-06-26 21:13:55,2013-07-03T10:00:37.000+0000,mmerli,Matteo Merli,mmerli,"The NoSuchEntry is an internal error that is recoverable within the BK client library by issuing a read to a different bookie.

I think that INFO level should be more appropriate.",2013-06-26 21:13:55,2013-07-03 10:00:37
BOOKKEEPER-638,Two bookies could start at the same time to access bookie data.,Bug,1,Resolved,5,Fixed,2013-10-11 14:19:01,2013-06-28 01:34:35,2013-10-11T14:57:58.000+0000,hustlmsp,Sijie Guo,hustlmsp,"this issue is introduced in providing netty server for bookie.

in BOOKKEEPER-294, we agreed on the start sequence of bookie:

1) bind bookie port first (to avoid two processes running at the same host).
2) start bookie (e.g initialize bookie storage and replaying journals)
3) start nio server to accept incoming requests.

but after refactoring for netty server, step 1) is combined to be executed in step 3), so two processes could have chance to run at the same time replaying journals. this is pretty bad.

we need to change the code to stick on the sequence described above.",2013-06-28 01:34:35,2013-10-11 14:19:01
BOOKKEEPER-639,Provide hostname based bookie and ledger metadata to support IP change,Improvement,4,Resolved,5,Fixed,2017-07-28 00:00:00,2013-07-01 05:00:24,2017-07-28T00:00:00.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,,2013-07-01 05:00:24,2017-07-28 00:00:00
BOOKKEEPER-640,Log improvement - add shutdown/exit log message for the bookie services,Improvement,4,Resolved,5,Fixed,2013-10-02 04:23:55,2013-07-02 19:23:11,2013-10-02T04:56:53.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,Add logs to know the shutting down or exit sequence of various internal services. This will help debugging the exit flows.,2013-07-02 19:23:11,2013-10-02 04:23:55
BOOKKEEPER-641,DeathWatcher thread is unnecessarily running even after bookie shutdown,Bug,1,Resolved,5,Fixed,2013-07-03 15:39:23,2013-07-02 19:53:15,2013-07-03T16:31:01.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"I've seen in our testcases, DeathWatcher threads are continue running even after bkServer#shutdown.",2013-07-02 19:53:15,2013-07-03 15:39:23
BOOKKEEPER-642,"Bookie returns incorrect exitcode, ExitCode.ZK_REG_FAIL is getting overridden",Bug,1,Resolved,5,Fixed,2013-07-24 14:56:31,2013-07-05 17:15:54,2013-07-24T14:56:31.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"When bookie registration fails due to zookeeper exception, its not exiting with ExitCode.ZK_REG_FAIL.

Bookie.java
{code}
       try {
            registerBookie(conf);
        } catch (IOException e) {
            LOG.error(""Couldn't register bookie with zookeeper, shutting down"", e);
            shutdown(ExitCode.ZK_REG_FAIL);
        }
{code}",2013-07-05 17:15:54,2013-07-24 14:56:31
BOOKKEEPER-643,Improve concurrency of entry logger,Sub-task,7,Resolved,5,Fixed,2014-01-22 13:35:27,2013-07-06 20:53:36,2014-01-22T14:15:30.000+0000,i0exception,Aniruddha,i0exception,the jira is created as part of BOOKKEEPER-429 to improve concurrency of current bookie implementation by leverage concurrent structures.,2013-07-06 20:53:36,2014-01-22 13:35:27
BOOKKEEPER-644,Provide a bookie address wrapper,Sub-task,7,Resolved,5,Fixed,2014-02-05 21:44:24,2013-07-07 01:13:06,2014-02-05T22:14:05.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Provide bookie address wrapper for BOOKKEEPER-629, so client would use the address identifier by server w/o involving in deciding using ip or hostname.",2013-07-07 01:13:06,2014-02-05 21:44:24
BOOKKEEPER-645,Bookkeeper shell command to get a list of readonly bookies ,Improvement,4,Resolved,5,Fixed,2013-10-02 04:54:47,2013-07-07 10:01:22,2013-10-02T05:23:56.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"Provide bookie shell command to know the bookies which are running in readonly mode, rather than to look through zookeeper command/script.",2013-07-07 10:01:22,2013-10-02 04:54:47
BOOKKEEPER-646,BookieShell readjournal command is throwing BufferUnderflowException,Bug,1,Resolved,5,Fixed,2013-07-20 18:28:01,2013-07-08 06:11:20,2013-07-20T18:28:01.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"Following is the exception:
{code}
--------- Lid=3, Eid=99, ByteOffset=5992, EntrySize=56 ---------
Type:           DATA
LastConfirmed:  98

--------- Lid=3, Eid=-8192, ByteOffset=6052, EntrySize=16 ---------
Exception in thread ""main"" java.nio.BufferUnderflowException
	at java.nio.Buffer.nextGetIndex(Buffer.java:480)
	at java.nio.HeapByteBuffer.getLong(HeapByteBuffer.java:387)
	at org.apache.bookkeeper.bookie.BookieShell.formatEntry(BookieShell.java:899)
	at org.apache.bookkeeper.bookie.BookieShell.access$1(BookieShell.java:882)
	at org.apache.bookkeeper.bookie.BookieShell$2.process(BookieShell.java:857)
	at org.apache.bookkeeper.bookie.Journal.scanJournal(Journal.java:395)
	at org.apache.bookkeeper.bookie.BookieShell.scanJournal(BookieShell.java:738)
	at org.apache.bookkeeper.bookie.BookieShell.scanJournal(BookieShell.java:849)
	at org.apache.bookkeeper.bookie.BookieShell$ReadJournalCmd.runCmd(BookieShell.java:440)
	at org.apache.bookkeeper.bookie.BookieShell$MyCommand.runCmd(BookieShell.java:111)
	at org.apache.bookkeeper.bookie.BookieShell.run(BookieShell.java:630)
	at org.apache.bookkeeper.bookie.BookieShell.main(BookieShell.java:656)
{code}


+Cause:+ When reading entries from a fenced ledger, BookieShell#formatEntry meeting Bookie.METAENTRY_ID_FENCE_KEY as an entry, but it doesn't have any data.",2013-07-08 06:11:20,2013-07-20 18:28:01
BOOKKEEPER-649,Race condition in sync ZKUtils.createFullPathOptimistic(),Bug,1,Resolved,5,Fixed,2013-08-22 15:15:56,2013-07-16 18:03:39,2013-08-22T15:15:57.000+0000,ikelly,Ivan Kelly,ikelly,"If multiple threads are calling createFullPathOptimistic() there will be race conditions on creating the intermediate nodes. If the intermediate nodes have been created since we last check, we can just ignore the exception and continue creating the child nodes.",2013-07-16 18:03:39,2013-08-22 15:15:56
BOOKKEEPER-652,Logger class name is wrong in LedgerCacheImpl.java,Bug,1,Resolved,5,Fixed,2013-07-20 18:31:51,2013-07-20 08:43:31,2013-07-20T18:32:00.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"In LedgerCacheImpl.java logger class name is given as 'LedgerDescriptor.class'
{code}
public class LedgerCacheImpl implements LedgerCache {
    private final static Logger LOG = LoggerFactory.getLogger(LedgerDescriptor.class);
{code}",2013-07-20 08:43:31,2013-07-20 18:31:51
BOOKKEEPER-653,Timeout option is missing in few testcases,Test,6,Resolved,5,Fixed,2013-07-24 14:15:07,2013-07-20 20:25:30,2013-07-24T14:15:07.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,Few testcases doesn't have timeout option. Just adds it to avoid hanging issues..,2013-07-20 20:25:30,2013-07-24 14:15:07
BOOKKEEPER-654,"Bookkeeper client operations are allowed even after its closure, bk#close()",Bug,1,Resolved,5,Fixed,2014-02-21 18:01:50,2013-07-21 09:05:46,2014-02-21T18:42:39.000+0000,hustlmsp,Sijie Guo,hustlmsp,"User can perform below operations with the closed bookkeeper client, which was instantiated with external zkclient.
- open a closed ledger 
- create a new ledger 

Also, ledgerhandle operations like fencing/add/write are infinitely hanging.",2013-07-21 09:05:46,2014-02-21 18:01:50
BOOKKEEPER-656,Bookie Performance Improvement,Improvement,4,Resolved,5,Fixed,2014-05-07 05:10:39,2013-07-23 05:18:14,2014-10-07T09:55:18.000+0000,hustlmsp,Sijie Guo,hustlmsp,"this is the master ticket to merge the bookie performance improvement made in twitter branch.

it would generate the patches component by component (e.g. journal, ledger cache, entry logger)",2013-07-23 05:18:14,2014-05-07 05:10:39
BOOKKEEPER-657,Journal Improvement,Sub-task,7,Resolved,5,Fixed,2013-10-12 03:44:28,2013-07-23 05:21:29,2013-10-12T03:59:03.000+0000,robindhamankar,Robin Dhamankar,robindhamankar,"separated force write thread, better group commit strategy on latency and throughput.",2013-07-23 05:21:29,2013-10-12 03:44:28
BOOKKEEPER-658,ledger cache refactor,Sub-task,7,Resolved,5,Fixed,2013-10-11 06:37:30,2013-07-23 05:23:24,2013-10-11T07:13:35.000+0000,robindhamankar,Robin Dhamankar,robindhamankar,refactor ledger cache to separate in-memory page management from persistent management.,2013-07-23 05:23:24,2013-10-11 06:37:30
BOOKKEEPER-659,LRU page management in ledger cache.,Sub-task,7,Resolved,5,Fixed,2013-10-22 14:22:16,2013-07-23 05:24:52,2013-10-22T14:59:51.000+0000,robindhamankar,Robin Dhamankar,robindhamankar,better ledger page management.,2013-07-23 05:24:52,2013-10-22 14:22:16
BOOKKEEPER-660,Logs too noisy on NIOServerFactory when client drops a connection,Bug,1,Resolved,5,Fixed,2013-08-20 12:27:51,2013-07-24 13:57:10,2013-08-20T12:29:04.000+0000,mmerli,Matteo Merli,mmerli,"When a client drops a connection, the server throws an exception. It should only log at info level and close the socket.

{code}
    if (k.isReadable()) {
        int rc = sock.read(incomingBuffer);
        if (rc < 0) {
            throw new IOException(""Read error"");
        }
        if (incomingBuffer.remaining() == 0) {
{code}
",2013-07-24 13:57:10,2013-08-20 12:27:51
BOOKKEEPER-661,Turn readonly back to writable if spaces are reclaimed.,Improvement,4,Resolved,5,Fixed,2014-01-21 16:26:42,2013-07-25 06:42:16,2014-01-21T16:59:57.000+0000,hustlmsp,Sijie Guo,hustlmsp,should be able to turn a bookie from readonly back to writable if the spaces are reclaimed.,2013-07-25 06:42:16,2014-01-21 16:26:42
BOOKKEEPER-662,Major GC should kick in immediately if remaining space reaches a warning threshold,Improvement,4,Resolved,5,Fixed,2014-01-15 14:58:46,2013-07-25 06:44:39,2014-01-15T15:24:20.000+0000,i0exception,Aniruddha,i0exception,"in a high throughput case, Major GC should kick in immediately if remaining spaces reaches a warning threshold.",2013-07-25 06:44:39,2014-01-15 14:58:46
BOOKKEEPER-663,HierarchicalLedgerManager iterator is missing some ranges and the last ledger in the range,Bug,1,Resolved,5,Fixed,2013-07-29 12:23:19,2013-07-26 19:31:59,2013-07-29T12:23:19.000+0000,mmerli,Matteo Merli,mmerli,"The HierarchicalLedgerManager is missing some ledger ranges when iterating over 2nd level ranges. 
Also, within these ranges, the last ledger (*9999) it's not included in the iteration.",2013-07-26 19:31:59,2013-07-29 12:23:19
BOOKKEEPER-664,Compaction increases latency on journal writes,Bug,1,Resolved,5,Fixed,2013-10-22 05:44:36,2013-07-29 12:35:59,2013-10-22T06:13:39.000+0000,ikelly,Ivan Kelly,ikelly,"Compaction writes to the journal to avoid data loss (see BOOKKEEPER-530). BOOKKEEPER-530 correctly identified that this may affect latency on the journal but we have observed this since in production. It is possible to avoid the journal completely, as twitter do in their github branch. Basically, we need to write to the entrylogger first, flush the entry log and then add to the index.",2013-07-29 12:35:59,2013-10-22 05:44:36
BOOKKEEPER-666,Naming threads of ExecutorService,Improvement,4,Resolved,5,Fixed,2013-10-02 04:41:00,2013-08-04 17:39:33,2013-10-02T05:23:55.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,Useful to provide the naming behavior. Otw executors would create threads with default name like 'Thread[pool-1-thread-1]'.,2013-08-04 17:39:33,2013-10-02 04:41:00
BOOKKEEPER-667,Client write will fail with BadMetadataVersion in case of multiple Bookie failures with AutoRecovery enabled,Bug,1,Resolved,5,Fixed,2013-08-13 13:02:24,2013-08-06 06:29:24,2013-08-13T13:11:50.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Scenario:
------------
1. Start cluster of enough bookies, say 4, with autorecovery
2. Create ledger and write some entries.
3. Restart one of the bookies
4. again, write some more entries
5. wait for some time.. till autorecovery completes replication of first segment
6. Now restart one of the bookie of latest ensemble
7. continue to write.

Here second ensemble change will fail, throwing BadMetadataVersion
",2013-08-06 06:29:24,2013-08-13 13:02:24
BOOKKEEPER-668,Race between PerChannelBookieClient#channelDisconnected() and disconnect() calls can make clients hang while add/reading entries in case of multiple bookie failures,Bug,1,Resolved,5,Fixed,2013-08-20 10:52:21,2013-08-06 09:52:07,2013-08-20T11:27:15.000+0000,hustlmsp,Sijie Guo,hustlmsp,"1. Ledger was created with ensemble 2 and quorum as 2 and entries were written.
2. While reading entries, 2 BKs out of 3 in cluster were killed and restarted.
3. Client was hung at read call waiting for sync counter notification.

As though I was not able to reproduce this in some tries, but
By looking at the logs and code, following seems to be problem

1. BookieWatcher got the notification first for changes in available bookies.
2. PerChannelBookieClient#disconnect() called from BookieWatcher for failed bookies. This has set the 'this.channel=null;'
3. PerChannelBookieClient#channelDisconnected() call came now, and it proceeded silently without notifying errors to read ops.

So client is hung waiting for result.

",2013-08-06 09:52:07,2013-08-20 10:52:21
BOOKKEEPER-669,Race condition in ledger deletion and eviction from cache,Bug,1,Resolved,5,Fixed,2013-09-09 16:01:33,2013-08-08 00:59:18,2013-09-09T16:01:33.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"There is a race condition between when a ledger is delete and an eviction from
LedgerCache occur.

The resulting exception is:

{code}
14:06:24.754 [SyncThread] ERROR org.apache.bookkeeper.bookie.Bookie  -
Exception in SyncThread
java.lang.NullPointerException: null
        at
org.apache.bookkeeper.bookie.LedgerCacheImpl.evictFileInfoIfNecessary(LedgerCacheImpl.java:809)
~[bookkeeper-server-4.2.1.15.jar:4.2.2-SNAPSHOT]
        at
org.apache.bookkeeper.bookie.LedgerCacheImpl.getFileInfo(LedgerCacheImpl.java:267)
~[bookkeeper-server-4.2.1.15.jar:4.2.2-SNAPSHOT]
        at
org.apache.bookkeeper.bookie.LedgerCacheImpl.flushLedger(LedgerCacheImpl.java:425)
~[bookkeeper-server-4.2.1.15.jar:4.2.2-SNAPSHOT]
        at
org.apache.bookkeeper.bookie.LedgerCacheImpl.flushLedger(LedgerCacheImpl.java:382)
~[bookkeeper-server-4.2.1.15.jar:4.2.2-SNAPSHOT]
        at
org.apache.bookkeeper.bookie.InterleavedLedgerStorage.flush(InterleavedLedgerStorage.java:167)
~[bookkeeper-server-4.2.1.15.jar:4.2.2-SNAPSHOT]
        at org.apache.bookkeeper.bookie.Bookie$SyncThread.run(Bookie.java:330)
~[bookkeeper-server-4.2.1.15.jar:4.2.2-SNAPSHOT]
14:06:24.755 [SyncThread] INFO  org.apache.bookkeeper.bookie.Bookie  -
Triggering shutdown of Bookie-3181 with exitCode 5
14:06:24.768 [BookieShutdownTrigger] INFO  org.apache.bookkeeper.bookie.Bookie 
- Shutting down Bookie-3181 with exitCode 5
14:06:24.769 [BookieJournal-3181] WARN  org.apache.bookkeeper.bookie.Journal -
Journal exits when shutting down
{code}

The problem is that the openLedger list is a normal LinkedList and sometimes is
modified while synchronizing on fileInfoCache, other times on openLedgers, and
in other places it is accessed without synchronizing.",2013-08-08 00:59:18,2013-09-09 16:01:33
BOOKKEEPER-670,Longpoll Read & Piggyback Support,New Feature,2,Resolved,5,Fixed,2017-07-17 21:28:57,2013-08-09 00:01:41,2017-07-17T21:28:57.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,"LastAddConfirmed (LAC) is a hint entry id carried on each entry written by a ledger writer, which indicates that all the entries before LAC have already acknowledged by the writer. So the reader is safe to read all the entries written before LAC.

Currently a bookkeeper reader doesnt sync LAC with the bookkeeper writer. So a bookkeeper reader has to read LAC (aka LedgerHandle#readLastConfirmed) before getting the latest entries written by the writer.

Such polling behavior results in poor performance:
* Delay on reading entries if we are setting a larger polling interval.
** ReadLastConfirm needs to wait all the responses from all bookies in last ensemble. This constraint is required for Ledger Recovery Procedure, but not for the reader just needs to know latest LAC.
* It might Introduce useless polling loads to bookie servers if we are setting a smaller polling interval.

A notification mechanism is good to reduce round-trips that a reader spent on polling LAC.

",2013-08-09 00:01:41,2017-07-17 21:28:57
BOOKKEEPER-671,PerChannelBookieClient#channelDisconnected can error out other channel's requests,Bug,1,Resolved,5,Fixed,2017-10-09 09:39:05,2013-08-13 09:47:55,2017-10-09T09:39:05.000+0000,,,,"Consider the following.

# Client calls connect() [state=CONNECTING]
# Client calls disconnect() before connect finishes [state=DISCONNECTED]
# Client calls connect() [state=CONNECTING]
# Connect completes, client writes request [state=CONNECTED]
# channelDisconnected() from previous disconnect() called

The #channelDisconnected() call will then error out the write request. This is due to the fact that the outstanding request map belongs to the PerChannelBookieClient, rather than to the channel, even though they should belong to the socket on which they were sent out on.

The solution would be to move the completions into the ChannelHandlerContext. At the same time, we can get rid of the separate read and add lists. This information can be in the keys. Perhaps this fix can be done as part of the transaction id changes.
",2013-08-13 09:47:55,2017-10-09 09:39:05
BOOKKEEPER-672,Cleanup on LedgerMetadata,Bug,1,Resolved,5,Done,2017-10-09 09:38:44,2013-08-13 15:12:32,2017-10-09T09:38:44.000+0000,,,,"LedgerMetadata handling has a lot of corner cases and special handling. This has resulted in a lot of bugs in the past. This jira is to identify the root cause for why it has been so problematic, and to try and find a solution. ",2013-08-13 15:12:32,2017-10-09 09:38:44
BOOKKEEPER-673,Ledger length can be inaccurate in failure case,Bug,1,Resolved,5,Fixed,2013-10-14 16:32:44,2013-08-21 11:00:38,2014-05-30T14:33:15.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Ledger length can be inconsistent if a ledger is closed by a writing client that encounters an error. For example, in a cluster with 3 bookies, and an ledger with a q3e3 configuration, if a bookie dies, the client will close the ledger when it fails to write an entry. However, it has already added the length of the failed entry to the local ledger length, and this is what is stored to zk.",2013-08-21 11:00:38,2013-10-14 16:32:44
BOOKKEEPER-674,Tooling wishlist,Wish,5,Resolved,5,Done,2017-10-09 09:38:27,2013-08-22 09:38:55,2017-10-09T09:38:27.000+0000,,,,"One of the issues brought up when I was in California was the lack of tooling for bookkeeper. As such, I'm creating this wishlist as a place to discuss tooling and to create a list of the tools missing. Before 4.3.0 we should go through the suggestions and implement the most useful stuff.",2013-08-22 09:38:55,2017-10-09 09:38:27
BOOKKEEPER-675,Log noise fixup before cutting 4.2.2,Wish,5,Resolved,5,Fixed,2013-09-10 22:36:51,2013-08-22 15:22:13,2013-09-10T23:11:47.000+0000,ikelly,Ivan Kelly,ikelly,"The message isn't a warning, but an information message that tells you that you initiated your cluster before instance ids existed, as such it should be info level so it doesn't show up on monitoring systems.

WARN  org.apache.bookkeeper.bookie.Bookie  - INSTANCEID not exists in
zookeeper. Not considering it for data verification 

",2013-08-22 15:22:13,2013-09-10 22:36:51
BOOKKEEPER-676,Make add asynchrounous in ledger recovery,Bug,1,Resolved,5,Fixed,2013-10-14 15:39:10,2013-08-23 04:26:39,2013-10-14T16:15:06.000+0000,i0exception,Aniruddha,i0exception,"currently, recovery read needs to wait until add finished. it would take a long time for ledger recovery if there are lots of entries needs to recover. read next and add current could be sent in parallel.

this ticket is for merging change: https://github.com/twitter/bookkeeper/commit/e7ff599869a35c24ebd255a20fa6c70c32b559f5",2013-08-23 04:26:39,2013-10-14 15:39:10
BOOKKEEPER-678,BookieServer shutdown hangs indefinitely at NioServerSocketChannelFactory.releaseExternalResources,Bug,1,Resolved,5,Fixed,2013-11-22 09:41:21,2013-09-01 09:18:58,2013-11-22T09:58:24.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"BookieFailureTest testcase hangs randomly in my environment(Windows 7), when I checked the threaddump, its waiting at NIO's releaseExternalResources. Please have a look at the following threaddump.

{code}
""Thread-6"" prio=6 tid=0x0000000007676800 nid=0x19ac waiting on condition [0x000000000b1ae000]
   java.lang.Thread.State: TIMED_WAITING (parking)
	at sun.misc.Unsafe.park(Native Method)
	- parking to wait for  <0x00000000c3278068> (a java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject)
	at java.util.concurrent.locks.LockSupport.parkNanos(LockSupport.java:196)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:2025)
	at java.util.concurrent.ThreadPoolExecutor.awaitTermination(ThreadPoolExecutor.java:1261)
	at org.jboss.netty.util.internal.ExecutorUtil.terminate(ExecutorUtil.java:107)
	at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.releaseExternalResources(NioServerSocketChannelFactory.java:146)
	at org.apache.bookkeeper.proto.BookieNettyServer.shutdown(BookieNettyServer.java:149)
	at org.apache.bookkeeper.proto.BookieServer.shutdown(BookieServer.java:138)
	- locked <0x00000000c3277ca8> (a org.apache.bookkeeper.proto.BookieServer)
	at org.apache.bookkeeper.test.BookieFailureTest.auxTestReadWriteAsyncSingleClient(BookieFailureTest.java:177)
	at org.apache.bookkeeper.test.BookieFailureTest.testAsyncBK3(BookieFailureTest.java:114)
{code}

Also, full threaddump is attached to this JIRA.",2013-09-01 09:18:58,2013-11-22 09:41:21
BOOKKEEPER-679,Bookie should exit with non-zero if NIOServer crashes with Error,Bug,1,Resolved,5,Fixed,2013-09-09 10:29:51,2013-09-04 15:49:17,2013-09-09T10:29:51.000+0000,ikelly,Ivan Kelly,ikelly,"Currently, if NIOServerFactory throws something like OutOfMemoryError, bookie process will exit with 0. This is bad, as monitoring tools will take it to mean a normal shutdown and not restart.",2013-09-04 15:49:17,2013-09-09 10:29:51
BOOKKEEPER-683,TestSubAfterCloseSub fails on 4.2,Bug,1,Resolved,5,Fixed,2013-09-27 09:38:15,2013-09-12 20:27:44,2013-09-27T10:12:16.000+0000,jiannan,Jiannan Wang,jiannan,Test failure when checking the release candidate.,2013-09-12 20:27:44,2013-09-27 09:38:15
BOOKKEEPER-684,"ZK logging is oververbose, can cause oom in tests",Bug,1,Resolved,5,Fixed,2013-09-19 21:18:02,2013-09-13 09:47:46,2013-09-19T21:18:02.000+0000,ikelly,Ivan Kelly,ikelly,"Some tests, GcLedgerTests for example, create a lot of ledgers (30k) which causes a lot of zk writes. This causes a lot of zk logging, which can fill the log buffer and cause an oom when you're running with very little memory.

Fix is trivial. zk should be set to only log at error level in log4j.properties.",2013-09-13 09:47:46,2013-09-19 21:18:02
BOOKKEEPER-685,Race in compaction algorithm from BOOKKEEPER-664,Bug,1,Resolved,5,Fixed,2013-10-02 09:53:02,2013-09-13 19:15:03,2013-10-02T09:53:02.000+0000,ikelly,Ivan Kelly,ikelly,"I discovered a race in the algorithm when I was forward porting to trunk.

1) Thread1: flushed.set(false)
2) Thread2: onRotateEntryLog() // flushed.set(true)
3) Thread1: entryLogger addEntry L123-E456
4) Thread1: offsets > max, waits for flushed, flushed is true(as set in 2), L123-E456 updated in ledger cache
5) T2: L123 flushed out of ledger cache
6) Crash

This will possible lose 1 entry. I've only reasoned this, not observed it, but it can happen.

The fix is pretty easy. EntryLoggerListener should notify with the point offset in the entry log it has synced as far as. 
      
",2013-09-13 19:15:03,2013-10-02 09:53:02
BOOKKEEPER-686,Bookie startup will fail if one of the configured ledgerDir is full and the same is used for replaying the journal,Bug,1,Resolved,5,Fixed,2013-10-02 05:02:25,2013-09-29 08:06:17,2013-10-02T05:50:49.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"When bookie startup, entry logger is randomly picking one of the configured ledger directory and creates a new log to write. Now journal will be replaying the entries and add to the entry logger.

Unfortunately, if the randomly selected ledger directory is full, then it will immediately fail the bookie startup. Here Bookie is not efficiently filtering the writable ledger directories and utilizing all the available ledger directories.",2013-09-29 08:06:17,2013-10-02 05:02:25
BOOKKEEPER-687,Use static final Logger for hedwig related modules,Improvement,4,Closed,6,Fixed,2015-07-16 06:30:25,2013-10-02 05:12:39,2016-05-16T21:47:53.000+0000,ankurgarg9,Ankur Garg,ankurgarg9,,2013-10-02 05:12:39,2015-07-16 06:30:25
BOOKKEEPER-688,NPE exception in PerChannelBookieClient,Bug,1,Resolved,5,Fixed,2014-03-04 08:21:00,2013-10-04 07:09:29,2014-03-04T08:21:34.000+0000,ikelly,Ivan Kelly,ikelly,"NPE exception in PerChannelBookieClient:

{code}
2013-10-04 11:56:34,526 - INFO  - [NIOServerFactory-15099:NIOServerFactory$Cnxn@246] - Peer closed connection. rc=-1 java.nio.channels.SocketChannel[connected local=/10.18.170.130:15099 remote=/10.18.170.130:53945]
2013-10-04 11:56:34,526 - INFO  - [Thread-93:PerChannelBookieClient@493] - Disconnected from bookie channel [id: 0x006287d3, /10.18.170.130:53945 :> /10.18.170.130:15099]
2013-10-04 11:56:34,526 - INFO  - [New I/O client worker #90-3:PerChannelBookieClient$1@137] - Successfully connected to bookie: [id: 0x01964fe8, /10.18.170.130:53951 => /10.18.170.130:15100]
2013-10-04 11:56:34,542 - INFO  - [NIOServerFactory-15100:NIOServerFactory$Cnxn@246] - Peer closed connection. rc=-1 java.nio.channels.SocketChannel[connected local=/10.18.170.130:15100 remote=/10.18.170.130:53951]
2013-10-04 11:56:34,542 - INFO  - [Thread-93:PerChannelBookieClient@493] - Disconnected from bookie channel [id: 0x01964fe8, /10.18.170.130:53951 :> /10.18.170.130:15100]
2013-10-04 11:56:34,542 - WARN  - [New I/O client worker #90-3:PerChannelBookieClient@274] - Add entry operation failed
java.lang.NullPointerException
	at org.apache.bookkeeper.proto.PerChannelBookieClient.addEntry(PerChannelBookieClient.java:258)
	at org.apache.bookkeeper.proto.BookieClient$2.operationComplete(BookieClient.java:138)
	at org.apache.bookkeeper.proto.BookieClient$2.operationComplete(BookieClient.java:1)
	at org.apache.bookkeeper.proto.PerChannelBookieClient$1.operationComplete(PerChannelBookieClient.java:173)
	at org.jboss.netty.channel.DefaultChannelFuture.notifyListener(DefaultChannelFuture.java:381)
	at org.jboss.netty.channel.DefaultChannelFuture.notifyListeners(DefaultChannelFuture.java:372)
	at org.jboss.netty.channel.DefaultChannelFuture.setSuccess(DefaultChannelFuture.java:316)
	at org.jboss.netty.channel.socket.nio.NioWorker$RegisterTask.run(NioWorker.java:767)
	at org.jboss.netty.channel.socket.nio.NioWorker.processRegisterTaskQueue(NioWorker.java:256)
	at org.jboss.netty.channel.socket.nio.NioWorker.run(NioWorker.java:198)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:44)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:885)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
	at java.lang.Thread.run(Thread.java:619)
4 Oct, 2013 11:56:34 AM org.jboss.netty.channel.DefaultChannelFuture
WARNING: An exception was thrown by ChannelFutureListener.
{code}

Here the operation which is performed is
step-1 addEntry asynchronously
step-2 Immediately after adding the entry, close the bookie client",2013-10-04 07:09:29,2014-03-04 08:21:00
BOOKKEEPER-689,BookKeeperTest failure,Bug,1,Resolved,5,Fixed,2014-03-07 18:15:22,2013-10-04 18:16:50,2014-03-07T18:15:22.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Tests run: 12, Failures: 1, Errors: 0, Skipped: 0, Time elapsed: 49.385 sec <<< FAILURE!
testCloseDuringOp[1](org.apache.bookkeeper.client.BookKeeperTest)  Time elapsed: 14.74 sec  <<< FAILURE!
junit.framework.AssertionFailedError: Close never completed
        at junit.framework.Assert.fail(Assert.java:47)
        at junit.framework.Assert.assertTrue(Assert.java:20)
        at org.apache.bookkeeper.client.BookKeeperTest.testCloseDuringOp(BookKeeperTest.java:217)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:601)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
        at org.junit.internal.runners.statements.FailOnTimeout$1.run(FailOnTimeout.java:28)",2013-10-04 18:16:50,2014-03-07 18:15:22
BOOKKEEPER-690,Add state diagram in document,Task,3,Resolved,5,Fixed,2014-07-29 07:32:39,2013-10-08 05:29:27,2014-10-07T09:57:31.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,Add client state diagram for bookkeeper client in document.,2013-10-08 05:29:27,2014-07-29 07:32:39
BOOKKEEPER-695,Some entry logs are not removed from the bookie storage,Bug,1,Closed,6,Fixed,2015-09-25 06:05:37,2013-10-16 21:34:21,2016-02-18T21:43:20.000+0000,mmerli,Matteo Merli,mmerli,"Some entry logs appear to be truncated (possible at a momemnt when the bookie
was shut down) and the compaction is never getting rid of them:

{code}
00:00:06.448 [GarbageCollectorThread] INFO o.a.b.bookie.GarbageCollectorThread - Extracting entry log meta from entryLogId: 1497
00:00:07.140 [GarbageCollectorThread] WARN  o.a.b.bookie.GarbageCollectorThread - Premature exception when processing 1497 recovery will take care of the problem
java.io.IOException: Short read for ledger entry from entryLog 1497@718702792(31356!=32840)
        at org.apache.bookkeeper.bookie.EntryLogger.scanEntryLog(EntryLogger.java:514) ~[bookkeeper-server-4.2.1.15.jar:4.2.2-SNAPSHOT]
        at org.apache.bookkeeper.bookie.GarbageCollectorThread.extractMetaFromEntryLog(GarbageCollectorThread.java:572) [bookkeeper-server-4.2.1.15.jar:4.2.2-SNAPSHOT]
        at org.apache.bookkeeper.bookie.GarbageCollectorThread.extractMetaFromEntryLogs(GarbageCollectorThread.java:549) [bookkeeper-server-4.2.1.15.jar:4.2.2-SNAPSHOT]
        at org.apache.bookkeeper.bookie.GarbageCollectorThread.run(GarbageCollectorThread.java:268) [bookkeeper-server-4.2.1.15.jar:4.2.2-SNAPSHOT]
{code}

These entry logs are not being removed: 
{code}
$ ll -h *.log
-rw-r--r-- 1 yahoo users 686M Jul 17 10:45 5d9.log
-rw-r--r-- 1 yahoo users 634M Jul 27 19:31 b2d.log
-rw-r--r-- 1 yahoo users 1.5G Jul 28 15:22 b35.log
-rw-r--r-- 1 yahoo users 2.0G Aug  4 04:57 dbd.log
-rw-r--r-- 1 yahoo users 2.0G Aug  4 04:58 dbe.log
.....
{code}
",2013-10-16 21:34:21,2015-09-25 06:05:37
BOOKKEEPER-696,stats collection on bookkeeper client,Sub-task,7,Resolved,5,Fixed,2014-01-21 04:19:52,2013-10-29 06:45:23,2014-01-21T05:02:36.000+0000,i0exception,Aniruddha,i0exception,Stats for bookkeeper client.,2013-10-29 06:45:23,2014-01-21 04:19:52
BOOKKEEPER-697,stats collection on bookkeeper server,Sub-task,7,Resolved,5,Fixed,2014-08-02 18:02:41,2013-10-29 06:46:09,2014-08-06T05:31:01.000+0000,i0exception,Aniruddha,i0exception,Stats collection on bookkeeper server.,2013-10-29 06:46:09,2014-08-02 18:02:41
BOOKKEEPER-698,Bookie client closure is not considering timeoutExecutor,Bug,1,Resolved,5,Fixed,2013-10-30 05:00:13,2013-10-29 08:37:18,2013-10-30T05:29:25.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"'timeoutExecutor' is leaking for every bookie client, it should be closed during bookie client closure. I've seen in tests, scheduler is running and periodically executing the TimeoutTask even after bk client closure.

Also, timeoutExecutor is missing thread name. IMHO, no need to raise another issue, just including the small change with this JIRA.",2013-10-29 08:37:18,2013-10-30 05:00:13
BOOKKEEPER-699,Codahale metrics implementation of stats API,Improvement,4,Resolved,5,Fixed,2013-11-09 18:50:33,2013-10-29 17:58:28,2013-11-09T19:31:24.000+0000,ikelly,Ivan Kelly,ikelly,"As title says, add codahale metrics implementation of stats collection.",2013-10-29 17:58:28,2013-11-09 18:50:33
BOOKKEEPER-700,GarbageCollectorThread exsiting with ArrayIndexOutOfBoundsException,Bug,1,Resolved,5,Fixed,2013-10-30 15:28:32,2013-10-30 09:17:16,2013-11-01T07:06:11.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"After completing compaction, GarbageCollectorThread will do flush any outstanding offsets. When there is no offset present, its throwing following exception and exiting.

{code}
2013-10-30 11:37:20,944 - ERROR - [GarbageCollectorThread:NIOServerCnxnFactory$1@49] - Thread Thread[GarbageCollectorThread,5,main] died
java.lang.ArrayIndexOutOfBoundsException: -1
	at java.util.ArrayList.get(ArrayList.java:324)
	at org.apache.bookkeeper.bookie.GarbageCollectorThread$CompactionScannerFactory.waitEntrylogFlushed(GarbageCollectorThread.java:151)
	at org.apache.bookkeeper.bookie.GarbageCollectorThread$CompactionScannerFactory.flush(GarbageCollectorThread.java:175)
	at org.apache.bookkeeper.bookie.GarbageCollectorThread.doCompactEntryLogs(GarbageCollectorThread.java:400)
	at org.apache.bookkeeper.bookie.GarbageCollectorThread.run(GarbageCollectorThread.java:309)
{code}",2013-10-30 09:17:16,2013-10-30 15:28:32
BOOKKEEPER-701,Improve exception handling of Bookkeeper threads,Improvement,4,Resolved,5,Fixed,2013-12-06 06:39:56,2013-11-01 07:01:37,2013-12-06T07:13:33.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"This JIRA discusses how to improve the exception handling of bookkeeper threads. As part of this it needs to review all the bookkeeper threads, if any unhandled exception from a thread, it should,
- log a loud error when a thread dies. 
- exit if any of the critical thread dies.

Please have a look at BOOKKEEPER-700 to know the initial discussions.",2013-11-01 07:01:37,2013-12-06 06:39:56
BOOKKEEPER-703,Document all the settings added in BOOKKEEPER-656,Sub-task,7,Resolved,5,Fixed,2014-01-24 08:26:44,2013-11-10 02:28:49,2014-01-25T07:05:07.000+0000,hustlmsp,Sijie Guo,hustlmsp,As summary.,2013-11-10 02:28:49,2014-01-24 08:26:44
BOOKKEEPER-704,reconnectable zookeeper client wrapper,Sub-task,7,Resolved,5,Fixed,2014-08-18 21:00:32,2013-11-10 06:11:19,2014-10-07T09:58:03.000+0000,hustlmsp,Sijie Guo,hustlmsp,create a reconnectable zookkeeper client wrapper to handle session expire event.,2013-11-10 06:11:19,2014-08-18 21:00:32
BOOKKEEPER-708,Shade protobuf library to avoid incompatible versions,Bug,1,Resolved,5,Fixed,2014-02-02 05:34:26,2013-11-10 22:02:12,2014-03-07T17:56:37.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"as offline discussion, we need to shade protobuf library for BKJM as hadoop uses protobuf 2.5.

this is planned on version 4.2.3 and 4.3.0.",2013-11-10 22:02:12,2014-02-02 05:34:26
BOOKKEEPER-709,SlowBookieTest#testSlowBookie fails intermittently,Bug,1,Resolved,5,Fixed,2014-01-03 17:12:59,2013-11-23 03:39:01,2014-01-03T17:44:58.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"SlowBookieTest#testSlowBookie fails intermittently when verifying the result of addEntry. 

{code}
junit.framework.AssertionFailedError: expected:<0> but was:<-559038737>
	at junit.framework.Assert.fail(Assert.java:47)
	at junit.framework.Assert.failNotEquals(Assert.java:283)
	at junit.framework.Assert.assertEquals(Assert.java:64)
	at junit.framework.Assert.assertEquals(Assert.java:195)
	at junit.framework.Assert.assertEquals(Assert.java:201)
	at org.apache.bookkeeper.client.SlowBookieTest.testSlowBookie(SlowBookieTest.java:82)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
{code}",2013-11-23 03:39:01,2014-01-03 17:12:59
BOOKKEEPER-710,OpenLedgerNoRecovery should watch ensemble change.,Bug,1,Resolved,5,Fixed,2014-04-11 23:35:29,2013-11-23 06:22:54,2014-04-11T23:35:29.000+0000,hustlmsp,Sijie Guo,hustlmsp,"LedgerHandle opened by openLedgerNoRecovery should watch ensemble change. otherwise, readLastConfirmed & readEntries will stuck if there are ensemble changes in the ledger.",2013-11-23 06:22:54,2014-04-11 23:35:29
BOOKKEEPER-770,Please delete old releases from mirroring system,Bug,1,Resolved,5,Done,2017-10-09 09:31:45,2013-11-26 17:52:55,2017-10-09T09:31:45.000+0000,,,,"To reduce the load on the ASF mirrors, projects are required to delete old releases.

Please can you remove all non-current releases?

[Note that older releases are always available from the ASF archive server]

Thanks.

",2013-11-26 17:52:55,2017-10-09 09:31:45
BOOKKEEPER-711,bookkeeper-daemon.sh will not remove the pid file on successful stop,Bug,1,Resolved,5,Fixed,2013-12-05 06:34:01,2013-12-03 09:08:01,2013-12-05T07:13:12.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"bookkeeper-daemon.sh will not remove the pid file one successfull stop.

This may result in startup failure, if the same PID is used by some other process at that time.

",2013-12-03 09:08:01,2013-12-05 06:34:01
BOOKKEEPER-712,bookkeeper script should use 'java' from JAVA_HOME,Bug,1,Resolved,5,Fixed,2013-12-05 06:36:17,2013-12-05 03:14:36,2013-12-05T07:13:13.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"Currently bookkeeper script is running using the default 'java' from the PATH.

But it should check JAVA_HOME and use JAVA_HOME/bin/java",2013-12-05 03:14:36,2013-12-05 06:36:17
BOOKKEEPER-713,Bookie should store the cookie in zookeeper first,Bug,1,Resolved,5,Invalid,2013-12-06 08:34:08,2013-12-06 06:57:10,2013-12-06T08:34:08.000+0000,vinayakumarb,Vinayakumar B,vinayrpet,"following code in {{Bookie#checkEnvironment(..)}} should store the cookie in zookeeper and then to local disks for {{newEnv}}
{code}            if (newEnv) {
                if (missedCookieDirs.size() > 0) {
                    LOG.debug(""Directories missing cookie file are {}"", missedCookieDirs);
                    masterCookie.writeToDirectory(journalDirectory);
                    for (File dir : allLedgerDirs) {
                        masterCookie.writeToDirectory(dir);
                    }
                }
                masterCookie.writeToZooKeeper(zk, conf);
            }{code}

Otherwise if the {{masterCookie.writeToZooKeeper(zk, conf);}} fails due to some exception, then bookie cannot start again.",2013-12-06 06:57:10,2013-12-06 08:34:08
BOOKKEEPER-714,Logging channel exceptions in PerChannelBookieClient,Bug,1,Resolved,5,Fixed,2014-03-10 02:07:41,2013-12-31 07:06:27,2014-03-10T02:07:41.000+0000,hustlmsp,Sijie Guo,hustlmsp,Logging channel exceptions in PerChannelBookieClient to identify channel connect issue.,2013-12-31 07:06:27,2014-03-10 02:07:41
BOOKKEEPER-715,bookie: delay dropping journal cached pages,Sub-task,7,Resolved,5,Fixed,2014-03-07 12:31:15,2013-12-31 07:58:00,2014-03-07T13:15:31.000+0000,hustlmsp,Sijie Guo,hustlmsp,"As journal writes aren't aligned to sector size, if bookie drops cached pages immediately, journal has to read those pages again, which would impact journal write performance.",2013-12-31 07:58:00,2014-03-07 12:31:15
BOOKKEEPER-716,padding writes for bookie journal,Sub-task,7,Resolved,5,Fixed,2014-04-29 20:09:16,2013-12-31 08:01:04,2014-04-29T20:44:44.000+0000,hustlmsp,Sijie Guo,hustlmsp,"it would be better to pad journal writes to align sector size, which to avoid second syncing corrupt an already synced sector/page.",2013-12-31 08:01:04,2014-04-29 20:09:16
BOOKKEEPER-717,journal should look forward to group time-out entries,Sub-task,7,Resolved,5,Fixed,2014-03-07 12:16:13,2013-12-31 08:05:05,2014-03-07T12:35:55.000+0000,hustlmsp,Sijie Guo,hustlmsp,"journal should look a bit forward to group timeout entries, which avoid too much fsyncs with single entry impacting journal performance. so bookie could have sustained high throughput with low-latency.",2013-12-31 08:05:05,2014-03-07 12:16:13
BOOKKEEPER-718,AuditorLedgerCheckerTest is flakey,Bug,1,Reopened,4,,,2014-01-15 15:27:21,2017-10-17T21:46:09.000+0000,gmenon,Govind Menon,govindmenon,"See:
https://builds.apache.org/job/bookkeeper-trunk/505/
& 
https://builds.apache.org/job/bookkeeper-trunk/509

Relevant errors attached.",2014-01-15 15:27:21,
BOOKKEEPER-719,Inconsistent synchronization of org.apache.bookkeeper.stats.CodahaleMetricsProvider.metrics,Bug,1,Resolved,5,Fixed,2014-01-21 15:42:13,2014-01-21 05:38:17,2014-01-21T16:12:57.000+0000,hustlmsp,Sijie Guo,hustlmsp," Inconsistent synchronization of org.apache.bookkeeper.stats.CodahaleMetricsProvider.metrics; locked 50% of time [""org.apache.bookkeeper.stats.CodahaleMetricsProvider""] At CodahaleMetricsProvider.java:[lines 48-125]",2014-01-21 05:38:17,2014-01-21 15:42:13
BOOKKEEPER-720,CheckpointSource.MIN#compareTo does exactly the opposite of what it should,Bug,1,Resolved,5,Fixed,2014-01-22 06:38:04,2014-01-21 11:19:27,2014-01-22T07:14:50.000+0000,ikelly,Ivan Kelly,ikelly,"CheckpointSource.MIN#compareTo returns 1 which means that ""this"" is greater than the passed argument (see java.util.Comparable javadoc). It should return -1. 

This hasn't been a problem, because MIN isn't currently used anywhere.",2014-01-21 11:19:27,2014-01-22 06:38:04
BOOKKEEPER-721,Close opened entry log files when they become idle,Improvement,4,Open,1,,,2014-01-22 06:44:09,2017-10-17T21:29:30.000+0000,hustlmsp,Sijie Guo,hustlmsp,we might consider closing opened entry log files when they become idle.,2014-01-22 06:44:09,
BOOKKEEPER-722,Cleanup Hierarchical of bufferedchannel,Improvement,4,Open,1,,,2014-01-22 06:45:27,2017-10-17T21:29:27.000+0000,hustlmsp,Sijie Guo,hustlmsp,,2014-01-22 06:45:27,
BOOKKEEPER-723,Statemachine for bookkeeper client,Task,3,Open,1,,,2014-02-02 06:20:44,2017-10-17T21:29:24.000+0000,,,,"{quote}
FPJ: Just to be on the same page, even if we have a state machine for each component, they need to be interconnected somehow, since they are part of the same client and the behavior of one component influences the other, e.g., PCBC is not independent of BookieClient. Consequently, there should be implicit one state machine driving the whole computation of the client. An example of an overarching state machine like this is the ZK one for sessions:

http://zookeeper.apache.org/doc/r3.4.5/zookeeperProgrammers.html#ch_zkSessions
{quote}",2014-02-02 06:20:44,
BOOKKEEPER-724,Shade introduces RAT error,Bug,1,Resolved,5,Fixed,2014-02-06 11:34:03,2014-02-02 08:51:20,2014-02-06T12:13:49.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Shading library in BOOKKEEPER-708 introduces an unlicensed pom file for bookkeeper-server module. we should address this, otherwise we could not publish the new jar per apache release procedure.",2014-02-02 08:51:20,2014-02-06 11:34:03
BOOKKEEPER-725,AutoRecoveryMain should exit with error code if deathwatcher finds dead thread,Bug,1,Resolved,5,Fixed,2014-02-06 08:31:33,2014-02-04 16:43:35,2014-06-03T13:51:24.000+0000,ikelly,Ivan Kelly,ikelly,"Currently exits with 0, which is bad, won't be restarted if daemontools is watching",2014-02-04 16:43:35,2014-02-06 08:31:33
BOOKKEEPER-726,PerChannelBookieClient should print address that it failed to connect to when it fails to correct,Bug,1,Resolved,5,Fixed,2014-03-10 02:11:09,2014-02-04 16:45:33,2014-03-10T02:11:09.000+0000,ikelly,Ivan Kelly,ikelly,Currently we log the channel. But the channel doesn't contain the address if the connection failed.,2014-02-04 16:45:33,2014-03-10 02:11:09
BOOKKEEPER-727,Names of bookie write/read threads are backwards,Bug,1,Resolved,5,Fixed,2014-02-05 21:52:30,2014-02-04 16:46:44,2014-02-05T22:46:27.000+0000,ikelly,Ivan Kelly,ikelly,Summary says it all. Thread factories are backwards.,2014-02-04 16:46:44,2014-02-05 21:52:30
BOOKKEEPER-728,"Bookkeeper#Builder is not public, so can't be used outside of client package",Bug,1,Resolved,5,Fixed,2014-02-06 08:21:31,2014-02-04 16:47:49,2014-02-06T08:58:45.000+0000,ikelly,Ivan Kelly,ikelly,Should be public,2014-02-04 16:47:49,2014-02-06 08:21:31
BOOKKEEPER-729,"Bookie shouldn't exit with 0, if exiting from deathwatcher and thread death was caused by OOM",Bug,1,Resolved,5,Fixed,2014-02-06 08:26:11,2014-02-04 16:49:37,2014-02-06T08:58:44.000+0000,ikelly,Ivan Kelly,ikelly,"I've seen the deathwatcher reset the exit code to 0, even after it was set correct. We should make setting the exitcode a one way operation. ",2014-02-04 16:49:37,2014-02-06 08:26:11
BOOKKEEPER-730,Shade pom file missing apache license header,Bug,1,Resolved,5,Fixed,2014-03-07 18:06:24,2014-02-06 08:37:51,2014-03-07T18:06:24.000+0000,ikelly,Ivan Kelly,ikelly,Shade plugin doesn't generate pom file with apache license header.,2014-02-06 08:37:51,2014-03-07 18:06:24
BOOKKEEPER-731,Missing BOOKIE_PID_DIR and BOOKIE_STOP_TIMEOUT in env variables list,Bug,1,Resolved,5,Fixed,2014-02-10 05:54:13,2014-02-06 12:27:37,2014-02-10T06:28:38.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,,2014-02-06 12:27:37,2014-02-10 05:54:13
BOOKKEEPER-732,Add env variable ENTRY_FORMATTER_CLASS to the bkenv.sh,Improvement,4,Resolved,5,Fixed,2014-02-10 05:52:38,2014-02-06 12:33:10,2014-02-10T06:28:38.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,,2014-02-06 12:33:10,2014-02-10 05:52:38
BOOKKEEPER-733,Improve ReplicationWorker to handle the urLedgers which already have same leder replica in hand,Bug,1,Open,1,,,2014-02-18 16:46:51,2017-10-17T21:33:38.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"+Scenario:+

Step1 : Have three bookies BK1, BK2, BK3
Step2 : Have written ledgers with quorum 2
Step3 : Unfortunately BK2 and BK3 both went down for few moments.

The following logs are flooded in BK1 autorecovery logs. RW is trying to replicate the ledgers, but it simply skip this fragment and moves to next cycle when it sees a replica found in his hand. IMO, we should have a mechanism in place to avoid unnecessary cycles.

{code}
2014-02-18 21:47:55,140 - ERROR - [New I/O client boss #2-1:PerChannelBookieClient$1@230] - Could not connect to bookie: [id: 0x00ba679e]/10.18.170.130:15002, current state CONNECTING : 
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)
	at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.connect(NioClientSocketPipelineSink.java:401)
	at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.processSelectedKeys(NioClientSocketPipelineSink.java:370)
	at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.run(NioClientSocketPipelineSink.java:292)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:44)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:885)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
	at java.lang.Thread.run(Thread.java:619)
2014-02-18 21:47:55,140 - INFO  - 2014-02-18 21:59:33,215 - DEBUG  - [ReplicationWorker:ReplicationWorker@182] - Target Bookie[10.18.170.130:15003] found in the fragment ensemble: [10.18.170.130:15003, 10.18.170.130:15001, 10.18.170.130:15002]
[ReplicationWorker:PerChannelBookieClient@194] - Connecting to bookie: 10.18.170.130:15002
2014-02-18 21:47:56,162 - ERROR - [New I/O client boss #2-1:PerChannelBookieClient$1@230] - Could not connect to bookie: [id: 0x0003f377]/10.18.170.130:15002, current state CONNECTING : 
java.net.ConnectException: Connection refused: no further information
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:574)
	at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.connect(NioClientSocketPipelineSink.java:401)
	at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.processSelectedKeys(NioClientSocketPipelineSink.java:370)
	at org.jboss.netty.channel.socket.nio.NioClientSocketPipelineSink$Boss.run(NioClientSocketPipelineSink.java:292)
	at org.jboss.netty.util.ThreadRenamingRunnable.run(ThreadRenamingRunnable.java:108)
	at org.jboss.netty.util.internal.DeadLockProofWorker$1.run(DeadLockProofWorker.java:44)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:885)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:907)
	at java.lang.Thread.run(Thread.java:619)
2014-02-18 21:59:33,215 - DEBUG  - [ReplicationWorker:ReplicationWorker@182] - Target Bookie[10.18.170.130:15003] found in the fragment ensemble: [10.18.170.130:15003, 10.18.170.130:15001, 10.18.170.130:15002]

{code}",2014-02-18 16:46:51,
BOOKKEEPER-736,Stats for AutoRecovery,New Feature,2,Resolved,5,Fixed,2014-09-06 05:59:07,2014-02-24 07:39:02,2014-09-06T10:12:38.000+0000,hustlmsp,Sijie Guo,hustlmsp,Idea of this JIRA is to provide jmx interfaces to get the statistics of the auto recovery activities.,2014-02-24 07:39:02,2014-09-06 05:59:07
BOOKKEEPER-739,Test timeouts mostly ignored,Bug,1,Resolved,5,Fixed,2014-07-23 23:41:46,2014-03-04 17:48:00,2014-07-24T00:52:47.000+0000,hustlmsp,Sijie Guo,hustlmsp,"A lot of our tests extend BookKeeperClusterTestCase which extends TestCase, which is the junit 3 way of doing tests. Annotations is the junit4 way to doing tests. If you're using a junit3 harness, annotations are ignored. Therefore, most of our timeout annotations are ignored. I propose we move everything to the junit4 style.

http://stackoverflow.com/questions/1151237/junit-expected-tag-not-working-as-expected",2014-03-04 17:48:00,2014-07-23 23:41:46
BOOKKEEPER-740,AutoRecoveryMainTest#testAutoRecoverySessionLoss is failing,Bug,1,Resolved,5,Fixed,2014-03-10 02:15:03,2014-03-07 09:25:21,2014-03-10T02:45:46.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"It seems the test case is failiing due to the following exception at join and is skipping auditorElector.shutdown.

{code}
2014-03-06 13:27:18,603 - WARN  - [AutoRecoveryDeathWatcher-15007:AutoRecoveryMain@127] - Interrupted shutting down auto recovery
java.lang.InterruptedException
	at java.lang.Object.wait(Native Method)
	at java.lang.Thread.join(Thread.java:1186)
	at java.lang.Thread.join(Thread.java:1239)
	at org.apache.bookkeeper.replication.AutoRecoveryMain.shutdown(AutoRecoveryMain.java:122)
{code}",2014-03-07 09:25:21,2014-03-10 02:15:03
BOOKKEEPER-742,Fix for empty ledgers losing quorum.,Bug,1,Resolved,5,Fixed,2014-04-24 11:41:12,2014-04-04 15:23:54,2014-04-24T11:45:21.000+0000,ikelly,Ivan Kelly,ikelly,"If a ledger is open and empty, when a bookie in the ensemble crashes no recovery will take place (because there's nothing to recover). This open empty unrepaired ledger can persist for a long time. If it loses another bookie, it can lose quorum. At this point it's impossible for the bookie to know that its an empty ledger, and the admin gets notified of missing data.",2014-04-04 15:23:54,2014-04-24 11:41:12
BOOKKEEPER-743,Periodic ledger check running too often as doc doesn't match implementation.,Bug,1,Resolved,5,Fixed,2014-04-24 12:45:31,2014-04-04 15:24:54,2014-04-24T13:33:22.000+0000,ikelly,Ivan Kelly,ikelly,"The documentation says the configuration value for ""auditorPeriodicCheckInterval"" should be in seconds, but in fact the scheduler schedules it using milliseconds. This mean its running far too often.
    
",2014-04-04 15:24:54,2014-04-24 12:45:31
BOOKKEEPER-744,Run the auditor bookie check periodically,Bug,1,Resolved,5,Fixed,2014-05-06 13:14:12,2014-04-04 15:26:01,2014-05-06T22:01:23.000+0000,ikelly,Ivan Kelly,ikelly,"Previous the bookie check only runs when a bookie fails. If for some reason this doesn't pick up a failure, the failure will go undetected until the next time a bookie fails, in which case quorum could have been lost. This fix makes the bookie check run periodically, by default once a day.",2014-04-04 15:26:01,2014-05-06 13:14:12
BOOKKEEPER-745,Fix for false reports of ledger unreplication during rolling restarts.,Bug,1,Resolved,5,Fixed,2014-06-02 15:55:14,2014-04-04 15:27:30,2014-06-02T15:55:14.000+0000,ikelly,Ivan Kelly,ikelly,"The bug occurred because there was no check if rereplication was enabled or not when the auditor came online. When the auditor comes online it does a check of which bookies are up and marks the ledgers on missing bookies as underreplicated. In the false report case, the auditor was running after each bookie was bounced due to the way leader election for the auditor works. And since one bookie was down since you're bouncing the server, all ledgers on that bookie will get marked as underreplicated.",2014-04-04 15:27:30,2014-06-02 15:55:14
BOOKKEEPER-746,"5 new shell commands. List ledgers, list metadata, list underreplicated, show auditor and simpletest",Bug,1,Resolved,5,Fixed,2014-06-03 11:56:58,2014-04-04 15:29:38,2014-06-03T11:56:58.000+0000,ikelly,Ivan Kelly,ikelly,"names are self explanatory. 
1. list all the ledgers in the cluster
2. print the metadata for a ledger
3. list underreplicated ledgers
4. show the address of the auditor
5. simple test: create ledger, write to ledger, close ledger",2014-04-04 15:29:38,2014-06-03 11:56:58
BOOKKEEPER-747,Implement register/unregister LedgerMetadataListener in MSLedgerManagerFactory,Improvement,4,Resolved,5,Fixed,2014-05-12 06:36:42,2014-04-11 22:58:55,2014-05-12T19:47:18.000+0000,fpj,Flavio Paiva Junqueira,fpj,Check TODOs in MSLedgerManagerFactory.,2014-04-11 22:58:55,2014-05-12 06:36:42
BOOKKEEPER-748,Move fence requests out of read threads,Improvement,4,Resolved,5,Fixed,2017-06-05 20:25:31,2014-04-21 06:02:47,2017-06-06T18:13:15.000+0000,hustlmsp,Sijie Guo,hustlmsp,move fence requests out of read threads to address TODO.,2014-04-21 06:02:47,2017-06-05 20:25:31
BOOKKEEPER-749,Improve LedgerUnderreplicationManager#getLedgerToRereplicate(),Improvement,4,Open,1,,,2014-04-28 08:38:50,2017-10-17T21:33:35.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"As per the discussion in BOOKKEEPER-733, LedgerUnderreplicationManager#getLedgerToRereplicate having multiple resposibilities like : getUrLedger + acquireLock. Actually the idea of this JIRA is to make the interface better.

Please see the discussion thread:
https://issues.apache.org/jira/browse/BOOKKEEPER-733?focusedCommentId=13963072&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-13963072",2014-04-28 08:38:50,
BOOKKEEPER-750,Flake in BookieAutoRecoveryTest#testEmptyLedgerLosesQuorumEventually,Bug,1,Resolved,5,Fixed,2014-05-23 16:49:20,2014-04-29 20:10:53,2014-06-03T14:53:36.000+0000,ikelly,Ivan Kelly,ikelly,See https://builds.apache.org/job/bookkeeper-trunk-precommit-build/617/testReport/junit/org.apache.bookkeeper.replication/BookieAutoRecoveryTest/testEmptyLedgerLosesQuorumEventually/,2014-04-29 20:10:53,2014-05-23 16:49:20
BOOKKEEPER-751,Ensure all the bookkeeper callbacks not run under ledger handle lock,Bug,1,Resolved,5,Fixed,2014-05-30 15:42:22,2014-05-07 07:50:31,2014-05-30T15:50:16.000+0000,hustlmsp,Sijie Guo,hustlmsp,"we are running bookkeeper callbacks under ledger handle lock, which would possibly introduce deadlock if application call bookkeeper functions in those callbacks.",2014-05-07 07:50:31,2014-05-30 15:42:22
BOOKKEEPER-752,Deadlock on NIOServer shutdown,Bug,1,Resolved,5,Fixed,2014-05-27 10:53:42,2014-05-07 07:57:41,2014-05-27T10:53:43.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Not all places in NIOServerFactory acquire locks in order, which cause deadlock on shutdown. ",2014-05-07 07:57:41,2014-05-27 10:53:42
BOOKKEEPER-755,Incorrect number of seconds specified in a day,Bug,1,Resolved,5,Fixed,2014-05-14 22:44:41,2014-05-08 20:46:56,2014-05-15T21:11:06.000+0000,josephredfern,Joseph Redfern,josephredfern,"Pretty minor bug, but: https://github.com/apache/bookkeeper/blob/trunk/bookkeeper-server/src/main/java/org/apache/bookkeeper/conf/ServerConfiguration.java#L1182

specifies that there are 84600 seconds in a day, when there are in fact 86400. The default should be changed to to the correct value. ",2014-05-08 20:46:56,2014-05-14 22:44:41
BOOKKEEPER-756,Use HashedwheelTimer for request timeouts for PCBC,Improvement,4,Resolved,5,Fixed,2014-05-29 07:39:59,2014-05-12 04:18:43,2014-05-29T07:39:59.000+0000,hustlmsp,Sijie Guo,hustlmsp,"Current scheduler based timeout mechanism is per batch, which isn't efficient. HashedWheelTimer is much better for timeouts. So change the PCBC to use HashedWheelTimer for timeouts.

Besides that HashedWheelTimer change, it also provides multiple channel per bookie support for latency consideration.",2014-05-12 04:18:43,2014-05-29 07:39:59
BOOKKEEPER-757,Ledger Recovery Improvement,Improvement,4,Resolved,5,Fixed,2017-06-22 00:10:05,2014-05-12 04:24:32,2017-06-22T00:10:05.000+0000,hustlmsp,Sijie Guo,hustlmsp,"for performance consideration, the jira is targeting on improving ledger recovery. this ticket is to track improvements:

- add a parallel reading request in PendingReadOp (so when we read range of requests, we could callback individual entry if they are available)
- change recovery read to use batch read, so we could parallel reading entries to improve recovery time.",2014-05-12 04:24:32,2017-06-22 00:10:05
BOOKKEEPER-758,Add TryReadLastAddConfirmed API,Improvement,4,Resolved,5,Fixed,2014-05-30 12:02:00,2014-05-12 05:01:53,2014-05-30T12:45:16.000+0000,hustlmsp,Sijie Guo,hustlmsp,"add TryReadLastConfirmed to read last confirmed without coverage checking, as for readers which polls LAC, they just need LAC.",2014-05-12 05:01:53,2014-05-30 12:02:00
BOOKKEEPER-759,bookkeeper: delay ensemble change if it doesn't break ack quorum requirement,Improvement,4,Resolved,5,Fixed,2017-06-29 22:12:54,2014-05-12 05:05:43,2017-06-30T14:03:31.000+0000,hustlmsp,Sijie Guo,hustlmsp,"flag to allow delay ensemble change. if that is set to change, will not do ensemble change until it breaks ack quorum requirement",2014-05-12 05:05:43,2017-06-29 22:12:54
BOOKKEEPER-760,Don't close PCBC proactively if bookies disappeared from zookeeper znodes.,Improvement,4,Closed,6,Fixed,2015-07-28 11:46:05,2014-05-12 05:25:24,2016-05-16T21:47:44.000+0000,hustlmsp,Sijie Guo,hustlmsp,Don't close PCBC proactively if bookies disappeared from zookeeper znodes.,2014-05-12 05:25:24,2015-07-28 11:46:05
BOOKKEEPER-763,findbugs fails to run on jenkins,Bug,1,Resolved,5,Fixed,2014-05-30 10:42:17,2014-05-29 12:45:01,2014-05-30T11:20:21.000+0000,ikelly,Ivan Kelly,ikelly,"Search for [ERROR] in https://builds.apache.org/job/bookkeeper-trunk-precommit-build/641/consoleText

The problem is that maven isn't able to resolve the sibling modules if they are not installed in a repo it has access to.",2014-05-29 12:45:01,2014-05-30 10:42:17
BOOKKEEPER-765,bookkeeper script should fall back to java in path if JAVA_HOME is not set,Bug,1,Resolved,5,Fixed,2014-06-10 10:04:20,2014-06-03 16:23:32,2014-06-10T10:46:25.000+0000,ikelly,Ivan Kelly,ikelly,"The current behaviour requires JAVA_HOME to be set, which isn't set by default on all machines. So machines on which bookkeeper ran fine, no longer work.

Solution is to fallback to java in path is JAVA_HOME not set.",2014-06-03 16:23:32,2014-06-10 10:04:20
BOOKKEEPER-766,Update notice.txt files to include 2014,Bug,1,Resolved,5,Fixed,2014-06-05 10:56:49,2014-06-03 17:05:57,2014-06-05T12:48:53.000+0000,ikelly,Ivan Kelly,ikelly,Copyright should include this year.,2014-06-03 17:05:57,2014-06-05 10:56:49
BOOKKEEPER-767,Allow loopback in tests,Bug,1,Resolved,5,Fixed,2014-06-06 13:32:43,2014-06-04 09:05:31,2014-06-06T14:00:46.000+0000,ikelly,Ivan Kelly,ikelly,"It's not uncommon to have something like the following in /etc/hosts:
{quote}
127.0.1.1 <myhostname>
{quote}

This breaks the bookkeeper tests because getAllowLoopback() defaults to false. We should set allow loopback to true to allow tests to run out of the box on linux machines.",2014-06-04 09:05:31,2014-06-06 13:32:43
BOOKKEEPER-768,fix typo 'seconds' to milliseconds in benchmark output,Bug,1,Resolved,5,Fixed,2014-07-15 07:09:50,2014-06-17 17:32:47,2014-07-15T08:00:22.000+0000,jaln,jialin,jaln,fix typo 'seconds' to 'milliseconds' in benchmark output,2014-06-17 17:32:47,2014-07-15 07:09:50
BOOKKEEPER-769,Remove hedwig from source tree,Bug,1,Closed,6,Fixed,2016-03-16 03:44:48,2014-06-19 10:01:13,2016-05-16T21:47:28.000+0000,robindhamankar,Robin Dhamankar,robindhamankar,"As the license issue, isn't forcing the issue right now, I'd like to change this to a general discussion of the future of hedwig. Almost all the comments about the c++ client apply to hedwig as a whole. Hedwig has only had 5 real changes in the last year, only one in 2014. For all intensive purposes, it is inactive, unmaintained and unsupported. AFAIK, noone is using it in production in anything close to the form of the apache codebase.

However, by having it in the codebase, at the same level of bookkeeper-server, we are indicating to users that it is in fact supported software and considered as important as bookkeeper-server. So, I would like to propose that, after the 4.3.0 release, we remove hedwig from the codebase. Obviously, it will still be available in the git/svn history, and in all releases <= 4.3.0.

-The hedwig c++ client has not had any real code change since november 2012. It is not built as part of the main build. It is not tested as part of the main build. It is effectively unmaintained.-

-In addition to this, it contains m4 files whose license status is unclear.-

-I propose we simple remove it from trunk and branch-4.2. The license issue is currently blocking the release of 4.2.3. [~jiannan], [~farrellee], you were the last people to submit anything for the client. Are you using in production? Any objection to its removal from the main code tree?-",2014-06-19 10:01:13,2016-03-16 03:44:48
BOOKKEEPER-772,Reorder read sequnce ,Improvement,4,Resolved,5,Fixed,2017-07-04 05:10:15,2014-07-23 04:16:10,2017-07-04T13:40:33.000+0000,hustlmsp,Sijie Guo,hustlmsp,"We should reorder the read sequence base on location, bookie availability, for latency consideration.",2014-07-23 04:16:10,2017-07-04 05:10:15
BOOKKEEPER-773,Provide admin tool to rename bookie identifier in Cookies,Sub-task,7,Resolved,5,Fixed,2014-09-29 14:29:49,2014-07-25 11:17:03,2014-09-29T17:33:38.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"The idea of this JIRA to implement a mechanism to efficiently rename the bookie identifier present in the Cookies. Cookie information will be present in:
- ledger & journal directories in each Bookie server
- cookies znode in ZooKeeper",2014-07-25 11:17:03,2014-09-29 14:29:49
BOOKKEEPER-774,Flaky test org.apache.bookkeeper.test.ReadOnlyBookieTest.testBookieShouldTurnWritableFromReadOnly,Bug,1,Resolved,5,Fixed,2014-08-14 06:16:25,2014-07-26 07:34:12,2014-08-14T09:08:08.000+0000,hustlmsp,Sijie Guo,hustlmsp,"it failed at https://builds.apache.org/job/bookkeeper-trunk/716 .

It seems that an addEntry hit a ClosedChannelException on file io after the bookie turned to writable from readonly.

{code}
2014-07-26 07:03:14,584 - ERROR - [BookieWriteThread-15006-0:WriteEntryProcessorV3@103] - Error writing entry:0 to ledger:4
java.nio.channels.ClosedChannelException
	at sun.nio.ch.FileChannelImpl.ensureOpen(FileChannelImpl.java:88)
	at sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:184)
	at org.apache.bookkeeper.bookie.BufferedChannel.flushInternal(BufferedChannel.java:126)
	at org.apache.bookkeeper.bookie.BufferedChannel.flush(BufferedChannel.java:111)
	at org.apache.bookkeeper.bookie.EntryLogger.createNewLog(EntryLogger.java:371)
	at org.apache.bookkeeper.bookie.EntryLogger.addEntry(EntryLogger.java:623)
	at org.apache.bookkeeper.bookie.InterleavedLedgerStorage.processEntry(InterleavedLedgerStorage.java:296)
	at org.apache.bookkeeper.bookie.InterleavedLedgerStorage.processEntry(InterleavedLedgerStorage.java:283)
	at org.apache.bookkeeper.bookie.InterleavedLedgerStorage.addEntry(InterleavedLedgerStorage.java:196)
	at org.apache.bookkeeper.bookie.LedgerDescriptorImpl.addEntry(LedgerDescriptorImpl.java:80)
	at org.apache.bookkeeper.bookie.Bookie.addEntryInternal(Bookie.java:1046)
	at org.apache.bookkeeper.bookie.Bookie.addEntry(Bookie.java:1085)
	at org.apache.bookkeeper.proto.WriteEntryProcessorV3.getAddResponse(WriteEntryProcessorV3.java:99)
	at org.apache.bookkeeper.proto.WriteEntryProcessorV3.run(WriteEntryProcessorV3.java:132)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:439)
	at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:303)
	at java.util.concurrent.FutureTask.run(FutureTask.java:138)
	at java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:895)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:918)
	at java.lang.Thread.run(Thread.java:662)
{code}",2014-07-26 07:34:12,2014-08-14 06:16:25
BOOKKEEPER-775,Improve MultipleThreadReadTest to reduce flakiness,Test,6,Resolved,5,Fixed,2014-09-10 22:41:48,2014-08-02 00:41:58,2014-09-12T04:11:42.000+0000,hustlmsp,Sijie Guo,hustlmsp,,2014-08-02 00:41:58,2014-09-10 22:41:48
BOOKKEEPER-776,Flaky test BookieRecoveryTest,Test,6,Resolved,5,Fixed,2014-09-09 10:40:29,2014-08-02 00:43:54,2014-09-09T11:01:33.000+0000,ikelly,Ivan Kelly,ikelly,"

testMetadataConflictWithRecovery[0](org.apache.bookkeeper.client.BookieRecoveryTest): Not fully replicated",2014-08-02 00:43:54,2014-09-09 10:40:29
BOOKKEEPER-777,Flake in LedgerCloseTest,Bug,1,Resolved,5,Fixed,2014-09-06 05:14:17,2014-08-28 14:29:37,2014-09-06T06:12:33.000+0000,ikelly,Ivan Kelly,ikelly,This test fails every so often. Logs attached.,2014-08-28 14:29:37,2014-09-06 05:14:17
BOOKKEEPER-778,Flake in TestTryReadLastConfirmed,Bug,1,Resolved,5,Fixed,2014-09-09 03:57:24,2014-08-28 14:42:25,2014-09-09T04:57:39.000+0000,ikelly,Ivan Kelly,ikelly,Logs attached.,2014-08-28 14:42:25,2014-09-09 03:57:24
BOOKKEEPER-779,jmx reporter for codahale metrics provider,Bug,1,Resolved,5,Fixed,2014-09-06 05:27:23,2014-08-28 14:53:15,2014-09-06T07:08:22.000+0000,ikelly,Ivan Kelly,ikelly,Allow access to metrics through jmx.,2014-08-28 14:53:15,2014-09-06 05:27:23
BOOKKEEPER-780,Findbug issue in trunk,Bug,1,Resolved,5,Fixed,2014-09-04 21:49:48,2014-08-28 16:26:31,2014-09-04T22:57:10.000+0000,ikelly,Ivan Kelly,ikelly,"[INFO] --- findbugs-maven-plugin:2.5.2:check (default-cli) @ bookkeeper-server ---
[INFO] BugInstance size is 1
[INFO] Error size is 0
[INFO] Total bugs: 1
[INFO] Dead store to conn in org.apache.bookkeeper.proto.WriteEntryProcessorV3$1.writeComplete(int, long, long, BookieSocketAddress, Object) [""org.apache.bookkeeper.proto.WriteEntryProcessorV3$1""] At WriteEntryProcessorV3.java:[lines 68-98]",2014-08-28 16:26:31,2014-09-04 21:49:48
BOOKKEEPER-781,Fix OOM on Hedwig Tests,Improvement,4,Resolved,5,Fixed,2014-09-09 09:03:56,2014-09-06 07:41:26,2014-09-09T09:31:43.000+0000,hustlmsp,Sijie Guo,hustlmsp,"{code}
java.lang.OutOfMemoryError: Direct buffer memory
	at java.nio.Bits.reserveMemory(Bits.java:632)
	at java.nio.DirectByteBuffer.<init>(DirectByteBuffer.java:97)
	at java.nio.ByteBuffer.allocateDirect(ByteBuffer.java:288)
	at org.jboss.netty.channel.socket.nio.SocketSendBufferPool$Preallocation.<init>(SocketSendBufferPool.java:155)
	at org.jboss.netty.channel.socket.nio.SocketSendBufferPool.<init>(SocketSendBufferPool.java:42)
	at org.jboss.netty.channel.socket.nio.NioWorker.<init>(NioWorker.java:84)
	at org.jboss.netty.channel.socket.nio.NioServerSocketPipelineSink.<init>(NioServerSocketPipelineSink.java:66)
	at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:138)
	at org.jboss.netty.channel.socket.nio.NioServerSocketChannelFactory.<init>(NioServerSocketChannelFactory.java:109)
	at org.apache.bookkeeper.proto.BookieNettyServer.<init>(BookieNettyServer.java:76)
	at org.apache.bookkeeper.proto.BookieServer.<init>(BookieServer.java:97)
	at org.apache.bookkeeper.proto.BookieServer.<init>(BookieServer.java:86)
	at org.apache.hedwig.server.persistence.BookKeeperTestBase$TestBookieServer.<init>(BookKeeperTestBase.java:86)
	at org.apache.hedwig.server.persistence.BookKeeperTestBase.startBookie(BookKeeperTestBase.java:234)
	at org.apache.hedwig.server.persistence.BookKeeperTestBase.startUpNewBookieServer(BookKeeperTestBase.java:222)
	at org.apache.hedwig.server.persistence.BookKeeperTestBase.setUp(BookKeeperTestBase.java:159)
	at org.apache.hedwig.server.HedwigHubTestBase.setUp(HedwigHubTestBase.java:178)
	at org.apache.hedwig.server.integration.TestHedwigHub.setUp(TestHedwigHub.java:226)
	at sun.reflect.GeneratedMethodAccessor50.invoke(Unknown Source)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:27)
	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:76)
	at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
	at org.junit.runners.Suite.runChild(Suite.java:128)
	at org.junit.runners.Suite.runChild(Suite.java:24)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
	at org.apache.maven.surefire.junit4.JUnit4TestSet.execute(JUnit4TestSet.java:53)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:123)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:104)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110)
	at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:172)
	at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcessWhenForked(SurefireStarter.java:78)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:70)
{code}",2014-09-06 07:41:26,2014-09-09 09:03:56
BOOKKEEPER-782,Use builder pattern for Cookie,Sub-task,7,Resolved,5,Fixed,2014-09-18 04:57:29,2014-09-11 09:42:54,2014-09-18T05:30:46.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"It would be good to use builder pattern for Cookie, rather than modifying the fields in place.",2014-09-11 09:42:54,2014-09-18 04:57:29
BOOKKEEPER-783,Avoid running out of fds in MutlipleThreadReadTest,Bug,1,Resolved,5,Fixed,2014-09-17 14:34:10,2014-09-12 05:02:48,2014-09-17T15:16:10.000+0000,hustlmsp,Sijie Guo,hustlmsp,"{code}
org.jboss.netty.channel.ChannelException: Failed to create a selector.
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:343)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.<init>(AbstractNioSelector.java:100)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorker.<init>(AbstractNioWorker.java:52)
	at org.jboss.netty.channel.socket.nio.NioWorker.<init>(NioWorker.java:45)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.createWorker(NioWorkerPool.java:45)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.createWorker(NioWorkerPool.java:28)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorkerPool.newWorker(AbstractNioWorkerPool.java:143)
	at org.jboss.netty.channel.socket.nio.AbstractNioWorkerPool.init(AbstractNioWorkerPool.java:81)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:39)
	at org.jboss.netty.channel.socket.nio.NioWorkerPool.<init>(NioWorkerPool.java:33)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.<init>(NioClientSocketChannelFactory.java:151)
	at org.jboss.netty.channel.socket.nio.NioClientSocketChannelFactory.<init>(NioClientSocketChannelFactory.java:116)
	at org.apache.bookkeeper.client.BookKeeper.<init>(BookKeeper.java:204)
	at org.apache.bookkeeper.client.BookKeeperTestClient.<init>(BookKeeperTestClient.java:50)
	at org.apache.bookkeeper.test.MultipleThreadReadTest.createClients(MultipleThreadReadTest.java:73)
	at org.apache.bookkeeper.test.MultipleThreadReadTest.multiLedgerMultiThreadRead(MultipleThreadReadTest.java:282)
	at org.apache.bookkeeper.test.MultipleThreadReadTest.test1Ledger50ThreadsRead(MultipleThreadReadTest.java:326)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.FailOnTimeout$1.run(FailOnTimeout.java:28)
Caused by: java.io.IOException: Too many open files
	at sun.nio.ch.EPollArrayWrapper.epollCreate(Native Method)
	at sun.nio.ch.EPollArrayWrapper.<init>(EPollArrayWrapper.java:69)
	at sun.nio.ch.EPollSelectorImpl.<init>(EPollSelectorImpl.java:52)
	at sun.nio.ch.EPollSelectorProvider.openSelector(EPollSelectorProvider.java:18)
	at java.nio.channels.Selector.open(Selector.java:209)
	at org.jboss.netty.channel.socket.nio.SelectorUtil.open(SelectorUtil.java:63)
	at org.jboss.netty.channel.socket.nio.AbstractNioSelector.openSelector(AbstractNioSelector.java:341)
{code}",2014-09-12 05:02:48,2014-09-17 14:34:10
BOOKKEEPER-784,BookKeeperCloseTest#testLedgerCheck is failing intermittently,Bug,1,Resolved,5,Fixed,2014-09-18 04:54:06,2014-09-12 08:35:46,2014-09-18T05:30:43.000+0000,ikelly,Ivan Kelly,ikelly,"*Stacktrace*
{code}
java.lang.AssertionError: Should have client closed exception expected:<0> but was:<-19>
	at org.junit.Assert.fail(Assert.java:91)
	at org.junit.Assert.failNotEquals(Assert.java:645)
	at org.junit.Assert.assertEquals(Assert.java:126)
	at org.junit.Assert.assertEquals(Assert.java:470)
	at org.apache.bookkeeper.client.BookKeeperCloseTest.testLedgerCheck(BookKeeperCloseTest.java:501)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
	at java.lang.reflect.Method.invoke(Method.java:597)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
	at org.junit.internal.runners.statements.FailOnTimeout$1.run(FailOnTimeout.java:28)
{code}

Link: https://builds.apache.org/job/bookkeeper-trunk-precommit-build/722/testReport/junit/org.apache.bookkeeper.client/BookKeeperCloseTest/testLedgerCheck/",2014-09-12 08:35:46,2014-09-18 04:54:06
BOOKKEEPER-785,Fix javadoc warnings in trunk,Bug,1,Resolved,5,Fixed,2014-09-18 04:47:42,2014-09-17 14:34:47,2014-09-18T05:30:45.000+0000,ikelly,Ivan Kelly,ikelly,,2014-09-17 14:34:47,2014-09-18 04:47:42
BOOKKEEPER-786,Fix Findbugs Error In Codahale Stats Provider,Bug,1,Resolved,5,Fixed,2014-09-22 10:11:56,2014-09-20 05:21:40,2014-09-22T10:46:15.000+0000,hustlmsp,Sijie Guo,hustlmsp,"{quote}
[INFO] BugInstance size is 1
[INFO] Error size is 0
[INFO] Total bugs: 1
[INFO] Inconsistent synchronization of org.apache.bookkeeper.stats.CodahaleMetricsProvider.metrics; locked 83% of time [""org.apache.bookkeeper.stats.CodahaleMetricsProvider""] At CodahaleMetricsProvider.java:[lines 49-145]
{quote}",2014-09-20 05:21:40,2014-09-22 10:11:56
BOOKKEEPER-787,Modify Cookie by removing 'znodeVersion' state/field,Sub-task,7,Resolved,5,Fixed,2014-09-23 15:55:47,2014-09-23 09:20:12,2014-09-23T16:30:37.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"The idea is to make Versioned<Cookie> instead of maintaining 'znodeVersion' by Cookie.

Please see the [discussion thread|https://issues.apache.org/jira/browse/BOOKKEEPER-773?focusedCommentId=14143263&page=com.atlassian.jira.plugin.system.issuetabpanels:comment-tabpanel#comment-14143263] for more details.",2014-09-23 09:20:12,2014-09-23 15:55:47
BOOKKEEPER-788,Provide release inspector script,Improvement,4,Resolved,5,Won't Do,2017-06-22 00:13:37,2014-10-04 15:28:41,2017-06-22T00:13:37.000+0000,hustlmsp,Sijie Guo,hustlmsp,"For each release, we need to type a sequence of commands to validate release candidate tag. This process could be achieved by a single script.

Here is the behavior of the script in my mind:
   1. Collecting build environment info (Operation System, JDK, Maven)
   2. Run 'mvn install -DskipTests'
   3. Checking code (findbugs, rat).
   4. Running unit test
   5. Start standalone Bookie and Hedwig service
   6. Run simple Bookie test: bookkeeper-server/bin/bookkeeper simpletest
-ensemble 3 -writeQuorum 3
   7. Run simple Hedwig test: hedwig-server/bin/hedwig console; pubsub
topic subscriber 10 message
   8. Tar all above logs when error/exit

In addition, this script could also be provided to user which could collect related information to diagnose compile/UT failure issue.",2014-10-04 15:28:41,2017-06-22 00:13:37
BOOKKEEPER-789,Update README to reflect bookkeeper modules,Task,3,Closed,6,Fixed,2014-10-08 08:44:17,2014-10-04 21:02:35,2016-05-16T21:47:42.000+0000,hustlmsp,Sijie Guo,hustlmsp,"{quote}
""BookKeeper project contains:"" section missing the following projects info.
- bookkeeper-stats (Stats API for bookkeeper)
- hedwig-client-jms (Hedwig client jms)
{quote}",2014-10-04 21:02:35,2014-10-08 08:44:17
BOOKKEEPER-790,Add JNA license in NOTICE files,Task,3,Closed,6,Fixed,2014-10-14 08:49:39,2014-10-07 07:20:21,2016-05-16T21:47:38.000+0000,hustlmsp,Sijie Guo,hustlmsp,Add JNA in NOTICE file.,2014-10-07 07:20:21,2014-10-14 08:49:39
BOOKKEEPER-791,New text for bookkeeper homepage,Improvement,4,Resolved,5,Done,2014-10-10 14:20:18,2014-10-09 10:07:58,2014-10-10T14:20:18.000+0000,ikelly,Ivan Kelly,ikelly,"The current text on the frontpage means little to people who don't already know what bookkeeper is. From experience, they think it's like log4j, but distributed. We need to be clearer for these people, as they are really the people who the frontpage is for.

I've put a draft.

https://reviews.apache.org/r/26491/",2014-10-09 10:07:58,2014-10-10 14:20:18
BOOKKEEPER-792,Split bookkeeper client into a separate maven module,Bug,1,Open,1,,,2014-10-13 16:11:10,2017-10-17T21:29:18.000+0000,ikelly,Ivan Kelly,ikelly,"Right now, to include bookkeeper as a dependency, you need to include org.apache.bookkeeper:bookkeeper-server

This pulls in all the bookkeeper-server code, and all the server dependencies as well as the client. The server dependencies are larger than the client dependencies. For one thing, it pulls in jna and log4j which should never be pulled in from the client.",2014-10-13 16:11:10,
BOOKKEEPER-793,Move to java 7,Bug,1,Closed,6,Fixed,2014-10-15 05:27:17,2014-10-13 16:18:18,2016-05-16T21:47:26.000+0000,ikelly,Ivan Kelly,ikelly,Oracle ended support for java 6 last march. We should follow their lead. As an added bonus we can start to use async io apis with 7.,2014-10-13 16:18:18,2014-10-15 05:27:17
BOOKKEEPER-794,BookkeeperProtocol.Response.status is completely ignored,Bug,1,Closed,6,Fixed,2016-04-05 19:56:39,2014-10-17 09:53:24,2016-05-16T21:47:48.000+0000,mmerli,Matteo Merli,mmerli,"As the summary says, if you set the status to anything but ok, it will be ignored by PerChannelBookieClient. If you try to handle it, a whole load of tests fail due to different mapping for read and write requests.

I'm running this while rebasing our auth stuff, which i'll push up when it's been validated. I means the auth stuff needs to be aware of all message types, as I can't just send a EUA error in the packet level status.",2014-10-17 09:53:24,2016-04-05 19:56:39
BOOKKEEPER-795,Race condition causes writes to hang if ledger is fenced,Bug,1,Closed,6,Fixed,2014-12-09 19:55:59,2014-10-27 14:18:23,2016-05-16T21:47:31.000+0000,hustlmsp,Sijie Guo,hustlmsp,"If a ledger is fenced while the write is still writing to it, some of the writes will fail to ever complete.

I've attached the log of this happening along with a test case that will trigger the behaviour.

What appears to be happening is that when the fence occurs, the first write after the fence gets an unrecoverable error, so tries to close the ledger. Closing the ledger sets the closed flag on the ledger metadata, and tries to write it, which fails as the metadata in zookeeper was modified by the fencing operation, so the close op fails, resets the closed status for a moment, a write operation gets through, which then fails with a fencing error, so we try to close the ledger, but the other close operation has since closed the ledger in our metadata, so nothing happens, and the write hangs forever.

There's a number of issues here, but foremost, the ledger metadata that the handle is using should only ever represent what is actually in zookeeper. Having various parts of the code flipping bits just explodes the state space. The LedgerMetadata object itself should be immutable, and should only be modified, as a local variable, using a builder, before writing to zookeeper. Only when the zookeeper operation succeeds should we update the reference which LedgerHandle has access to.

There's also a problem in how we handle pendingaddops when we close. Really it shouldn't be possible for a write op to get through after a closure, but we should be defensive here and error out anything that has gotten through, adding a big old log message to alert us that this cases that shouldn't happen, is happening.",2014-10-27 14:18:23,2014-12-09 19:55:59
BOOKKEEPER-796,Make bookkeeper client use reconnectable zookeeper wrapper,Sub-task,7,Closed,6,Fixed,2015-07-10 20:51:31,2014-11-10 16:23:23,2016-05-16T21:47:48.000+0000,hustlmsp,Sijie Guo,hustlmsp,BOOKKEEPER-704 introduced a reconnectable zookeeper wrapper. This patch is to make the bookkeeper client use it.,2014-11-10 16:23:23,2015-07-10 20:51:31
BOOKKEEPER-797,IllegalArgumentException when calling CodahaleOpStatsLogger#toOpStatsData(),Bug,1,Closed,6,Fixed,2014-11-19 17:01:00,2014-11-19 13:38:19,2016-05-16T21:47:30.000+0000,mmorel,Matthieu Morel,mmorel,"The implementation of CodahaleOpStatsLogger#toOpStatsData() passes incorrect parameters to codahale's Snapshot#getValue method, resulting in the following runtime exception:

java.lang.IllegalArgumentException: 10.0 is not in [0..1]
	at com.codahale.metrics.Snapshot.getValue(Snapshot.java:52)
	at org.apache.bookkeeper.stats.CodahaleOpStatsLogger.toOpStatsData(CodahaleOpStatsLogger.java:64)
...

In order to pass quantiles as [0..1] values, as expected by codahale metrics library, we must divide parameters by 100 before passing them.

",2014-11-19 13:38:19,2014-11-19 17:01:00
BOOKKEEPER-798,Make website look more modern,Bug,1,Resolved,5,Fixed,2014-12-02 10:11:01,2014-11-19 15:07:16,2014-12-02T10:11:02.000+0000,ikelly,Ivan Kelly,ikelly,The current website looks super old. This jira is to remedy the style. Changes to content will come later.,2014-11-19 15:07:16,2014-12-02 10:11:01
BOOKKEEPER-799,Distribution schedule coverage sets don't take gaps in response lists into account when writequorum > ackquorum,Bug,1,Closed,6,Fixed,2014-12-09 19:07:05,2014-11-21 11:33:30,2016-05-16T21:47:46.000+0000,ikelly,Ivan Kelly,ikelly,"The algorithm now be used to check if all quorums are being covered when sending a read lac or fencing message is broken when writeQuorum >= ackQuorum.

The purpose of the algorithm is to tell us when we have heard a response from enough nodes, that an ack quorum could not possibly have been formed without at least one of the nodes that we have heard responses from.

The current algorithm works when writeQuorum == ackQuorum, as we consider all quorums covered if the first |ackQuorum| nodes in the writeQuorum are covered. However, this doesn't work in the case that it's the middle node in the quorum that we have heard.

Take the example, e:4, w:3, a:2, and we've heard from node 0, and node 2. In this case, it is possible for the write quorum, 1,2,3 to get an ack quorum if 1 and 3 response. 
",2014-11-21 11:33:30,2014-12-09 19:07:05
BOOKKEEPER-800,Expose whether a ledger is closed or not,Bug,1,Closed,6,Fixed,2014-12-05 13:39:55,2014-11-21 13:30:18,2016-05-16T21:47:50.000+0000,ikelly,Ivan Kelly,ikelly,"On issue i could writing the tutorial is that when you open a ledger in non-recovery mode, it's not possible to check if the ledger you opened has been closed or is still been written too. This complicates things when you get to the end of the ledger, as you don't know whether to try for more entries in the same ledger, or to look at the next ledger is the list.

This jira is to expose this information (it's in the metadata). This method only makes sense for reading. For writing a ledger, you really should know if you closed the ledger or not, and if you don't then you shouldn't be touching it again.",2014-11-21 13:30:18,2014-12-05 13:39:55
BOOKKEEPER-801,Bookkeeper client tutorial,Bug,1,Closed,6,Fixed,2014-12-12 11:13:13,2014-11-21 16:51:10,2016-05-16T21:47:51.000+0000,ikelly,Ivan Kelly,ikelly,Taking the tutorial from https://github.com/ivankelly/bookkeeper-tutorial and adding it to the bookkeeper docs.,2014-11-21 16:51:10,2014-12-12 11:13:13
BOOKKEEPER-802,Bookkeeper protocol documentation,Bug,1,Closed,6,Fixed,2015-09-07 15:59:33,2014-11-21 16:56:18,2016-05-16T21:47:28.000+0000,ikelly,Ivan Kelly,ikelly,We need a precise description of the bookkeeper protocol and the guarantees therein.,2014-11-21 16:56:18,2015-09-07 15:59:33
BOOKKEEPER-803,Guide for making a replicated log out of ledgers,Bug,1,Closed,6,Fixed,2014-12-12 11:15:06,2014-11-21 17:00:24,2016-05-16T21:47:49.000+0000,ikelly,Ivan Kelly,ikelly,"We need a guide to show people how to create a replicated log out of ledgers, as ledgers on their own aren't enough.",2014-11-21 17:00:24,2014-12-12 11:15:06
BOOKKEEPER-804,Client program is not terminated when using openLedgerNoRecovery,Bug,1,Closed,6,Fixed,2014-12-06 06:43:18,2014-11-24 12:17:26,2016-05-16T21:47:37.000+0000,ikelly,Ivan Kelly,ikelly,"If a client program does some operations using a ledger handle opened by openLedgerNoRecovery(), the program is not terminated after the handle and bookkeeper object is closed.

Here is a sample code. 
{code}
import java.util.Enumeration;

import org.apache.bookkeeper.client.BookKeeper;
import org.apache.bookkeeper.client.LedgerEntry;
import org.apache.bookkeeper.client.LedgerHandle;

public class BkClient {
  public static void main(String[] args) {
    try {
      BookKeeper bk = new BookKeeper(""localhost:2181"");

      // 9 is a ledger id of an existing ledger
      LedgerHandle lh = bk.openLedgerNoRecovery(9, BookKeeper.DigestType.CRC32, ""passwd"".getBytes());

      Enumeration<LedgerEntry> entries = lh.readEntries(0, 0);

      lh.close();
      bk.close();
    } catch (Exception e) {
      e.printStackTrace();
    }
  }
}
{code}

Thread dump of this program shows that non-daemon thread ""ZkLedgerManagerScheduler-0""  is alive, after bk.close() is called. 
",2014-11-24 12:17:26,2014-12-06 06:43:18
BOOKKEEPER-805,NullPointException in bookie server when using twitter-ostrich-provider,Bug,1,Closed,6,Fixed,2014-12-06 05:55:39,2014-11-25 11:37:02,2016-05-16T21:47:54.000+0000,y0un5,Youngjoon Kim,y0un5,"How to reproduce this bug
1) Set configurations in conf/bk_server.conf to use twitter-ostrich-provider.
{noformat}
statsProviderClass=org.apache.bookkeeper.stats.twitter.ostrich.OstrichProvider
statsExport=true
{noformat}

2) Copy twitter-ostrich-provider-4.3.0.jar and required library jars to lib directory.
{noformat}
(library jars)
ostrich_2.9.2-9.1.3.jar
scala-json_2.9.2-3.0.1.jar
scala-library-2.9.2.jar
util-app_2.9.2-6.3.7.jar
util-core_2.9.2-6.3.7.jar
util-eval_2.9.2-6.3.7.jar
util-jvm_2.9.2-6.3.7.jar
util-logging_2.9.2-6.3.7.jar
{noformat}

3) Start a bookie server. Then, the server doesn't start and server log shows NullPointException.
{noformat}
2014-11-25 17:30:27,796 - ERROR [main:BookieServer@396] - Exception running bookie server :
java.lang.NullPointerException
    at com.twitter.ostrich.stats.StatsListener.<init>(StatsListener.scala:90)
    at com.twitter.ostrich.stats.LatchedStatsListener.<init>(StatsListener.scala:144)
    at com.twitter.ostrich.stats.StatsListener$$anonfun$apply$4.apply(StatsListener.scala:68)
    at com.twitter.ostrich.stats.StatsListener$$anonfun$apply$4.apply(StatsListener.scala:68)
    at com.twitter.ostrich.stats.StatsListener$$anonfun$getOrRegister$1.apply(StatsListener.scala:40)
    at com.twitter.ostrich.stats.StatsListener$$anonfun$getOrRegister$1.apply(StatsListener.scala:39)
    at scala.Option.getOrElse(Option.scala:108)
    at com.twitter.ostrich.stats.StatsListener$.getOrRegister(StatsListener.scala:39)
    at com.twitter.ostrich.stats.StatsListener$.apply(StatsListener.scala:67)
    at com.twitter.ostrich.admin.AdminServiceFactory$$anonfun$configureStatsListeners$1.apply(AdminServiceFactory.scala:81)
    at com.twitter.ostrich.admin.AdminServiceFactory$$anonfun$configureStatsListeners$1.apply(AdminServiceFactory.scala:81)
    at scala.collection.LinearSeqOptimized$class.foreach(LinearSeqOptimized.scala:59)
    at scala.collection.immutable.List.foreach(List.scala:76)
    at com.twitter.ostrich.admin.AdminServiceFactory.configureStatsListeners(AdminServiceFactory.scala:81)
    at com.twitter.ostrich.admin.AdminServiceFactory.apply(AdminServiceFactory.scala:61)
    at org.apache.bookkeeper.stats.twitter.ostrich.OstrichProvider.start(OstrichProvider.java:57)
    at org.apache.bookkeeper.proto.BookieServer.main(BookieServer.java:375)
{noformat}
",2014-11-25 11:37:02,2014-12-06 05:55:39
BOOKKEEPER-806,Please create a DOAP file for your TLP,Task,3,Resolved,5,Done,2017-10-09 09:31:14,2014-11-27 02:16:49,2017-10-09T09:31:14.000+0000,ikelly,Ivan Kelly,ikelly,"Please can you set up a DOAP for your project and get it added to files.xml?

Please see http://projects.apache.org/create.html

Once you have created the DOAP and committed it to your source code repository, please submit it for inclusion in the Apache projects listing as per:

http://projects.apache.org/create.html#submit

Remember, if you ever move or rename the doap file in future, please
ensure that files.xml is updated to point to the new location.

Thanks!",2014-11-27 02:16:49,2017-10-09 09:31:14
BOOKKEEPER-807,Document updatecookie and updateledgers admin tool sequence,Documentation,20,Open,1,,,2014-12-02 04:32:57,2017-10-17T21:29:15.000+0000,,,,,2014-12-02 04:32:57,
BOOKKEEPER-808,Shell cmd to audit the ledgers and list bookie id requires updation,New Feature,2,Open,1,,,2014-12-02 04:38:11,2017-10-17T21:33:32.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,The idea is to expose shell command to list the ledgers which needs to be updated using the 'updateledgers' command. This will be helpful for the administrators to ensure that the bookie id updation is completed.,2014-12-02 04:38:11,
BOOKKEEPER-809,Wrong metric on LedgerDeleteOp and LedgerOpenOp,Bug,1,Closed,6,Fixed,2014-12-06 06:16:51,2014-12-04 02:16:56,2016-05-16T21:47:28.000+0000,cxie,Charles X,cxie,"These two operations uses startTime as the latency for metric, which is wrong. 

{code}
    void openComplete(int rc, LedgerHandle lh) {
        if (BKException.Code.OK != rc) {
            openOpLogger.registerFailedEvent(startTime);
        } else {
            openOpLogger.registerSuccessfulEvent(startTime);
        }
        cb.openComplete(rc, lh, ctx);
    }
{code}",2014-12-04 02:16:56,2014-12-06 06:16:51
BOOKKEEPER-810,Allow to configure TCP connect timeout,Improvement,4,Closed,6,Fixed,2014-12-06 06:58:52,2014-12-04 02:32:27,2016-05-16T21:47:51.000+0000,cxie,Charles X,cxie,"in one of our use cases, we might encounter slow network on some bookies. we'd like it to be timeout quickly so the bookkeeper client could do ensemble change to replace good bookies. so we'd like the ability to configure tcp connection timeout.",2014-12-04 02:32:27,2014-12-06 06:58:52
BOOKKEEPER-811,Recovery tool doesn't remove cookie after recovering one bookie,Improvement,4,Closed,6,Fixed,2014-12-06 07:06:21,2014-12-04 02:38:19,2016-05-16T21:47:46.000+0000,cxie,Charles X,cxie,"we ran bookie recovery tool to recover bookie after encountered hardware issue. but the recovery tool doesn't remove the cookie after it finished recovery. so when we fixed the bookie and added it back to the cluster, it couldn't start because the cookie exists on zookeeper but not on disks.

we want the tool could delete the cookie after recover a bookie, or maybe provide another tool to remove the cookie for a bookie.",2014-12-04 02:38:19,2014-12-06 07:06:21
BOOKKEEPER-812,StatsLogger doesn't cache counters/stats-loggers,Improvement,4,Open,1,,,2014-12-04 02:43:11,2017-10-17T21:29:11.000+0000,ankurgarg9,Ankur Garg,ankurgarg9,"Currently the stats providers implementation doesn't provide caching ability for counters/stats loggers for different metrics. if the underlying stats library (e.g. code hale, ostrich) doesn't provide that, the client would end up creating different instances for same metric name, which would introduce bad gc behavior.

it would be better that bookkeeper-stats-provider could address this in high level, rather than ask individual stats provider implementing similar caching behavior.",2014-12-04 02:43:11,
BOOKKEEPER-813,BookieShell doesn't find index directory ,Bug,1,Closed,6,Fixed,2014-12-06 06:50:48,2014-12-04 02:49:36,2016-05-16T21:47:43.000+0000,cxie,Charles X,cxie,"we configured our bookie to use indexDirectory, which is supposed to store the index files on it. but when we use BookieShell tool to inspect a ledger's entries, it ends up failing to read any ledger. it seems that the BookieShell doesn't handle indexDirectory correctly.",2014-12-04 02:49:36,2014-12-06 06:50:48
BOOKKEEPER-814,clean up temp files that generated by test cases.,Bug,1,Closed,6,Fixed,2014-12-10 18:46:56,2014-12-04 03:00:59,2016-05-16T21:47:33.000+0000,zhaijia,Jia Zhai,zhaijia,"Currently some of bookkeeper test cases are using temp files for unit tests. Those temp files aren't cleaned up after unit tests finished. 
If running several times of these test cases, /tmp directory will soon be full.",2014-12-04 03:00:59,2014-12-10 18:46:56
BOOKKEEPER-815,Ledger fence state is lost when the ledger file is evicted,Bug,1,Closed,6,Fixed,2014-12-05 11:27:47,2014-12-04 03:07:12,2016-05-16T21:47:33.000+0000,cxie,Charles X,cxie,"we observed in our use case that when a ledger file is evicted before flushing. the fence state isn't persisted to disk, which would cause fencing doesn't work correctly.",2014-12-04 03:07:12,2014-12-05 11:27:47
BOOKKEEPER-816,use native fallocate & sync_file_range to improve journal allocation,Improvement,4,Patch Available,10002,,,2014-12-05 06:15:20,2017-10-17T21:29:07.000+0000,hustlmsp,Sijie Guo,hustlmsp,it'd better to leverage filesystem fallocate & sync_file_range for journal performance.,2014-12-05 06:15:20,
BOOKKEEPER-817,Bookie: LRU FileInfo Eviction Policy,Improvement,4,Open,1,,,2014-12-05 06:17:58,2017-10-17T21:29:04.000+0000,hustlmsp,Sijie Guo,hustlmsp,"currently ledger cache used a FIFO mechanism to evict file info, it is not efficient. it'd better to adopt guava cache for file info cache.",2014-12-05 06:17:58,
BOOKKEEPER-818,Make bookie recovery work with recovering multiple bookies,Improvement,4,Open,1,,,2014-12-05 06:20:04,2017-10-17T21:29:01.000+0000,hustlmsp,Sijie Guo,hustlmsp,Make recovery tool work with multiple bookies so we could recover bookies inside ensemble at one time call. so we don't need to run the tool multiple times when we want to recover multiple bookies,2014-12-05 06:20:04,
BOOKKEEPER-819,Bound maximum number of ensemble changes,Bug,1,Open,1,,,2014-12-05 06:26:31,2017-10-17T21:28:58.000+0000,hustlmsp,Sijie Guo,hustlmsp,"when bookkeeper cluster is overwhelm, the ensemble changes would end up causing sending more traffic to the cluster, which make the cluster getting worse. it would be better to set a timeout to addEntry, which to limit the number of ensemble changes that a ledger handle could do.",2014-12-05 06:26:31,
BOOKKEEPER-820,print out fi.isFenced() in BookieShell,Improvement,4,Closed,6,Fixed,2014-12-06 06:31:24,2014-12-05 07:52:54,2016-05-16T21:47:31.000+0000,zhaijia,Jia Zhai,zhaijia,It would be useful to print out fi.isFenced() in BookieShell.,2014-12-05 07:52:54,2014-12-06 06:31:24
BOOKKEEPER-821,Failing to write lastId to ledger directories should not fail startup of bookies,Bug,1,Closed,6,Fixed,2015-05-20 06:20:45,2014-12-08 04:43:26,2016-05-16T21:47:44.000+0000,zhaijia,Jia Zhai,zhaijia,"At the startup of bookie,   the bookie constructor would call setLastLogId() as this trace:
	Bookie() -> InterleavedLedgerStorage() -> EntryLogger() -> Initialize() - >createNewLog() -> allocateNewLog() -> setLastLogId().  

If ""bw.write() and bw.flush()"" in setLastLogId() failed, an IOException would throw and not catch, and cause Bookie constructor fail. 
	{code}
	    private void setLastLogId(File dir, long logId) throws IOException {
	        FileOutputStream fos;
	        fos = new FileOutputStream(new File(dir, ""lastId""));
	        BufferedWriter bw = new BufferedWriter(new OutputStreamWriter(fos, UTF_8));
	        try {     // < ==== original: if write fail in this try, IOException thrown but not catch, and cause bookie startup fail.
	            bw.write(Long.toHexString(logId) + ""\n"");
	            bw.flush();
	        } finally {
	            try {
	                bw.close();
	            } catch (IOException e) {
	                LOG.error(""Could not close lastId file in {}"", dir.getPath());
	            }
	        }
	    }
	{code}

But failing setLastLogId() could be tolerated, and will not cause any problem in next time Bookie startup.  
Next time, when calling EntryLogger constructor again, in getLastLogId(), if read ledgerDir.lastId fail, it will walk through all log files to get LastLogID; If reading an old ledgerDir.lastId, which caused by last failure of setLastLogId(), and it happened to be the largest logId, then allocateNewLog() will find the file already exist, and will allocate newlogfile with bigger ID.
{code}
       BufferedLogChannel allocateNewLog() throws IOException {
            List<File> list = ledgerDirsManager.getWritableLedgerDirs();
            Collections.shuffle(list);
            // It would better not to overwrite existing entry log files
            File newLogFile = null;
            do {
                String logFileName = Long.toHexString(++preallocatedLogId) + "".log"";
                for (File dir : list) {
                    newLogFile = new File(dir, logFileName);
                    currentDir = dir;
                    if (newLogFile.exists()) {  < === this will handle last set fail issue, in which LastId update fail, and get a wrong preallocatedLogId.
                        LOG.warn(""Found existed entry log "" + newLogFile
                               + "" when trying to create it as a new log."");
                        newLogFile = null;
                        break;
                    }
                }
            } while (newLogFile == null);

            FileChannel channel = new RandomAccessFile(newLogFile, ""rw"").getChannel();
            BufferedLogChannel logChannel = new BufferedLogChannel(channel,
                    conf.getWriteBufferBytes(), conf.getReadBufferBytes(), preallocatedLogId);
            logChannel.write((ByteBuffer) LOGFILE_HEADER.clear());

            for (File f : list) {
                setLastLogId(f, preallocatedLogId);
            }
            LOG.info(""Preallocated entry logger {}."", preallocatedLogId);
            return logChannel;
        }
{code}
",2014-12-08 04:43:26,2015-05-20 06:20:45
BOOKKEEPER-822,Make LedgerMetadata Immutable,Bug,1,Open,1,,,2014-12-09 20:31:21,2017-10-17T21:28:54.000+0000,ikelly,Ivan Kelly,ikelly,"Mutable metadata has been a very rich source of bugs. There are multiple processing modifying for rebuilding ensembles, closing, fencing, autorecovery etc.

The local metadata should be a mirror of the metadata in zookeeper. So we should only modify the local metadata as a whole. The first part of this is making it immutable, so that it can only be modified with a builder.",2014-12-09 20:31:21,
BOOKKEEPER-823,Clean up temp files created by hedwig tests,Bug,1,Closed,6,Fixed,2015-07-07 06:25:30,2014-12-10 18:48:13,2016-05-16T21:47:40.000+0000,zhaijia,Jia Zhai,zhaijia,BOOKKEEPER-814 cleaned up temp files from the bookkeeper tests. This jira is to do the same for hedwig tests (it creates a couple of zookeeper directories).,2014-12-10 18:48:13,2015-07-07 06:25:30
BOOKKEEPER-824,Cookie should include index directory,Bug,1,Open,1,,,2014-12-11 23:39:50,2017-10-17T21:28:51.000+0000,ankurgarg9,Ankur Garg,ankurgarg9,"after introduced index directory, the cookie isn't upgraded to include the index directories, which potentially break data integrity  ",2014-12-11 23:39:50,
BOOKKEEPER-825,Need a tool to upgrade bookie cluster that has empty instance id,Bug,1,Open,1,,,2014-12-12 00:11:27,2017-10-17T21:28:48.000+0000,cxie,Charles X,cxie,"after introducing instance id, bookkeeper doesn't provide a tool to upgrade existing clusters to have a valid instance id.

the tool is useful, when you operate multiple bookkeeper clusters and want to move bookies around, you could use 'instanceid' to prevent any bad admin operation. without instanceid, it provides a back hole to break data integrity.",2014-12-12 00:11:27,
BOOKKEEPER-826,PendingAddOp is ignoring ack response after meet ack quorum constraint ,Improvement,4,Resolved,5,Fixed,2015-10-06 09:13:08,2014-12-12 00:26:08,2015-10-06T09:51:18.000+0000,hustlmsp,Sijie Guo,hustlmsp,"PendingAddOp is set to completed when it meets ack quorum.
{code}
        if (ackSet.addBookieAndCheck(bookieIndex) && !completed) {
            completed = true;

            LOG.debug(""Complete (lid:{}, eid:{})."", ledgerId, entryId);
            // when completed an entry, try to send success add callbacks in order
            lh.sendAddSuccessCallbacks();
        }
{code}

responses are ignored after completed flag is set.
{code}
       if (completed) {
            // I am already finished, ignore incoming responses.
            // otherwise, we might hit the following error handling logic, which might cause bad things.
            return;
        }
{code}

It is not a correctness problem, but it would introduce performance issue during ensemble change. A callback (could be acknowledge before ensemble change) has to be delayed to ensemble change completion.",2014-12-12 00:26:08,2015-10-06 09:13:08
BOOKKEEPER-827,"change throttle in GarbageCollector to use either ""by entry"" or ""by byte""",Improvement,4,Closed,6,Fixed,2015-01-16 15:02:38,2014-12-13 07:39:51,2016-05-16T21:47:45.000+0000,zhaijia,Jia Zhai,zhaijia,"Current bookie compaction in GarbageCollector has setting: 'compactionRate'. It is throttling and limiting the compaction by entries. 
But from a bandwidth perspective, it would be good that we could throttle and limit compaction by bytes, which would really reflect the bandwidth of disk. 

So in this enhancement, we added another ""by bytes"" option when doing compaction in GarbageCollector:
""boolean isThrottleByBytes"": true when use by bytes, false when use by entries;
""int compactionRateByEntries"": by entries, number of concurrent entries;
""int compactionRateByBytes"": by bytes, number of bytes of entries before flush.",2014-12-13 07:39:51,2015-01-16 15:02:38
BOOKKEEPER-828,Script for updating docs on website from master branch,Bug,1,Closed,6,Fixed,2015-03-18 06:22:54,2014-12-16 18:58:30,2016-05-16T21:47:35.000+0000,ikelly,Ivan Kelly,ikelly,"Pre TLP, whenever we updated the docs/ directory of trunk, the website docs for trunk would be ""automatically"" updated. Updates to the docs still needed to be built with the old build_trigger mechanism, and the site published through CMS.

The docs were pulled in using a svn:external link. This is no longer possible, as _master_'s docs/ directory is in git. 

We need a new way to sync master docs on the website with what is in git.",2014-12-16 18:58:30,2015-03-18 06:22:54
BOOKKEEPER-829,Make important documentation available from front page,Bug,1,Resolved,5,Fixed,2015-08-23 15:26:04,2014-12-17 15:56:40,2015-08-23T15:26:05.000+0000,ikelly,Ivan Kelly,ikelly,"We should make important stuff, like the api docs and basic client and admin guides available from the front page.

It really annoys me when I'm using a project and i have to dig deep to get to the api docs in particular.",2014-12-17 15:56:40,2015-08-23 15:26:04
BOOKKEEPER-830,Documentation has no structure,Improvement,4,Closed,6,Fixed,2015-01-19 21:03:44,2014-12-17 16:00:49,2016-05-16T21:47:52.000+0000,ikelly,Ivan Kelly,ikelly,"The current documentation landing page is just a list of links. There's no hint as to who each doc is targetted at, and what each document contains.",2014-12-17 16:00:49,2015-01-19 21:03:44
BOOKKEEPER-831,Outdated links in tutorial,Bug,1,Closed,6,Fixed,2015-03-12 07:57:25,2014-12-17 16:06:17,2016-05-16T21:47:31.000+0000,ikelly,Ivan Kelly,ikelly,There are some links still pointing to zookeeper.apache.org/bookkeeper. ,2014-12-17 16:06:17,2015-03-12 07:57:25
BOOKKEEPER-832, Allow starting bookie in ReadOnly mode,Improvement,4,Closed,6,Fixed,2015-01-12 14:20:46,2014-12-22 16:16:12,2016-05-16T21:47:26.000+0000,zhaijia,Jia Zhai,zhaijia, Allow starting bookie in ReadOnly mode,2014-12-22 16:16:12,2015-01-12 14:20:46
BOOKKEEPER-833,EntryLogId and EntryLogLimit should not be larger than Integer.MAX_VALUE,Bug,1,Closed,6,Fixed,2015-04-21 08:08:53,2014-12-23 01:21:35,2016-05-16T21:47:37.000+0000,hustlmsp,Sijie Guo,hustlmsp,"currently the index entry position is combined with log id and entry offset inside a log. so it means that log id and entry log file size shouldn't be larger than Integer.MAX_VALUE. otherwise, it would cause trouble.",2014-12-23 01:21:35,2015-04-21 08:08:53
BOOKKEEPER-834,test case error in test class TestDiskChecker,Bug,1,Closed,6,Fixed,2015-03-18 06:37:15,2015-01-13 05:10:05,2016-05-16T21:47:24.000+0000,zhaijia,Jia Zhai,zhaijia,"In test class TestDiskChecker, test case will fail if tmp dir's usableSpace / totalSpace > 0.95, because threshold will be a negative number.
{code}
     public void testCheckDiskFull() throws IOException {
        File file = File.createTempFile(""DiskCheck"", ""test"");
        long usableSpace = file.getUsableSpace();
        long totalSpace = file.getTotalSpace();
        float threshold =
                (1f - ((float) usableSpace / (float) totalSpace)) - 0.05f;        
 < === if ""usableSpace / totalSpace"" is 0.99, then threshold is -0.04, this is invalid.
        diskChecker.setDiskSpaceThreshold(threshold, threshold);
        diskChecker.checkDiskFull(file);
    }
{code}

in my running of test:
  1 -------------------------------------------------------------------------------
  2 Test set: org.apache.bookkeeper.util.TestDiskChecker
  3 -------------------------------------------------------------------------------
  4 Tests run: 4, Failures: 0, Errors: 2, Skipped: 0, Time elapsed: 0.557 sec <<< FAILURE!
  5 testCheckDiskFull(org.apache.bookkeeper.util.TestDiskChecker)  Time elapsed: 0.066 sec  <<< ERROR!
  6 java.lang.Exception: Unexpected exception, expected<org.apache.bookkeeper.util.DiskChecker$DiskOutOfSpaceException> but was<java.lang.IllegalArgumentException>
  7     at org.junit.internal.runners.statements.ExpectException.evaluate(ExpectException.java:28)
  8     at org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:28)
  9     at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:76)
 10     at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)
 11     at org.junit.runners.ParentRunner$3.run(ParentRunner.java:193)
 12     at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:52)
 13     at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:191)
 14     at org.junit.runners.ParentRunner.access$000(ParentRunner.java:42)
 15     at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:184)
 16     at org.junit.runners.ParentRunner.run(ParentRunner.java:236)
 17     at org.apache.maven.surefire.junit4.JUnit4TestSet.execute(JUnit4TestSet.java:53)
 18     at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:123)
 19     at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:104)
 20     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 21     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
 22     at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 23     at java.lang.reflect.Method.invoke(Method.java:606)
 24     at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:164)
 25     at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:110)
 26     at org.apache.maven.surefire.booter.SurefireStarter.invokeProvider(SurefireStarter.java:172)
 27     at org.apache.maven.surefire.booter.SurefireStarter.runSuitesInProcessWhenForked(SurefireStarter.java:78)
 28     at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:70)
 29 Caused by: java.lang.IllegalArgumentException: Disk space threashold -0.04741608 is not valid. Should be > 0 and < 1              < ======
 30     at org.apache.bookkeeper.util.DiskChecker.validateThreshold(DiskChecker.java:163)
 31     at org.apache.bookkeeper.util.DiskChecker.setDiskSpaceThreshold(DiskChecker.java:157)
 32     at org.apache.bookkeeper.util.TestDiskChecker.testCheckDiskFull(TestDiskChecker.java:51)
 33     at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
 34     at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
 35     at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
 36     at java.lang.reflect.Method.invoke(Method.java:606)
 37     at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
 38     at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
 39     at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
 40     at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
 41     at org.junit.internal.runners.statements.ExpectException.evaluate(ExpectException.java:21)
 42     ... 21 more

print out vars in test to verify these values: 
2015-01-13 12:42:58,448 - INFO  - [main:TestDiskCheckerTest@78] - usableSpace:2062532608, totalSpace:2073448448, threshold: -0.04473542",2015-01-13 05:10:05,2015-03-18 06:37:15
BOOKKEEPER-835,Update copyright for 2015 on all active branches,Bug,1,Closed,6,Fixed,2015-05-19 07:38:59,2015-01-16 17:26:54,2016-05-16T21:47:42.000+0000,hustlmsp,Sijie Guo,hustlmsp,"As the title says, update the copyright in the notice files to add 2015. I don't think we need to do 4.2 branch as I doubt there'll be more releases on it.",2015-01-16 17:26:54,2015-05-19 07:38:59
BOOKKEEPER-836,"disable compaction when disk becomes full, otherwise compaction will fill up disk quickly",Improvement,4,Closed,6,Fixed,2015-04-21 07:55:43,2015-01-22 00:05:22,2016-05-16T21:47:23.000+0000,zhaijia,Jia Zhai,zhaijia,"In doCompactEntryLogs, Entries are added to new logs, while all old logs were not released until the end of handling.  So during the process, a lot of space will be used. Need to disable compaction when disk becomes full, otherwise compaction will fill up disk quickly.

I would like to change old ""forced garbage collection"" logic, and suspend major compaction when it reaches warn threshold, suspend minor compaction when it reaches critical threshold.",2015-01-22 00:05:22,2015-04-21 07:55:43
BOOKKEEPER-837,UpdateLedgerOp - Replace AbstractFuture with SettableFuture,Sub-task,7,Closed,6,Fixed,2015-03-12 07:37:52,2015-02-06 15:16:20,2016-05-16T21:47:41.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"+Review comment :+ Using AbstractFuture is too tight with guava's internal implementation. Instead it would be good to use a variable for the settable future.

{code}
 class Read... implements GenericCallback {

 SettableFuture future = ...;
  public void operationComplete(..) {
    future.set(null); 
    // future.setException(..)
  }
}
{code}",2015-02-06 15:16:20,2015-03-12 07:37:52
BOOKKEEPER-838,ForceWriteThread::run() leaks logFile.close() when interrupt comes,Bug,1,Closed,6,Fixed,2015-02-23 07:21:27,2015-02-21 05:21:24,2016-05-16T21:47:45.000+0000,zhaijia,Jia Zhai,zhaijia,"According to Ivans email, I did a check of the build history. Seems recently failing is with this stack:
java.io.IOException: Unable to delete directory /tmp/bkTest3561939033223584760.dir/current/0.
	at org.apache.commons.io.FileUtils.deleteDirectory(FileUtils.java:1337)
	at org.apache.commons.io.FileUtils.forceDelete(FileUtils.java:1910)
	at org.apache.commons.io.FileUtils.cleanDirectory(FileUtils.java:1399)
	at org.apache.commons.io.FileUtils.deleteDirectory(FileUtils.java:1331)
	at org.apache.commons.io.FileUtils.forceDelete(FileUtils.java:1910)
	at org.apache.commons.io.FileUtils.cleanDirectory(FileUtils.java:1399)
	at org.apache.commons.io.FileUtils.deleteDirectory(FileUtils.java:1331)
	at org.apache.bookkeeper.test.BookKeeperClusterTestCase.cleanupTempDirs(BookKeeperClusterTestCase.java:186)
	at org.apache.bookkeeper.test.BookKeeperClusterTestCase.tearDown(BookKeeperClusterTestCase.java:114)

This may be caused by an error in ForceWriteThread::run(), which leaked logFile.close() when interrupt comes.

{code}
private class ForceWriteThread {
     public void run() {
            LOG.info(""ForceWrite Thread started"");
            boolean shouldForceWrite = true;
            int numReqInLastForceWrite = 0;
            while(running) {
                ForceWriteRequest req = null;
                try {
                           
                } catch (IOException ioe) {
                    LOG.error(""I/O exception in ForceWrite thread"", ioe);
                    running = false;
                } catch (InterruptedException e) {
                    LOG.error(""ForceWrite thread interrupted"", e);
                    if (null != req) {
                        req.closeFileIfNecessary();        < ==== 2, when interrupt, shouldClose not set properly, so file not close
                    }
                    running = false;
                }
            }
            // Regardless of what caused us to exit, we should notify the
            // the parent thread as it should either exit or be in the process
            // of exiting else we will have write requests hang
            threadToNotifyOnEx.interrupt();
        }
        // shutdown sync thread
        void shutdown() throws InterruptedException {
            running = false;
            this.interrupt();               < ====  1, call interrupt
            this.join();
        }
}

        public void closeFileIfNecessary() {
            // Close if shouldClose is set
            if (shouldClose) {         < ==== 3, shouldClose is false here.
                // We should guard against exceptions so its
                // safe to call in catch blocks
                try {
                    logFile.close();
                    // Call close only once
                    shouldClose = false;
                }
                catch (IOException ioe) {
                    LOG.error(""I/O exception while closing file"", ioe);
                }
            }
        }
{code}",2015-02-21 05:21:24,2015-02-23 07:21:27
BOOKKEEPER-839,AuditorPeriodicCheckTest timeout,Bug,1,Closed,6,Fixed,2015-03-12 07:26:05,2015-02-24 17:07:41,2016-05-16T21:47:43.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,This is failing consistently for me. I'm using a ubuntu vm with Oracle jdk 8. Attaching a log file that I got from running it on the master branch.,2015-02-24 17:07:41,2015-03-12 07:26:05
BOOKKEEPER-840,Deadlock on flushLock on compaction,Bug,1,Closed,6,Fixed,2015-03-18 05:41:04,2015-03-09 23:40:13,2016-05-16T21:47:37.000+0000,hustlmsp,Sijie Guo,hustlmsp,"the dead lock happens on entry log rolling and compaction.

    entry log rolling will lock entry logger then lock flushLock.
    compaction waiting for flush, will lock flushLock and then entry logger.",2015-03-09 23:40:13,2015-03-18 05:41:04
BOOKKEEPER-841,Bookie should calculate ledgers map writing a new entry log file,Improvement,4,Closed,6,Fixed,2016-02-23 23:45:33,2015-03-09 23:41:58,2016-05-16T21:47:25.000+0000,mmerli,Matteo Merli,mmerli,"Bookie should calculate ledgers map when writing a new entry log file. so the bookie doesn't need to scan that entry log file again, which it would improve garbage collection efficiency ",2015-03-09 23:41:58,2016-02-23 23:45:33
BOOKKEEPER-842,Tests related to changing bookie id would fail if DNS resolution can't return hostname,Improvement,4,Open,1,,,2015-03-10 02:05:28,2017-10-17T21:28:45.000+0000,,,,"failed tests: UpdateCookieCmdTest, UpdateLedgerOpTest, CookieTest.

Some are easier to get around. but some aren't. in general, we shouldn't tight changing bookie id to be just hostname and ip, we should be allowed to configure what bookie id to be used.",2015-03-10 02:05:28,
BOOKKEEPER-843,GcLedgersTest creates too many ledgers in #testGcLedgersNotLast,Bug,1,Resolved,5,Won't Do,2017-06-22 00:35:04,2015-03-10 02:08:23,2017-06-22T00:35:04.000+0000,hustlmsp,Sijie Guo,hustlmsp,There should be other way to create ledgers that would span over 4 ranges in hierarchical ledger manager.,2015-03-10 02:08:23,2017-06-22 00:35:04
BOOKKEEPER-844,Add more metrics about latency and bytes characteristics on bookie operations ,Improvement,4,Closed,6,Fixed,2015-03-18 06:46:09,2015-03-12 09:03:06,2016-05-16T21:47:26.000+0000,tongyu,Tong Yu,tongyu,it would be good to have detail metrics about latency and bytes on bookie operations. it would help on investigating performance issues.,2015-03-12 09:03:06,2015-03-18 06:46:09
BOOKKEEPER-845,"test case fail with error ""Unable to delete directory /tmp/bkTest.dir/current/0""",Bug,1,Resolved,5,Implemented,2015-06-01 04:55:16,2015-03-17 08:17:07,2015-06-01T04:55:16.000+0000,zhaijia,Jia Zhai,zhaijia,"Recently, test case org.apache.bookkeeper.bookie.CompactionTest.testCompactionSafety would fail in ""Hadoop QA""'s comments for target patch. 
It happened at least in BOOKKEEPER-834 and BOOKKEEPER-839.

The failure is like this:
java.io.IOException: Unable to delete directory /tmp/bkTest1550867777962713274.dir/current/0.
at org.apache.commons.io.FileUtils.deleteDirectory(FileUtils.java:1337)
at org.apache.commons.io.FileUtils.forceDelete(FileUtils.java:1910)
at org.apache.commons.io.FileUtils.cleanDirectory(FileUtils.java:1399)
at org.apache.commons.io.FileUtils.deleteDirectory(FileUtils.java:1331)
at org.apache.commons.io.FileUtils.forceDelete(FileUtils.java:1910)
at org.apache.commons.io.FileUtils.cleanDirectory(FileUtils.java:1399)
at org.apache.commons.io.FileUtils.deleteDirectory(FileUtils.java:1331)
at org.apache.bookkeeper.test.BookKeeperClusterTestCase.cleanupTempDirs(BookKeeperClusterTestCase.java:186)
at org.apache.bookkeeper.test.BookKeeperClusterTestCase.tearDown(BookKeeperClusterTestCase.java:114)
2015-03-15 00:48:08,671 - WARN - [BookieJournal-15017:Journal@927] - Journal exits when shutting down
java.lang.InterruptedException
at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2017)
at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2052)
at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
at org.apache.bookkeeper.bookie.Journal.run(Journal.java:822)
2015-03-15 00:48:08,671 - INFO - [BookieJournal-15017:Journal@936] - Journal exited loop!

It seems bookie.Journal.run() not release file when interrupt comes, which is similar to
BOOKKEEPER-838 .
I would like to investigate more on this issue.",2015-03-17 08:17:07,2015-06-01 04:55:16
BOOKKEEPER-846,TestLedgerChecker times out,Test,6,Closed,6,Fixed,2015-04-21 08:20:24,2015-03-20 21:53:37,2016-05-16T21:47:32.000+0000,rakeshr,Rakesh Radhakrishnan,rakeshr,"{noformat}
java.lang.Exception: test timed out after 3000 milliseconds
        at java.lang.Object.wait(Native Method)
        at java.lang.Object.wait(Object.java:502)
        at org.apache.bookkeeper.client.SyncCounter.block(SyncCounter.java:51)
        at org.apache.bookkeeper.client.LedgerHandle.addEntry(LedgerHandle.java:480)
        at org.apache.bookkeeper.client.LedgerHandle.addEntry(LedgerHandle.java:457)
        at org.apache.bookkeeper.client.TestLedgerChecker.testShouldGetTwoFrgamentsIfTwoBookiesFailedInSameEnsemble(TestLedgerChecker.java:185)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:497)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
        at org.junit.internal.runners.statements.FailOnTimeout$1.run(FailOnTimeout.java:28)
{noformat}",2015-03-20 21:53:37,2015-04-21 08:20:24
BOOKKEEPER-847,ArrayIndexOutOfBoundsException in LedgerFragmentReplicator::updateEnsembleInfo,Bug,1,Resolved,5,Fixed,2015-04-21 07:36:25,2015-03-28 15:36:13,2015-04-21T08:33:38.000+0000,zhaijia,Jia Zhai,zhaijia,"ArrayIndexOutOfBoundsException in LedgerFragmentReplicator::updateEnsembleInfo, because update ensemble info might happen after re-read ledger metadata, so the ensemble might already change. if ensemble is already changed, skip replacing the bookie doesn't exist.",2015-03-28 15:36:13,2015-04-21 07:36:25
BOOKKEEPER-848,Use volatile for lastAddConfirmed,Bug,1,Closed,6,Fixed,2015-04-21 07:39:57,2015-04-10 21:12:23,2016-05-16T21:47:27.000+0000,mmerli,Matteo Merli,mmerli,"LastAddConfirmed in LedgerHandle is updated when an entry is persisted successfully. 

When sending a new entry, the most recent lastAddConfirmed is sent along. The reason is to start with a reasonable (confirmed) entryId when doing ledger recovery, by reading all entries from lastAddConfirmed until a NoEntryException is reached. 

If lastAddConfirmed updates are not visible to the thread that is writing new entries, new entries will carrie an older lastAddConfirmed value, and recovering the ledger will requiring reading one-by-one many entries.
When writing several thousand of entries per sec, the lastAddConfirmed can lag behind a lot from the real last entry.

We should use volatile, to ensure writing thread sees the updated version.",2015-04-10 21:12:23,2015-04-21 07:39:57
BOOKKEEPER-849,Collect stats with sub-milliseconds precision,Improvement,4,Closed,6,Fixed,2015-04-21 07:18:31,2015-04-10 21:17:15,2016-05-16T21:47:36.000+0000,mmerli,Matteo Merli,mmerli,"Most operations in Bookie are taking <1ms. Stats should be collected in nanos , expecially since latencies are already measured in nanos.",2015-04-10 21:17:15,2015-04-21 07:18:31
BOOKKEEPER-850,Use nanoseconds to calculate poll timeout when doing group commit,Improvement,4,Closed,6,Fixed,2015-04-21 07:24:54,2015-04-10 21:41:41,2016-05-16T21:47:27.000+0000,mmerli,Matteo Merli,mmerli,"When using group commit to reduce the number of fsync operations in the bookie journal, the timeout is rounded to the next millisecond. 

If the group commit is set to 1ms, that would mean that the effective wait time will be closer to 2ms.",2015-04-10 21:41:41,2015-04-21 07:24:54
BOOKKEEPER-851,Configurable LedgerStorageImplementation,Improvement,4,Closed,6,Fixed,2016-03-08 05:50:33,2015-04-10 21:51:12,2016-05-16T21:47:25.000+0000,mmerli,Matteo Merli,mmerli,Allow to configure a different implementation for the LedgerStorage interface in the Bookie configuration.,2015-04-10 21:51:12,2016-03-08 05:50:33
BOOKKEEPER-852,Release LedgerDescriptor and master-key objects when not used anymore,Bug,1,Resolved,5,Fixed,2017-03-28 20:37:27,2015-04-10 23:50:18,2017-03-29T14:17:25.000+0000,mmerli,Matteo Merli,mmerli,Maps with ledger descriptors and master-keys are not cleaned after a ledger gets deleted.,2015-04-10 23:50:18,2017-03-28 20:37:27
BOOKKEEPER-853,Use integer for entry log id,Bug,1,Open,1,,,2015-04-21 07:58:03,2017-10-17T21:28:42.000+0000,,,,"As the format of position (including log id and position) limitation, it'd better to use integer for entry log id rather than long.",2015-04-21 07:58:03,
BOOKKEEPER-854,NPE on InterleavedLedgerStorage.onRotateEntryLog,Bug,1,Closed,6,Fixed,2015-05-20 04:23:36,2015-05-19 08:18:32,2016-05-16T21:47:53.000+0000,hustlmsp,Sijie Guo,hustlmsp,"{code}
testLedgerCacheFlushFailureOnDiskFull(org.apache.bookkeeper.bookie.LedgerCacheTest)  Time elapsed: 0.032 sec  <<< ERROR!
java.lang.NullPointerException
        at org.apache.bookkeeper.bookie.InterleavedLedgerStorage.onRotateEntryLog(InterleavedLedgerStorage.java:350)
        at org.apache.bookkeeper.bookie.SortedLedgerStorage.onRotateEntryLog(SortedLedgerStorage.java:38)
        at org.apache.bookkeeper.bookie.EntryLogger.createNewLog(EntryLogger.java:381)
        at org.apache.bookkeeper.bookie.EntryLogger.addEntry(EntryLogger.java:637)
        at org.apache.bookkeeper.bookie.InterleavedLedgerStorage.processEntry(InterleavedLedgerStorage.java:334)
        at org.apache.bookkeeper.bookie.SortedLedgerStorage.process(SortedLedgerStorage.java:149)
        at org.apache.bookkeeper.bookie.EntryMemTable.flushSnapshot(EntryMemTable.java:236)
        at org.apache.bookkeeper.bookie.EntryMemTable.flush(EntryMemTable.java:214)
        at org.apache.bookkeeper.bookie.SortedLedgerStorage.flush(SortedLedgerStorage.java:154)
        at org.apache.bookkeeper.bookie.LedgerCacheTest.testLedgerCacheFlushFailureOnDiskFull(LedgerCacheTest.java:291)
        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
        at java.lang.reflect.Method.invoke(Method.java:601)
        at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:44)
        at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:15)
        at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:41)
        at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:20)
        at org.junit.internal.runners.statements.FailOnTimeout$1.run(FailOnTimeout.java:28)
{code}",2015-05-19 08:18:32,2015-05-20 04:23:36
BOOKKEEPER-855,handle session expire event in bookie,Sub-task,7,Closed,6,Fixed,2016-01-26 21:13:44,2015-05-24 05:25:21,2016-05-16T21:47:23.000+0000,hustlmsp,Sijie Guo,hustlmsp,handling zookeeper session expire event in bookie server & bookie watcher.,2015-05-24 05:25:21,2016-01-26 21:13:44
BOOKKEEPER-856,Fix default value of logSizeLimit,Bug,1,Open,1,,,2015-05-24 14:15:22,2017-10-17T21:28:39.000+0000,fpj,Flavio Paiva Junqueira,fpj,"When I run ./bookkeeper bookie, I get an error complaining about the value of the variable:

{norformat}
2015-05-24 14:14:01,196 - ERROR - [main:BookieServer@289] - Malformed configuration file: /home/fpj/code/bookkeeper-4.3.1/bookkeeper-server/conf/bk_server.conf
org.apache.commons.configuration.ConfigurationException: Entry log file size should not be larger than 1073741824
{noformat}

The parameter is commented out by default, so the fix is to bring it back in and set an appropriate value.",2015-05-24 14:15:22,
BOOKKEEPER-858,Fix broken links and typos in bookkeeper documents,Bug,1,Closed,6,Fixed,2015-06-02 06:03:08,2015-05-30 09:42:08,2016-05-16T21:47:45.000+0000,y0un5,Youngjoon Kim,y0un5,There are some broken links and trivial typos in bookkeeper documents.,2015-05-30 09:42:08,2015-06-02 06:03:08
BOOKKEEPER-859,Please delete old releases from mirroring system,Bug,1,Resolved,5,Fixed,2016-05-16 21:02:57,2015-06-21 13:34:44,2016-05-16T21:32:22.000+0000,mmerli,Matteo Merli,mmerli,"To reduce the load on the ASF mirrors, projects are required to delete old releases [1]

Please can you remove all non-current releases?
i.e. 4.2.4, 4.3.0
Thanks!

[1] http://www.apache.org/dev/release.html#when-to-archive",2015-06-21 13:34:44,2016-05-16 21:02:57
BOOKKEEPER-860,Enhance client API,Improvement,4,Open,1,,,2015-07-27 16:57:08,2017-10-17T21:28:36.000+0000,jujjuri,JV Jujjuri,jujjuri,"Today's BK client API generates entryId and LedgerHandle for the caller.
While this is very convenient and makes the life of caller very simple and easy,
this model may not be very suitable where application would like to have 
better control.

In order to facilitate applications/users of BK aspiring to have more control
following enhancements are proposed for BK client API:
 
- API enhancement to accept entryID:
Enhance BK client API to pass entryId as an input and the caller must guarantee the following:
    * entryIds are never duplicated
    * entryIds are sequential starting from 0.
    * entryIds have no holes.

- API enhancement to accept LedgerHandle
Applications are allowed to pass-in ledgerId  provided:
  * ledgerId is unique within the cluster. 
  * Or even better, if using GUID (128 bit) virtually guarantees universal
     uniqueness.  
   * Need to bypass current ledgerId generation logic. 

- Allow multiple entities (threads/processes) write to the ledger as long as
   there is only one writer at the given instance of time.

- Currently ledgerHandle interface accepts byteArray as input, but sockets 
  use byteBuffer. We will add additional functions to the new classes to 
  accept both byteBuffers and byteArrays.

- Sijie suggested to create a new classes that extents existing classes to accept LedgerId and entryId as inputs.This avoids any confusion with existing interfaces, and makes it explicit.",2015-07-27 16:57:08,
BOOKKEEPER-862,Add tracing and stats to OrderedSafeExecutor for debugging slow tasks,Improvement,4,Closed,6,Fixed,2015-10-06 08:08:05,2015-08-02 21:35:18,2016-05-16T21:47:32.000+0000,l4stewar,Leigh Stewart,l4stewar,"Porting a change form the Twitter branch to improve stats and logging in OrderedSafeExecutor
These changes have been helpful for us in debugging latency issues in Bookkeeper server/client 
Summary of changes is
* add a config option for op stats
* add stats for task execution time, task pending time
* add a config option for logging a warning when an op takes longer than x micros
* add toString implementations for submitted tasks so make it easier to track down slow ops
* start using Builder for OrderedSafeExecutor
* add a very simple test to make sure that the slow op logging path is exercised

Most of this came from Sijie originally, with some changes from me
 ",2015-08-02 21:35:18,2015-10-06 08:08:05
BOOKKEEPER-863,Potential resource leak with unclosed LedgerManager in BookieShell,Bug,1,Closed,6,Fixed,2015-08-12 02:01:49,2015-08-06 17:05:04,2016-05-16T21:47:32.000+0000,yuzhihong@gmail.com,Ted Yu,yuzhihong@gmail.com,"There're more than one occurrence.
Here is an example in ListLedgersCmd#runCmd():
{code}
                LedgerManagerFactory mFactory = LedgerManagerFactory.newLedgerManagerFactory(bkConf, zk);
                LedgerManager m = mFactory.newLedgerManager();
{code}
m is not closed upon leaving the method.",2015-08-06 17:05:04,2015-08-12 02:01:49
BOOKKEEPER-864,128 bit LedgerId,Improvement,4,Open,1,,,2015-08-18 19:54:47,2017-10-17T21:28:32.000+0000,,,,"BookKeeper coordinates with ZooKeeper to generate an cluster wide LedgerId. This is a 64 bit number. This method works great because we have ZK acting as a centralized coordinator.  But this method may not scale as the cluster size and number of ledgers increase. 

GUIDs ( (https://en.wikipedia.org/wiki/Globally_unique_identifier) are preferred way to generate decentralized globally unique IDs and it takes 128 bits ; This method can scale well as it doesnt need a centralized coordination. 
Current BK code used ledgerId as a primary object, any change to this (64 to128 bit) warrants across the board code changes. 

Opening this issue so we can solicit community input and track the progress.
",2015-08-18 19:54:47,
BOOKKEEPER-865,provide a simple way to compress the content in each Entry of EntryLogger,Improvement,4,Open,1,,,2015-08-31 02:01:57,2017-10-17T21:28:28.000+0000,zhaijia,Jia Zhai,zhaijia,"This issue is an enhancement, it tries to provide a simple way to compress the content in each Entry of EntryLogger. 
By this enhancement, it will save a lot of disk space for the logs, under the condition that contents is large in Entry.",2015-08-31 02:01:57,
BOOKKEEPER-866,Fix compile issue when Updating junit to latest release version( 4.12) in the test of  Bookkeeper-server.,Improvement,4,Closed,6,Fixed,2015-10-16 05:01:34,2015-08-31 12:51:55,2016-05-16T21:47:38.000+0000,zhaijia,Jia Zhai,zhaijia,"When write test cases for BOOKKEEPER-865,  It appears that current version of junit could not support some new features well, such as Parameterized test. Then we try to update junit to latest release version, but found "" junit.framework.Assert in junit.framework has been deprecated"" .  
So using this new ticket to trace this to make the objective more clear.

The fix is simple, 
replace 
import junit.framework.Assert;
to
import org.junit.Assert; 
",2015-08-31 12:51:55,2015-10-16 05:01:34
BOOKKEEPER-867,New Client API to allow applications pass-in EntryId.,Sub-task,7,Closed,6,Fixed,2015-10-22 07:24:43,2015-09-01 18:02:23,2016-05-16T21:47:45.000+0000,jujjuri,JV Jujjuri,jujjuri,,2015-09-01 18:02:23,2015-10-22 07:24:43
BOOKKEEPER-868,Add ADD_ENTRY quorum timeout,Task,3,Closed,6,Fixed,2015-10-06 08:49:13,2015-09-08 16:01:41,2016-05-16T21:47:50.000+0000,l4stewar,Leigh Stewart,l4stewar,"Sometimes bugs in the write path or persistent network issues can cause ADD_ENTRY to be delayed for a long time

Rather than allow this to block indefinitely specify a config param for the write quorum timeout",2015-09-08 16:01:41,2015-10-06 08:49:13
BOOKKEEPER-869,Add documentation on how to tune performance on bookies,Documentation,20,Open,1,,,2015-09-15 01:36:41,2017-10-17T21:28:24.000+0000,,,,"like how to choose number of threads, how to tune journal or memory.",2015-09-15 01:36:41,
BOOKKEEPER-870,Change the default value for bookie settings.,Documentation,20,Closed,6,Fixed,2016-04-13 23:11:54,2015-09-15 01:37:18,2016-05-16T21:47:25.000+0000,hustlmsp,Sijie Guo,hustlmsp,It would be good to tune the default settings for bookies.,2015-09-15 01:37:18,2016-04-13 23:11:54
BOOKKEEPER-872,Resource leak with unclosed LedgerManager in HierarchicalLedgerManagerFactory#format(),Bug,1,Resolved,5,Fixed,2015-10-10 16:38:55,2015-09-21 17:17:26,2015-10-10T17:20:58.000+0000,yuzhihong@gmail.com,Ted Yu,yuzhihong@gmail.com,"{code}
    public void format(AbstractConfiguration conf, ZooKeeper zk)
            throws InterruptedException, KeeperException, IOException {
        HierarchicalLedgerManager ledgerManager = (HierarchicalLedgerManager) newLedgerManager();
{code}
ledgerManager is not closed upon exit from the method.",2015-09-21 17:17:26,2015-10-10 16:38:55
BOOKKEEPER-873,Enhance CreatedLedger API to accept ledgerId as input,Sub-task,7,Resolved,5,Fixed,2017-01-31 01:42:12,2015-09-22 18:09:35,2017-02-08T21:49:30.000+0000,jujjuri,JV Jujjuri,jujjuri,,2015-09-22 18:09:35,2017-01-31 01:42:12
BOOKKEEPER-874,Explict LAC from Writer to Bookies,Improvement,4,Resolved,5,Fixed,2017-01-31 03:02:08,2015-09-22 18:12:55,2017-03-28T14:22:56.000+0000,jujjuri,JV Jujjuri,jujjuri,"Current client API piggy-backs LAC with a write. This is keeps reader one behind the writer. In order to keep reader up to date with writer even when there is a pause in write, proposing the following:

Writer sends explicit LAC on a configured timeout if there is no write within that period.",2015-09-22 18:12:55,2017-01-31 03:02:08
BOOKKEEPER-875,Provide a configuration option to set a fixed BookieID,Improvement,4,Open,1,,,2015-09-23 06:51:41,2017-10-17T21:28:21.000+0000,,,,"In Bookkeeper 4.3.x there are two ways of configuring the BookieID, that is using an IP address or using the hostname (useHostNameAsBookieID). There is also an option to force the use of a specific network interface.

In environments with many IP addresses both of the two options can lead to an undeterministic behaviour.

Another useful option would be to set explicitly a ""BookieID"".
I have to usecases:
- network configuration of the machine changes, but I want to preserve bookie data without recovery
- bookie data is to be moved to another machine (that is somehow similar the the first case)",2015-09-23 06:51:41,
BOOKKEEPER-877,Script for generating patch for reviews,Improvement,4,Closed,6,Fixed,2016-01-22 05:21:09,2015-11-04 09:38:30,2016-05-16T21:47:35.000+0000,hustlmsp,Sijie Guo,hustlmsp,It would be good to have a script to generate patch for reviews.,2015-11-04 09:38:30,2016-01-22 05:21:09
BOOKKEEPER-878,verify switching FlatLedgerManager to HierarchicalLedgerManager,Task,3,In Progress,3,,,2015-11-05 18:55:19,2017-10-17T21:28:19.000+0000,hustlmsp,Sijie Guo,hustlmsp,"after BOOKKEEPER-438 is in, it is possible to switch FlatLedgerManager to HierarchicalLedgerManager. 

- we need to verify whether it works
- add test cases to cover these steps
- documentation about the steps

if this is verified, port BOOKKEEPER-438 back to 4.3.* branch to make it available.",2015-11-05 18:55:19,
BOOKKEEPER-879,Record ledger creation time,New Feature,2,Closed,6,Fixed,2016-02-23 18:17:16,2015-11-09 11:32:41,2016-05-16T21:47:30.000+0000,eolivelli,Enrico Olivelli,eolivelli,"I think that a creation timestamp would be very useful and it does not cost very much. It would be an immutable value. 
Nowadays (on 4.3.1) I must keep that info together with the id of the ledger,  for instance in zookeeper,  but if that reference gets lost there is now way to know how old a ledger is.

I think that this timestamp should be captured on client while calling createLedger or asyncCreateLedger.

In addition to this very common field maybe it would be useful to add a custom byte[] field named ""custom client data"" in order to let the client 'describe' the ledger without the need of extra data on Zookeeper. 
",2015-11-09 11:32:41,2016-02-23 18:17:16
BOOKKEEPER-880,Make LedgerHandle implement AutoCloseable,Improvement,4,Closed,6,Fixed,2016-04-08 17:44:35,2015-11-11 08:56:52,2016-05-16T21:47:27.000+0000,eolivelli,Enrico Olivelli,eolivelli,It would be useful for simple clients to have LedgerHandle implement AutoCloseable.maybe Bookkeeper class too. ,2015-11-11 08:56:52,2016-04-08 17:44:35
BOOKKEEPER-881,upgrade surefire plugin to 2.19,Improvement,4,Resolved,5,Fixed,2016-06-08 23:08:51,2015-11-12 07:59:35,2016-06-09T13:11:55.000+0000,rithin.shetty,Rithin Shetty,rithin.shetty,"surefire 2.19 plugin provides running tests with multiple formats in one

{code}
mvn ""-Dtest=???Test, !Unstable*, pkg/**/Ci*leTest.java, *Test#test*One+testTwo?????, #fast*+slowTest"" test
mvn ""-Dtest=Basic*, !%regex[.*.Unstable.*], !%regex[.*.MyTest.class#one.*|two.*], %regex[#fast.*|slow.*]"" test
{code}",2015-11-12 07:59:35,2016-06-08 23:08:51
BOOKKEEPER-882,Document that BookKeeper servers will shutdown on losing quorum,Documentation,20,Open,1,,,2015-11-16 17:35:18,2017-10-17T21:28:16.000+0000,,,,"We have adopted BookKeeper as part of our state management in Onyx 0.8.0 http://www.onyxplatform.org. As part of testing Onyx 0.8.0 we have begun testing with Jepsen, and our first step was testing BookKeeper without any interaction with Onyx.

We have discovered that the BookKeeper servers automatically shutdown without retry upon losing a connection to a quorum of nodes, which is the expected behaviour according to the code.

It is not obvious from the link at http://bookkeeper.apache.org/ under ""Documentation / Admin guide"", that this is the expected behaviour.

I believe it would be beneficial if this was discussed in the admin documentation.

Cheers",2015-11-16 17:35:18,
BOOKKEEPER-883,Test timeout in bookkeeper-benchmark,Bug,1,Closed,6,Fixed,2016-02-09 07:16:14,2015-11-25 23:29:29,2016-05-16T21:47:33.000+0000,hustlmsp,Sijie Guo,hustlmsp,bookkeeper-benchmark tests usually timeout,2015-11-25 23:29:29,2016-02-09 07:16:14
BOOKKEEPER-884,4.3.2 link points to 4.3.1 documentation,Bug,1,Resolved,5,Fixed,2016-01-12 19:03:38,2016-01-12 15:28:13,2016-01-12T19:03:38.000+0000,fpj,Flavio Paiva Junqueira,fpj,,2016-01-12 15:28:13,2016-01-12 19:03:38
BOOKKEEPER-885,Script to merge github pull request,Improvement,4,Closed,6,Fixed,2016-01-24 17:45:42,2016-01-13 10:21:18,2016-05-16T21:47:37.000+0000,hustlmsp,Sijie Guo,hustlmsp,Utility for creating well-formed pull request merges and pushing them to Apache. Use the one from spark project: https://github.com/apache/spark/blob/master/dev/merge_spark_pr.py,2016-01-13 10:21:18,2016-01-24 17:45:42
BOOKKEEPER-886,Allow to disable ledgers operation throttling,Improvement,4,Closed,6,Fixed,2016-02-09 07:32:51,2016-02-01 08:30:07,2016-05-16T21:47:52.000+0000,mmerli,Matteo Merli,mmerli,"In the bookie client there is a throttling mechanism that is rate-limiting the number of writes/s done on a particular ledger. The default value is 5000 entries/s written on a ledger.

Trying to write faster will block the calling thread, which may not be desirable in an asynchronous server.

We should be able to disable the throttling, if the application wants to control the rate with different mechanisms.",2016-02-01 08:30:07,2016-02-09 07:32:51
BOOKKEEPER-888,Dispatch individual callbacks from journal in different threads,Improvement,4,Closed,6,Fixed,2016-02-09 07:31:17,2016-02-01 09:03:58,2016-05-16T21:47:36.000+0000,mmerli,Matteo Merli,mmerli,"Currently the journal is sending all the responses from a single thread, after the entries in a batch are synced. Since a thread pool has been configured, it is better to spread the send-response tasks to all the available threads.",2016-02-01 09:03:58,2016-02-09 07:31:17
BOOKKEEPER-889,BookKeeper client should try not to use bookies with errors/timeouts when forming a new ensemble,Improvement,4,Closed,6,Fixed,2016-03-08 06:07:13,2016-02-03 02:12:04,2016-05-16T21:47:41.000+0000,sboobna,Siddharth Boobna,sboobna,"Due to various issues (slow disks, network issues, bugs, etc), the bookkeeper can be slow or unresponsive for extended period of times. During this time, r/w operations will fail/timeout and ledgers will create a new segment and form a new ensemble replacing this bookie. For new ledgers, it might still pick up this bookie or we can replace this bookie with another faulty bookie if we have multiple faulty bookies. 
The BK client should keep stats about these failure rates for all the bookies and it should ""quarantine"" failing bookies for a certain amount of time. Once a bookie is quarantined, it will not be picked up in forming a new ensemble, unless no other ""healthy"" bookies are available.

Solution:
Keep a counter of errors in the bookie client pool and periodically check for number of errors in a given time span and mark these bookies as ""quarantined"" in the BookieWatcher.
In the BookieWatcher, try to create an ensemble list excluding the quarantined bookies and if that fails, fall back to an empty exclusion list.
We will also remove the bookies from the quarantined list after a configurable period of time.",2016-02-03 02:12:04,2016-03-08 06:07:13
BOOKKEEPER-890,Concurrent modification exception when removing listener in Bookkeeper ZK ledger manager,Bug,1,Closed,6,Fixed,2016-02-09 07:24:44,2016-02-03 19:59:11,2016-05-16T21:47:34.000+0000,mmerli,Matteo Merli,mmerli,"The listener set is modified while iterating through it.

{noformat}
00:20:00.283 [main-EventThread] INFO  o.a.b.meta.AbstractZkLedgerManager   - Unregistered ledger metadata listener ReadOnlyLedgerHandle(lid = 10454, id = 839729832) on ledger 10454.
00:20:00.283 [main-EventThread] ERROR org.apache.zookeeper.ClientCnxn      - Error while calling watcher 
java.util.ConcurrentModificationException: null
        at java.util.HashMap$HashIterator.nextNode(HashMap.java:1429) ~[na:1.8.0_60]
        at java.util.HashMap$KeyIterator.next(HashMap.java:1453) ~[na:1.8.0_60]
        at org.apache.bookkeeper.meta.AbstractZkLedgerManager.process(AbstractZkLedgerManager.java:207) ~[bookkeeper-server-4.3.1.36.jar:4.3.1]
        at org.apache.zookeeper.ClientCnxn$EventThread.processEvent(ClientCnxn.java:522) [zookeeper-3.4.6.jar:3.4.6-1569965]
        at org.apache.zookeeper.ClientCnxn$EventThread.run(ClientCnxn.java:498) [zookeeper-3.4.6.jar:3.4.6-1569965]
{noformat}",2016-02-03 19:59:11,2016-02-09 07:24:44
BOOKKEEPER-891,Read entries failure should trigger callback only once,Bug,1,Closed,6,Fixed,2016-02-09 07:41:28,2016-02-05 16:42:51,2016-05-16T21:47:49.000+0000,mmerli,Matteo Merli,mmerli,"When reading multiple entries with {code}LedgerHandle.asyncReadEntries(){code}, in case there is a read error, the callback is currently being invoked for each of the requested entries. 

Since a single ""success"" callback is expected, we should also have a single ""failure"" callback invocation.",2016-02-05 16:42:51,2016-02-09 07:41:28
BOOKKEEPER-892,Add a sanity test to help identify bookie nodes with problems that prevent writes but is still registered in ZK,Test,6,Closed,6,Fixed,2016-02-09 07:29:39,2016-02-08 03:02:08,2016-05-16T21:47:27.000+0000,sboobna,Siddharth Boobna,sboobna,"Bookie Shell should have a sanity test to identify any problems with the local bookie that is still registered in ZK.

Solution:
Add a sanity test to the bookie shell that will create a ledger locally, write/read few entries and delete the ledger. To test only the local bookie, the ledger ensemble size will be 1 and we implement a LocalBookieEnsemblePlacementPolicy.",2016-02-08 03:02:08,2016-02-09 07:29:39
BOOKKEEPER-893,bookie exited with status 0 on journal I/O exception,Bug,1,Closed,6,Fixed,2016-02-09 07:37:51,2016-02-08 06:03:15,2016-05-16T21:47:49.000+0000,sboobna,Siddharth Boobna,sboobna,"{noformat}
06:13:32.041 [BookieJournal-3181] ERROR org.apache.bookkeeper.bookie.Journal - I/O exception in Journal thread!
java.nio.channels.ClosedChannelException: null
        at sun.nio.ch.FileChannelImpl.ensureOpen(FileChannelImpl.java:110) ~[na:1.8.0_60]
        at sun.nio.ch.FileChannelImpl.position(FileChannelImpl.java:253) ~[na:1.8.0_60]
        at org.apache.bookkeeper.bookie.Journal.run(Journal.java:964) ~[bookkeeper-server-4.3.1.33.jar:4.3.1]
06:13:32.041 [BookieJournal-3181] INFO  org.apache.bookkeeper.bookie.Journal - Journal exited loop!
06:13:32.041 [Bookie-3181] ERROR org.apache.bookkeeper.bookie.Bookie  - Journal manager quits unexpectedly.
06:13:32.042 [Bookie-3181] INFO  org.apache.bookkeeper.bookie.Bookie  - Triggering shutdown of Bookie-3181 with exitCode 5
06:13:32.042 [BookieShutdownTrigger] INFO  org.apache.bookkeeper.bookie.Bookie  - Shutting down Bookie-3181 with exitCode 5
06:13:32.044 [main] INFO  o.a.bookkeeper.proto.BookieServer    - Stop stats provider
06:13:32.045 [bookie-reg-0] INFO  org.apache.zookeeper.ZooKeeper       - Session: 0x14ff63dc02cbd02 closed
06:13:32.045 [bookie-reg-0-EventThread] INFO  org.apache.zookeeper.ClientCnxn      - EventThread shut down
06:13:32.045 [BookieShutdownTrigger] INFO  org.apache.bookkeeper.bookie.Journal - Shutting down Journal
06:13:32.046 [Thread-2] INFO  o.a.bookkeeper.proto.BookieServer    - Shutting down BookieServer
06:13:32.046 [Thread-2] INFO  o.a.b.proto.BookieNettyServer        - Shutting down BookieNettyServer
06:13:32.046 [ForceWriteThread] ERROR org.apache.bookkeeper.bookie.Journal - ForceWrite thread interrupted
java.lang.InterruptedException: null
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014) ~[na:1.8.0_60]
        at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2048) ~[na:1.8.0_60]
        at org.apache.bookkeeper.util.UnboundArrayBlockingQueue.take(UnboundArrayBlockingQueue.java:312) ~[bookkeeper-server-4.3.1.33.jar:4.3.1]
        at org.apache.bookkeeper.bookie.Journal$ForceWriteThread.run(Journal.java:448) ~[bookkeeper-server-4.3.1.33.jar:4.3.1]
...
06:13:32.184 [bookie-io-0] WARN  i.n.channel.DefaultChannelPipeline   - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handle the exception.
java.nio.channels.ClosedChannelException: null
{noformat}

When the bookie shuts down due to some exception, it exits with exitCode 0. 
We try to get the exitCode when calling System.exit() here:
https://github.com/apache/bookkeeper/blob/master/bookkeeper-server/src/main/java/org/apache/bookkeeper/proto/BookieServer.java#L400

But the exitCode is set by the shutdown hook which is triggered by System.exit(). Thus, we will always exit with code 0.

Solution:
We explicitly call bookie shutdown to set the exit code.",2016-02-08 06:03:15,2016-02-09 07:37:51
BOOKKEEPER-894,Read ledger entries from the bookie shell,Improvement,4,Closed,6,Fixed,2016-03-16 04:04:06,2016-02-09 17:19:59,2016-05-16T21:47:50.000+0000,sboobna,Siddharth Boobna,sboobna,"Bookie Shell should have a tool to read ledger entries from the bookkeeper cluster with optional arguments of startEntryId and endEntryId.

Solution:
We implement readEntries() in BookKeeperAdmin and return an Iterable. While iterating through it, we fetch individual entries instead of fetching all entries at once. Also, if the lastEntryId is not specified, we read entries till we get a NoSuchEntryException",2016-02-09 17:19:59,2016-03-16 04:04:06
BOOKKEEPER-895,bookies should not retain ledgers which no longer belong to them,Improvement,4,Closed,6,Fixed,2016-04-27 07:55:48,2016-02-11 05:07:22,2016-05-16T21:47:48.000+0000,sboobna,Siddharth Boobna,sboobna,"The bookies do not clean up ledgers on their disk which exist in zookeeper but are not assigned to them by the ensemble definition. This happens if a bookie has a ledger, went offline, it was replicated elsewhere, and then the bookie comes back up. Then we have an extra copy of the same ledger.

Solution:
Bookie should handle this case in the garbage collector. Since we will have to read the ledger metadata and go through its ensemble set to determine if the bookie exists in the ensemble, this is an expensive operation. Thus, we will only run this task once every day.",2016-02-11 05:07:22,2016-04-27 07:55:48
BOOKKEEPER-896,VM-local transport,New Feature,2,Resolved,5,Fixed,2016-05-25 06:51:55,2016-02-19 09:27:29,2016-06-10T13:45:52.000+0000,eolivelli,Enrico Olivelli,eolivelli,"Hi,
Im wondering if it is feasible to have a way to launch a Bookie and a Bookkeeper client in the same JVM without using network, valid use cases are:
1) Unit testing 
2) Installations using a single Bookie 

1) Unit testing
For unit testing  Im using mock classes which reproduce the functions of Bookkeeper but it makes my code more complex. 
Running network-related libraries limits the possibility of running tests in parallel and slows down the overall throughput of the tests

2) Single Bookie deployment
Sometimes I need to launch software which uses Bookkeeper in a single-machine deployment, in this case using an embedded Bookie will let to have only a single JVM process which runs the full stack of the service.

For instance when Im using Bookkeeper as a commit log I need to implement a commit log which uses Bookkeeper for replicated deployments, a simple file based commit log  and a pure in-memory commit log for unit testing.

I think it could be done using Netty LocalServerChannelFactory (and related client-side classes) and some tricks about the use of hostnames, registration on Zookeeper and so on

Of course the same issue will be on Zookkeeper 
",2016-02-19 09:27:29,2016-05-25 06:51:55
BOOKKEEPER-897,Fix findbugs warnings and missing apache license header,Bug,1,Closed,6,Fixed,2016-02-23 23:39:23,2016-02-23 18:56:41,2016-05-16T21:47:49.000+0000,hustlmsp,Sijie Guo,hustlmsp,,2016-02-23 18:56:41,2016-02-23 23:39:23
BOOKKEEPER-898,Underreplication doesn't get triggered when a read only bookie is shut down,Bug,1,Closed,6,Fixed,2016-03-08 06:19:06,2016-02-28 19:04:48,2016-05-16T21:47:34.000+0000,sboobna,Siddharth Boobna,sboobna,"The auditor doesn't pick up a bookie shut down from read only mode. The watcher on child nodes of ""/ledgers/available"" node on zk doesn't get triggered if there is any change in the children of any of those child nodes (""/ledgers/available/readonly"").

Solution:
The auditor needs to set another child watcher on read only bookie node on zk.",2016-02-28 19:04:48,2016-03-08 06:19:06
BOOKKEEPER-899,Bookie should return to read-write mode once the disk usage drops before the threshold,Bug,1,Closed,6,Fixed,2016-03-08 06:14:36,2016-02-28 19:16:33,2016-05-16T21:47:38.000+0000,sboobna,Siddharth Boobna,sboobna,"Once a bookie goes above the diskUsageThreshold and becomes readOnly, it will never go back to readWrite even if the disk usage drops significantly.
When the LedgerDirsMonitor gets a NoWritableLedgerDirException, it will put the bookie in read only mode, but will also stop monitoring and never goes back to read-write mode when the disk usage drops below threshold.

Solution:
The LedgerDirsMonitor thread should not break out of the while loop when it gets NoWritableLedgerDirException, and should continue monitoring the directories.",2016-02-28 19:16:33,2016-03-08 06:14:36
BOOKKEEPER-900,read only bookie runs replicator and does not release the under replicated lock after failing,Bug,1,Closed,6,Fixed,2016-03-08 06:16:25,2016-02-29 03:46:12,2016-05-16T21:47:24.000+0000,sboobna,Siddharth Boobna,sboobna,"ReplicationWorker throws BkWriteOnReadOnlyBookieException here: https://github.com/apache/bookkeeper/blob/master/bookkeeper-server/src/main/java/org/apache/bookkeeper/replication/ReplicationWorker.java#L255
and does not release the under replicated lock.

Solution:
Release the under replicated lock before throwing BkWriteOnReadOnlyBookieException and make the replication worker wait till the bookie becomes writable again.",2016-02-29 03:46:12,2016-03-08 06:16:25
BOOKKEEPER-901,Add an authentication framework,New Feature,2,Closed,6,Fixed,2016-04-05 06:46:23,2016-03-08 19:59:05,2016-11-04T16:16:13.000+0000,mmerli,Matteo Merli,mmerli,"We should have an authentication framework to be able to add auth mechanisms on the communications between clients and bookies.

",2016-03-08 19:59:05,2016-04-05 06:46:23
BOOKKEEPER-902,Test failures in EntryLogTest,Bug,1,Closed,6,Fixed,2016-03-14 19:12:42,2016-03-08 20:46:18,2016-05-16T21:47:36.000+0000,mmerli,Matteo Merli,mmerli,"There are 2 tests consistently failing in EntryLogTest

{noformat} 
testRecoverFromLedgersMapOnV0EntryLog(org.apache.bookkeeper.bookie.EntryLogTest)
testRecoverFromLedgersMap(org.apache.bookkeeper.bookie.EntryLogTest)
{noformat}",2016-03-08 20:46:18,2016-03-14 19:12:42
BOOKKEEPER-903,MetaFormat BookieShell Command is not deleting UnderReplicatedLedgers list from the ZooKeeper,Bug,1,Resolved,5,Fixed,2016-11-09 02:07:15,2016-03-09 20:18:44,2016-11-09T13:12:57.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,MetaFormat BookieShell Command: On executing 'metaformat' BookieShell command it is observed that it does everything as expected but it doesn't deletes UnderReplicatedLedgers list from the ZooKeeper.,2016-03-09 20:18:44,2016-11-09 02:07:15
BOOKKEEPER-904,test BookieInitializationTest.testDuplicateBookieServerStartup fails on non-english machines,Bug,1,Closed,6,Fixed,2016-04-06 16:39:16,2016-03-14 16:33:05,2016-05-16T21:47:39.000+0000,eolivelli,Enrico Olivelli,eolivelli,"The test checks for message ""Address already in use"", which is ""Indirizzo gi in uso""  in Italian.
Maybe it is enough to catch BindException and remove the assertion

{code}
Assert.assertTrue(""BKServer allowed duplicate startups!"",
                    ce.getCause().getMessage().contains(""Address already in use""));
{code}",2016-03-14 16:33:05,2016-04-06 16:39:16
BOOKKEEPER-905,Enhanec Bookie Shell,Improvement,4,Open,1,,,2016-03-15 01:31:24,2017-10-17T21:28:13.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,"Enhance Bookkeeper shell to perform following.
We may open sub-tasks for some of the following if needed.

- Add flush command to bookie shell
- Make bookie shell usable on dev box including using local bookie; so basically we must be able to run bookie specific commands even while using local bookie.
- Multiple formats for ExtentId in bk shell; input/output to take log/hex/uuid formats
- Spit out list of disk files, including index,journal,and ledger files
- enhance readlog command just to take a particular entryId and print that.",2016-03-15 01:31:24,
BOOKKEEPER-907,"for ReadLedgerEntriesCmd, EntryFormatter should be configurable and HexDumpEntryFormatter should be one of them",Bug,1,Resolved,5,Fixed,2017-01-30 20:31:24,2016-03-16 23:20:51,2017-01-31T12:49:51.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,"In ReadLedgerEntriesCmd for printing the contents of the Entry, HexDumpFormat is used by default here, but whereas in ReadJournalCmd/ReadLogCmd StringEntryFormatter is used and it is configurable. We should add HexDumpEntryFormatter just like StringEntryFormatter and use the configured formatter for printing the entry.",2016-03-16 23:20:51,2017-01-30 20:31:24
BOOKKEEPER-908,Case to handle BKLedgerExistException,Bug,1,Resolved,5,Fixed,2016-07-11 20:53:46,2016-03-29 17:07:13,2016-07-11T22:39:30.000+0000,jujjuri,JV Jujjuri,jujjuri,"--- a/bookkeeper-server/src/main/java/org/apache/bookkeeper/client/BKException.java
+++ b/bookkeeper-server/src/main/java/org/apache/bookkeeper/client/BKException.java
@@ -100,6 +102,8 @@ public abstract class BKException extends Exception {
             return new BKDuplicateEntryIdException();
         case Code.TimeoutException:
             return new BKTimeoutException();
+        case Code.LedgerExistException:
+            return new BKLedgerExistException();
         default:
             return new BKUnexpectedConditionException();
         }
",2016-03-29 17:07:13,2016-07-11 20:53:46
BOOKKEEPER-909,ZooKeeper of LocalBookkeeper should use the correct tickTime,Bug,1,Closed,6,Fixed,2016-03-31 20:56:05,2016-03-31 20:28:05,2016-05-16T21:47:39.000+0000,arunmk,Arun M. Krishnakumar,arunmk,"ZooKeeperServer should use the correct value for tickTime in LocalBookie. Currently the code uses the port-number 2181, and since it's near to the DEFAULT_TICK_TIME it works.",2016-03-31 20:28:05,2016-03-31 20:56:05
BOOKKEEPER-910,"In LocalBookkeeper, Zookeeper server and client use different host addresses",Bug,1,Closed,6,Fixed,2016-04-11 20:39:43,2016-04-01 17:31:16,2016-05-16T21:47:51.000+0000,arunmk,Arun M. Krishnakumar,arunmk,"In LocalBookkeeper, the Zookeeper server is started at 127.0.0.1 and the client tries to derive the localhost address using getLocalHost API. This has a few issues:
1. There is a possibility of using the ipv6 address for localhost and hence the client will try connecting to ::1, 2181 rather than 127.0.0.1:2181 (this happens commonly on OSX)
2. The getLocalHost API could sometimes return non-loopback addresses as well.

Since the 'localbookie' mode is used with the zookeeper in the same machine, we should use loopback addresses for all invocations. The patch does just that.

 
",2016-04-01 17:31:16,2016-04-11 20:39:43
BOOKKEEPER-911,Fix TestReplicationWorker test failures,Bug,1,Closed,6,Fixed,2016-04-27 07:01:22,2016-04-02 17:38:29,2016-05-16T21:47:47.000+0000,mmerli,Matteo Merli,mmerli,"Currently we have the following test failures in master branch:
Results :

Failed tests:   testRWZKSessionLost[0](org.apache.bookkeeper.replication.TestReplicationWorker): Replication worker should have shut down
  testRWZKSessionLost[1](org.apache.bookkeeper.replication.TestReplicationWorker): Replication worker should have shut down
  testRWZKSessionLost[2](org.apache.bookkeeper.replication.TestReplicationWorker): Replication worker should have shut down

Tests in error: 
  testRWShutdownOnLocalBookieReadonlyTransition[0](org.apache.bookkeeper.replication.TestReplicationWorker): test timed out after 20000 milliseconds
  testRWShutdownOnLocalBookieReadonlyTransition[1](org.apache.bookkeeper.replication.TestReplicationWorker): test timed out after 20000 milliseconds
  testRWShutdownOnLocalBookieReadonlyTransition[2](org.apache.bookkeeper.replication.TestReplicationWorker): test timed out after 20000 milliseconds

Tests run: 654, Failures: 3, Errors: 3, Skipped: 0
",2016-04-02 17:38:29,2016-04-27 07:01:22
BOOKKEEPER-912,Allow EnsemblePlacementPolicy to choose bookies using ledger custom data (multitenancy support),New Feature,2,Resolved,5,Fixed,2016-11-17 23:44:18,2016-04-05 15:23:17,2016-11-18T21:08:34.000+0000,eolivelli,Enrico Olivelli,eolivelli,"I would like to restrict the set of bookies to be used for a specific ledger. Actually a single EnsemblePlacementPolicy is used for all the ledgers.

This is because I want to create a ledger only using a dedicated set of machines/bookies which are dedicated to the 'tenant' for which I'm creating the ledger.

We can add an optional (byte[]) parameter to asyncCreateLedger which in turn is to be passed to the configured EnsemblePlacementPolicy which in turn will be able to decide which are the most suitable bookies for the tenant.

This parameter must be stored on ledger metadata, in order to be used in replaceBookie. ",2016-04-05 15:23:17,2016-11-17 23:44:18
BOOKKEEPER-913,Fix flakiness in TestBackwardCompat,Bug,1,Closed,6,Fixed,2016-04-10 03:20:42,2016-04-05 16:02:32,2017-01-27T18:24:59.000+0000,mmerli,Matteo Merli,mmerli,"This test is intermittently failing. It could be related to a timing issue, given that it fails more frequently in Jenkins compared to running the test on the laptop.

{noformat}
Failed tests:   testCompat410(org.apache.bookkeeper.test.TestBackwardCompat): Shouldn't be able to write
{noformat}",2016-04-05 16:02:32,2016-04-10 03:20:42
BOOKKEEPER-914,ReadOnlyBookieTest.testBookieShouldTurnWritableFromReadOnly is intermettently failing,Bug,1,Closed,6,Fixed,2016-04-07 19:56:08,2016-04-06 18:38:15,2016-05-16T21:47:32.000+0000,ayegorov,Andrey Yegorov,ayegorov,"I've seen it failing a few times and it seems different that BOOKKEEPER-774.

https://builds.apache.org/job/bookkeeper-master-git-pullrequest/57/testReport/junit/org.apache.bookkeeper.test/ReadOnlyBookieTest/testBookieShouldTurnWritableFromReadOnly/

{noformat}
Error Message

Should fail to create a ledger since there isn't enough bookies alive.
Stacktrace

java.lang.AssertionError: Should fail to create a ledger since there isn't enough bookies alive.
	at org.junit.Assert.fail(Assert.java:88)
	at org.apache.bookkeeper.test.ReadOnlyBookieTest.testBookieShouldTurnWritableFromReadOnly(ReadOnlyBookieTest.java:137)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.lang.Thread.run(Thread.java:745)
{noformat}",2016-04-06 18:38:15,2016-04-07 19:56:08
BOOKKEEPER-915,Auto replication should honor ensemble placement policy,Bug,1,Open,1,,,2016-04-07 04:46:28,2017-10-17T21:28:10.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,"ReplicationWorker does not honor Ensemble Placement Policy.
The target bookie in ReplicationWorker should only be able to replicate based on the placement policy, else give up the underreplicated lock. For example, in rackaware policy, the target bookie should only be able to replicate if its not in the same rack as the other bookies in the ensemble, or if there isn't any other bookie available in different racks.",2016-04-07 04:46:28,
BOOKKEEPER-916,Placement policy to accomodate different types of ledger storage,New Feature,2,Open,1,,,2016-04-07 06:10:52,2017-10-17T21:33:29.000+0000,rithin.shetty,Rithin Shetty,rithin.shetty,"As we start to use bookkeeper as long term storage, it may not be right use of resources to keep all copies of entry (write ensemble) on efficient storage. This feature is to come up with an intelligent placement that distributes entry copies across different classes of storage.

Simply put, say we have SSD based ledger storage and HDD based ledger storage on each system. Instead of putting all copies of entries either on SSD or on HDD, this placement policy maintains one copy on SSD and others on HDD.

- Have at least one copy on SSD and others on HDD.
   - Writer need to be aware of this classification
   - Replication logic need to be aware of this logic.

- While reading attempt to read from SSD first.
  - Reader also need to be aware of this logic.

This will push bookkeeper  towards the long term storage, also can be a stepping store towards introducing storage tiers in the future.

This has dependency/relation to

 https://issues.apache.org/jira/browse/BOOKKEEPER-912.
https://issues.apache.org/jira/browse/BOOKKEEPER-915
",2016-04-07 06:10:52,
BOOKKEEPER-917,LocalBookKeeperTest seems to be silently failing,Bug,1,Closed,6,Fixed,2016-04-10 04:00:35,2016-04-07 09:23:06,2016-05-16T21:47:54.000+0000,mmerli,Matteo Merli,mmerli,"I've noticed this while inspecting the output in jenkins:

{noformat}
Running org.apache.bookkeeper.client.BookKeeperCloseTest
Tests run: 10, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 12.074 sec
Running org.apache.bookkeeper.client.LocalBookKeeperTest
Running org.apache.bookkeeper.meta.GcLedgersTest
{noformat}

It sounds like {{LocalBookKeeperTest}} is failing silently. Is it hanging and timing out?

https://builds.apache.org/job/bookkeeper-master-git-pullrequest/57/console",2016-04-07 09:23:06,2016-04-10 04:00:35
BOOKKEEPER-918,Create Ledger NameSpace,New Feature,2,Open,1,,,2016-04-07 14:22:28,2017-10-17T21:28:07.000+0000,jujjuri,JV Jujjuri,jujjuri,"Bookkeeper doesn't really have a real NameSpace, it operates by ledgerId. I have opened and worked on https://issues.apache.org/jira/browse/BOOKKEEPER-873 which allows applications to pass-in LedgerId instead of BK client API picking one for them. But that really doesn't offer much flexibility.

Since ledgerId is a long we can't have 128-bit UUIDs as ledgerIDs and this severely restricts the range if we are generating ledgerIDs through a random generator (https://issues.apache.org/jira/browse/BOOKKEEPER-864)

Best solution for this is to offer a real name space, and I believe it is relatively simple than offering 128-bit ledgerIDs.

Analogous to regular filesystem, we treat our ledgerId as inode-number. Create a new name space in ZK with the user provided pretty-name and provide simple mapping at ZK between name-to-ledgerId. This mapping is static, and never changes once created. i.e name-x always points ledgerId-z. Given this most part of bookie code doesn't need to be aware of this mapping, and changes mostly will be confined client code and in create/delete/list paths.",2016-04-07 14:22:28,
BOOKKEEPER-919,Auditor is sometimes marking as failed a bookie switching from available to read-only mode,Bug,1,Closed,6,Fixed,2016-04-27 07:31:53,2016-04-07 20:00:40,2016-05-16T21:47:53.000+0000,mmerli,Matteo Merli,mmerli,"AuditorLedgerCheckerTest.testReadOnlyBookieExclusionFromURLedgersCheck intermittently failing

This test too, I've seen it failing in different occasions.

https://builds.apache.org/job/bookkeeper-master-git-pullrequest/59/testReport/junit/org.apache.bookkeeper.replication/AuditorLedgerCheckerTest/testReadOnlyBookieExclusionFromURLedgersCheck_2_/

{noformat}
Error Message

latch should not have completed
Stacktrace

java.lang.AssertionError: latch should not have completed
	at org.junit.Assert.fail(Assert.java:88)
	at org.junit.Assert.assertTrue(Assert.java:41)
	at org.junit.Assert.assertFalse(Assert.java:64)
	at org.apache.bookkeeper.replication.AuditorLedgerCheckerTest.testReadOnlyBookieExclusionFromURLedgersCheck(AuditorLedgerCheckerTest.java:279)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
	at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
	at java.util.concurrent.FutureTask.run(FutureTask.java:262)
	at java.lang.Thread.run(Thread.java:745)
{noformat}",2016-04-07 20:00:40,2016-04-27 07:31:53
BOOKKEEPER-920,Extend bk-merge-pr.py to add more info to Jira ticket when merging,Improvement,4,Closed,6,Fixed,2016-04-27 07:07:40,2016-04-11 18:55:15,2016-05-16T21:47:46.000+0000,mmerli,Matteo Merli,mmerli,"We should add more information to the Jira ticket when merging a github PR. 
Currently, the update on the Jira contains only the author and commit title. It would be good to also have:
  * Author
  * Committer
  * Reviewers (Better if we automatically read the '+1' from the PR comments)
 
In addition, we should add the option to run the tests locally on the merged PR before pushing to apache git. 
Recently we had cases of PRs which were fine on their own, but then tests started failing after merging into master (because of other commits since), even without git merge conflicts.",2016-04-11 18:55:15,2016-04-27 07:07:40
BOOKKEEPER-921,Typo in LocalBookkeeper: Use InetAddress.getHostAddress instead of InetAddress,Bug,1,Closed,6,Fixed,2016-04-27 08:06:10,2016-04-11 20:37:02,2016-05-16T21:47:51.000+0000,arunmk,Arun M. Krishnakumar,arunmk,There was a typo in the fix for Bookkeeper-910 and this bug has the fix since the former is already merged.,2016-04-11 20:37:02,2016-04-27 08:06:10
BOOKKEEPER-922,"Create a generic (K,V) map to store ledger metadata",Improvement,4,Resolved,5,Fixed,2016-07-11 21:01:46,2016-04-13 01:11:24,2016-07-11T22:39:28.000+0000,rithin.shetty,Rithin Shetty,rithin.shetty,"We have introduced ctime into ledger metadata through https://issues.apache.org/jira/browse/BOOKKEEPER-879.

In the same token we would like to introduce createrId also. This can be a 128 bit UUID. Caller can write tools to group ledgers by createrId, in the future we can even enhance this to run queries based on createrId. 
 ",2016-04-13 01:11:24,2016-07-11 21:01:46
BOOKKEEPER-924,addEntry() is susceptible to spurious wakeups,Bug,1,Resolved,5,Fixed,2016-10-13 07:27:38,2016-04-22 16:40:50,2016-10-16T15:09:37.000+0000,eolivelli,Enrico Olivelli,eolivelli,"LedgerHandle sync interface heavily depends on SyncCounter to convert async interfaces
into sync interfaces.

Usaylly

SyncCounter.inc()
asyncCall()
SyncCOunter.block(0)

The block code is.

   synchronized void block(int limit) throws InterruptedException {
        while (i > limit) {
            int prev = i;
            wait();
            if (i == prev) {
                break;
            }
        }
    }

Since 'i' is going to be same as 'prev' on spurious wakeup, and wait() can return on spurious wakeups. ",2016-04-22 16:40:50,2016-10-13 07:27:38
BOOKKEEPER-925,Fix FindBugs discovered issues in master,Bug,1,Closed,6,Fixed,2016-04-30 00:14:22,2016-04-27 16:04:18,2016-05-16T21:47:35.000+0000,mmerli,Matteo Merli,mmerli,"After we have fixed unit tests in master, we are seeing FindBugs warnings: 

{noformat}
[INFO] --- findbugs-maven-plugin:2.5.2:check (default-cli) @ bookkeeper-server ---
[INFO] BugInstance size is 6
[INFO] Error size is 0
[INFO] Total bugs: 6
[INFO] Found reliance on default encoding in org.apache.bookkeeper.bookie.BookieShell$ReadLedgerEntriesCmd.runCmd(CommandLine): new String(byte[]) [""org.apache.bookkeeper.bookie.BookieShell$ReadLedgerEntriesCmd""] At BookieShell.java:[lines 403-474]
[INFO] Exception is caught when Exception is not thrown in org.apache.bookkeeper.bookie.ScanAndCompareGarbageCollector.gc(GarbageCollector$GarbageCleaner) [""org.apache.bookkeeper.bookie.ScanAndCompareGarbageCollector""] At ScanAndCompareGarbageCollector.java:[lines 64-227]
[INFO] org.apache.bookkeeper.client.BookieWatcher.<static initializer>() invokes inefficient Boolean constructor; use Boolean.valueOf(...) instead [""org.apache.bookkeeper.client.BookieWatcher""] At BookieWatcher.java:[lines 60-308]
[INFO] org.apache.bookkeeper.meta.ZkLedgerUnderreplicationManager.LOCK_DATA should be package protected [""org.apache.bookkeeper.meta.ZkLedgerUnderreplicationManager""] At ZkLedgerUnderreplicationManager.java:[lines 76-664]
[INFO] Synchronization performed on java.util.concurrent.ConcurrentLinkedQueue in org.apache.bookkeeper.proto.AuthHandler$ClientSideHandler.writeRequested(ChannelHandlerContext, MessageEvent) [""org.apache.bookkeeper.proto.AuthHandler$ClientSideHandler""] At AuthHandler.java:[lines 210-302]
[INFO] Synchronization performed on java.util.concurrent.ConcurrentLinkedQueue in org.apache.bookkeeper.proto.AuthHandler$ClientSideHandler$AuthHandshakeCompleteCallback.operationComplete(int, Void) [""org.apache.bookkeeper.proto.AuthHandler$ClientSideHandler$AuthHandshakeCompleteCallback""] At AuthHandler.java:[lines 333-354]
[INFO] ------------------------------------------------------------------------
{noformat}",2016-04-27 16:04:18,2016-04-30 00:14:22
BOOKKEEPER-926,Compacted entries are not properly synced before updating index,Bug,1,Closed,6,Fixed,2016-05-04 13:56:41,2016-04-30 21:58:42,2016-05-16T21:47:24.000+0000,mmerli,Matteo Merli,mmerli,"I have identified a couple of issues in Bookie compaction code. 

h4. Compacted entries are not properly synced when index is updated

When compacting, we read ""active"" entries from an entry log and we re-append to current entry log. After compacting a number of entries, by default 100K, or at the very end, we need to update the index pointing to the new entry log and offset.

Before updating the index, we need to wait for this entries to be flushed and fsynced, otherwise a bookie crash might leave the index updated, pointing to an invalid offset.

The current code that is supposed to wait until flushed is:

{code:java}
// GarbageCollectorThread.java:178
EntryLocation lastOffset = offsets.get(offsets.size()-1);
long lastOffsetLogId = EntryLogger.logIdForOffset(lastOffset.location);
while (lastOffsetLogId < entryLogger.getLeastUnflushedLogId() && running) {
    synchronized (flushLock) {
        flushLock.wait(1000);
    }

    lastOffset = offsets.get(offsets.size()-1);
    lastOffsetLogId = EntryLogger.logIdForOffset(lastOffset.location);
}

// update the index 
{code}

The condition {{lastOffsetLogId < entryLogger.getLeastUnflushedLogId()}} is wrong, because if the last compacted entry was written in an earlier entry log than the least unflushed log, it means that the entries are already flushed and thus we don't need to wait.

In the normal case what happens is that {{lastOffsetLogId} is actually the current entryLog and it's equal to {{entryLogger.getLeastUnflushedLogId()}}, so we don't wait. But, in this case the entries appended to the current entrylog are not flushed nor synced, hence the problem. 

h4. Exception during index flush

Having an exception when updating the index, combined with the above issue, makes the bookie GC to stop indefinitely. 
What happens is that the offset list is not cleared, and at the next bookie GC iteration it will find the old compacted entries in that list, for which now the entryLogId is less than the current log id, and that makes the while loop to never exit.

Another problem is that, any IOException during the index flush, will make the GC thread to bail out and it will not remove even the entry logs that were compacted and flushed. Next time, these entry logs will be compacted again.

h4. Proposed solution
I think the best solution is to trigger the {{entryLogger.flush()}} form the bookie GC thread before updating the indexes. That would simplify the code and I don't see any disadvantages in doing that. 
Another improvement would be to delete compacted entry logs individually, as soon as the compacted data is flush, without waiting the end of the whole compaction process. 

The advantages are : 
 * If compaction stop halfway, at least we don't have to re-compact what we just compacted
 * Compaction won't require significant space overhead. Today a major compaction can end up reappending a large amount of data and then deleting all the entry logs at the very end, requiring twice the size of the active data set to be stored on disk at some point in time.",2016-04-30 21:58:42,2016-05-04 13:56:41
BOOKKEEPER-927,Extend BOOKKEEPER-886 to LedgerHandleAdv too (BOOKKEEPER-886: Allow to disable ledgers operation throttling),Bug,1,Resolved,5,Fixed,2017-05-24 07:00:31,2016-05-15 22:39:03,2017-05-24T07:00:31.000+0000,jujjuri,JV Jujjuri,jujjuri,,2016-05-15 22:39:03,2017-05-24 07:00:31
BOOKKEEPER-929,"In ReadOnlyLedgerHandle, metadata gets updated in the event of writeclose but lastAddConfirmed and length is not getting updated.",Bug,1,Open,1,,,2016-05-30 23:04:43,2017-10-17T21:28:04.000+0000,jujjuri,JV Jujjuri,jujjuri,"In ReadOnlyLedgerHandle, metadata gets updated in the event of writeclose but lastAddConfirmed and length are not getting updated.",2016-05-30 23:04:43,
BOOKKEEPER-930,Option to disable Bookie networking,New Feature,2,Resolved,5,Fixed,2016-09-10 18:28:15,2016-06-10 13:45:27,2016-09-11T13:10:50.000+0000,eolivelli,Enrico Olivelli,eolivelli,"This issue is related to BOOKKEEPER-896 which introduced the ability to use Netty built-in local channels.

The idea is to disable Bookie networking for networkless JUnit testing.

We can introduce a ""disableServerSocketBind"" option to skip server-side bind at BookieNettyServer#listenOn

Another use case is to use BookKeeper as write-ahead log for single machine applications

Note: 
ZookKeeper still needs network but this is another issue",2016-06-10 13:45:27,2016-09-10 18:28:15
BOOKKEEPER-931,Update the committers list on website,Task,3,Resolved,5,Fixed,2016-06-14 07:46:27,2016-06-14 07:32:35,2016-06-14T07:46:27.000+0000,hustlmsp,Sijie Guo,hustlmsp,[~zhaijia] and [~jujjuri] joined the committers list. we need to update the committers list.,2016-06-14 07:32:35,2016-06-14 07:46:27
BOOKKEEPER-932,Move to JDK 8,Story,16,Resolved,5,Fixed,2016-07-11 21:06:52,2016-06-16 22:57:57,2016-07-14T10:38:26.000+0000,mmerli,Matteo Merli,mmerli,"We should move BookKeeper to compile with Java8 source level compatibility, to take advantage of new Java features.",2016-06-16 22:57:57,2016-07-11 21:06:52
BOOKKEEPER-933,ClientConfiguration always inherits System properties,Bug,1,Resolved,5,Fixed,2016-07-31 05:53:52,2016-06-17 15:06:00,2016-07-31T13:10:28.000+0000,eolivelli,Enrico Olivelli,eolivelli,"ClientConfiguration is always adding System.getProperties()

{code}
 protected AbstractConfiguration() {
        super();
        // add configuration for system properties
        addConfiguration(new SystemConfiguration());
    }
{code}

This is useful is some cases but sometimes it is very harmful because the user could modify the client behaviour inadvertently, for instance:: throttle, readTimeout....

",2016-06-17 15:06:00,2016-07-31 05:53:52
BOOKKEEPER-934,Relax durability,Improvement,4,Open,1,,,2016-06-19 22:54:16,2017-10-17T21:28:00.000+0000,,,,"I am thinking adding a new flag to bookkeeper#addEntry(..., Boolean sync). So the application can control whether to sync or not for individual entries.

- On the write protocol, adding a flag to indicate whether this write should sync to disk or not.
- On the bookie side, if the addEntry request is sync, going through original pipeline. If the addEntry disables sync,    complete the add callbacks after writing to the journal file and before flushing journal.
- Those add entries (disabled syncs) will be flushed to disks with subsequent sync add entries.


There is already a discussion in mail thread, here this ticket could gather ideas, and provide the discussion materials",2016-06-19 22:54:16,
BOOKKEEPER-935,Publish sources and javadocs to Maven Central,Improvement,4,Resolved,5,Fixed,2017-07-28 18:13:05,2016-06-21 10:55:44,2017-07-29T14:01:00.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,"We should push sources and javadocs to Maven Central during the release process. 
It is very useful to have such artifacts in IDEs ",2016-06-21 10:55:44,2017-07-28 18:13:05
BOOKKEEPER-936,Provide simple IP-filtered Auth Provider,New Feature,2,Open,1,,,2016-06-23 06:38:04,2017-10-17T21:27:57.000+0000,,,,"Since 4.4.0 we have introduced authentication. 
We can introduce a simple authentication provider which limit access to bookie data using the IP address of the client (it will affect inter-bookie connections too) ",2016-06-23 06:38:04,
BOOKKEEPER-937,Upgrade protobuf to 2.6,Improvement,4,Resolved,5,Fixed,2016-08-16 17:44:34,2016-06-27 18:30:37,2016-08-17T13:11:05.000+0000,,,,"I had to update protobuf definition for some internal experiments and found that working with protobuf 2.4 is rather inconvenient. It cannot be installed with brew on mac and building it on mac always result is build errors hence leaves an option of switching to linux to run protoc.

I decided to upgrade to 2.6 instead. It is compatible with 2.4 on wire and shaded so should not create any problems. All tests passed.

Please ignore changes in java files in attached patch during review; these are auto-generated.",2016-06-27 18:30:37,2016-08-16 17:44:34
BOOKKEEPER-938,LedgerOpenOp should use digestType from metadata,Bug,1,Resolved,5,Fixed,2016-08-01 06:04:30,2016-07-08 20:25:54,2016-08-01T13:10:52.000+0000,ayegorov,Andrey Yegorov,ayegorov,"Currently digestType verification in LedgerOpenOp seems to be treated as part of security logic. Since it is checked after password and error explicitly states that digestType mismatched, all that evil hacker has to do is to change digest type to another one. There are only two of them after all.

here is the scenario significantly affected by current behavior:

1. user rolls out clients with digestType set to MAC and creates lots of ledgers.
2. user notices that MAC is slower than CRC32 and decides to change digestType.
3. more ledgers created with CRC32.
4. user tries to read old and new ledgers
-> now old ledgers cannot be read because of the digest type mismatch.

I'll send pull request for review.
",2016-07-08 20:25:54,2016-08-01 06:04:30
BOOKKEEPER-939,Fix typo in bk-merge-pr.py,Bug,1,Resolved,5,Fixed,2016-07-11 22:25:57,2016-07-11 19:26:13,2016-07-12T13:09:40.000+0000,hustlmsp,Sijie Guo,hustlmsp,The script doesn't work if there is no JIRA associated with the pull request.,2016-07-11 19:26:13,2016-07-11 22:25:57
BOOKKEEPER-940,Fix findbugs warnings after bumping to java 8,Bug,1,Resolved,5,Fixed,2016-07-14 21:03:02,2016-07-12 06:54:55,2016-07-14T23:23:53.000+0000,eolivelli,Enrico Olivelli,eolivelli,"after bumping to java 8, the ci jobs fail with findbugs warnings. we'd need to fix all the findbugs warnings.",2016-07-12 06:54:55,2016-07-14 21:03:02
BOOKKEEPER-941,Introduce Feature Switches For controlling client and server behavior,New Feature,2,Resolved,5,Fixed,2016-07-31 05:56:52,2016-07-12 15:47:43,2016-07-31T13:10:29.000+0000,robindhamankar,Robin Dhamankar,robindhamankar,,2016-07-12 15:47:43,2016-07-31 05:56:52
BOOKKEEPER-942,Clean up Public Client Bootstrap API,Improvement,4,Open,1,,,2016-08-19 13:24:07,2017-10-17T21:27:54.000+0000,eolivelli,Enrico Olivelli,eolivelli,"The idea is to clean up the public client API to be used to bootstrap BookKeeper

The first problem to solve is to define a clear way to create the client, in 4.4.0 there are several constructors and a builder class.
The presence of many constructors is a burden to carry on for all the future versions, it would be better to have only a single way to boostrap the client.

Another minor issue is that from the point of view of a developer which uses BookKeeper client API it is very difficult to decide which API use,

We should also remove from the public API direct dependencies on third party APIs, like Netty 3.x, and maybe from ZooKeeper too.
At the same time we must support the option for the client to reuse existing expensive shared resources (such as ZooKeeper client, or netty3 HashedWheelTimer)

This issue may:
- deprecate existing constructors and BookKeeper.Builder class
- introduce a more future-proof API",2016-08-19 13:24:07,
BOOKKEEPER-943,Reduce log level of AbstractZkLedgerManager for register/unregister ReadOnlyLedgerHandle,Wish,5,Resolved,5,Fixed,2017-01-11 06:41:32,2016-08-24 07:46:30,2017-01-11T13:13:05.000+0000,eolivelli,Enrico Olivelli,eolivelli,"Every time a ledger is opened/closed at least two lines at level INFO are written to the application log.
In the case of ""tailing"" a ledger I open/close ledgers many times an so application log are filled up of this kind of lines:
{code}
Registered ledger metadata listener ReadOnlyLedgerHandle(lid = 29152, id = 1405806205) on ledger 29152.
Unregistered ledger metadata listener ReadOnlyLedgerHandle(lid = 29152, id = 1405806205) on ledger 29152.
{code}

I would like to decrease the log level to ""TRACE"" instead of ""INFO"" in AbstractZkLedgerManager.java
{code}
LOG.info(""Registered ledger metadata listener {} on ledger {}."", listener, ledgerId);
LOG.info(""Unregistered ledger metadata listener {} on ledger {}."", listener, ledgerId);
{code}",2016-08-24 07:46:30,2017-01-11 06:41:32
BOOKKEEPER-944,Multiple issues and improvements to BK Compaction.,Improvement,4,Resolved,5,Fixed,2017-06-05 18:31:06,2016-08-26 17:48:59,2017-06-06T18:13:05.000+0000,jujjuri,JV Jujjuri,jujjuri,"We have identified multiple issues with BK compaction.
This issue is to list all of them in one Jira ticket.

1.
MajorCompaction and MinorCompaction are very basic. Either they do it or wont do it. Proposal is to  add Low Water Mark(LWM) and High Water Mark(HWM) to the disk space. Have different compaction frequency and re-claim %s when the disk space is < low water mark  ,  >  LWM < HWM, > HWM.

2.
MajorCompaction and Minor Compactions are strictly frequency based. They should at least time of the day based, and also run during low system load, and if the system load raises, reduce the compaction depending on the disk availability 

3.
Current code disables compaction when disk space grows beyond configured threshold. There is no exit from this point. Have an option to keep reserved space for compaction, at least 2 entryLog file sizes when isForceGCAllowWhenNoSpace enabled.

4.
Current code toggles READONLY status of the bookie as soon as it falls below the disk storage threshold. Imagine if we keep 95% as the threshold, Bookie becomes RW as soon as it falls below 95 % and few more writes pushes it above 95 and it turns back to RONLY. Use a set of defines (another set of LWM/HWM?) where Bookie turns RO on high end and won't become RW until it hits low end.

5.
Current code never checks if the compaction is enabled or disabled once the major/minor compaction is started. If the bookie goes > disk threshold (95%) and at that compaction is going on, it never checks until it finishes but there may not be disk available for compaction to take place. So check if compaction is enabled after processing every EntryLog.

6.
Current code changes the Bookie Cookie value even when new storage is added. When the cookie changes Bookie becomes a new one, and BK cluster treats it as new bookie. If we have mechanism to keep valid cookie even after adding additional disk space, we may have a chance to bring the bookie back to healthy mode and have compaction going.

7. Bug
CheckPoint was never attempted to complete after once sync failure. There is a TODO in the code for this area.

8.
When the disk is above threshold, Bookie goes to RO. If we have to restart the bookie, on the way back, bookie tries to create new entrylog and other files, which will fail because disk usage is above threshold, hence bookie refuses to come up.",2016-08-26 17:48:59,2017-06-05 18:31:06
BOOKKEEPER-945,Add counters to track the activity of auditor and replication workers,Improvement,4,Resolved,5,Fixed,2017-06-22 00:37:00,2016-08-26 19:08:30,2017-06-22T00:37:00.000+0000,rithin.shetty,Rithin Shetty,rithin.shetty,"Once we enable auto recovery, auditor and replication workers start their activity. Today there is no way to monitor it using counters. This is a bug to track various activities of auditor and replication workers like: 

- Time taken by auditor to build the bookie->ledger list 
- No. of under replicated ledgers detected 
- Time taken by auditor to publish the under replicated ledger list 
- Time taken by auditor to check all the ledgers in the cluster 
- No. of ledgers replicated by each replication worker 
- No. of entries and bytes of data read and written by each replication worker
- Auditor can also report the distribution of ledgers within the cluster: how many bookies own a piece of ledger, etc. 

",2016-08-26 19:08:30,2017-06-22 00:37:00
BOOKKEEPER-946,Provide an option to delay auto recovery of lost bookies,Improvement,4,Resolved,5,Fixed,2016-12-17 01:44:36,2016-08-26 19:17:49,2016-12-17T12:49:46.000+0000,rithin.shetty,Rithin Shetty,rithin.shetty,"If auto recovery is enabled, and a bookie goes down for upgrade or even if it looses zk connection intermittently, the auditor detects it as a lost bookie and starts under replication detection and the replication workers on other bookie nodes start replicating the under replicated ledgers. All of this stops once the bookie comes up but by then a few ledgers would get replicated. Given the fact that we have multiple copies of data, it is probably not necessary to start the recovery as soon as a bookie goes down. We can probably wait for an hour or so and then start recovery. This should cover cases like planned upgrade, intermittent network connectivity loss, etc. The amount of time to wait can be an option and the default would be to not wait at all(i.e. retain current behavior).

Of course, if more than one bookie goes down within a short interval, we could decide to start auto recovery without waiting.
",2016-08-26 19:17:49,2016-12-17 01:44:36
BOOKKEEPER-947,Update workflow information on the web site,Documentation,20,Resolved,5,Done,2017-10-09 09:20:30,2016-08-31 14:17:39,2017-10-09T09:20:30.000+0000,fpj,Flavio Paiva Junqueira,fpj,"We need to update the information on how to contribute on the web site, in particular, how to submit patches. The wiki has been updated:

https://cwiki.apache.org/confluence/display/BOOKKEEPER/Contributing+to+BookKeeper

but not the web site:

http://bookkeeper.apache.org/svn.html",2016-08-31 14:17:39,2017-10-09 09:20:30
BOOKKEEPER-948,Provide an option to add more ledger/index directories to a bookie,New Feature,2,Resolved,5,Fixed,2016-11-29 23:03:07,2016-09-23 20:01:14,2016-11-30T13:13:14.000+0000,rithin.shetty,Rithin Shetty,rithin.shetty,Addition of new ledger or index directories to an existing bookie is disallowed via the cookie check in the bookie start path. Any attempt to add new storage is rejected and the bookie doesn't come up. We have a need to add additional storage to a bookie. This jira is for providing an option to add additional storage to a bookie.,2016-09-23 20:01:14,2016-11-29 23:03:07
BOOKKEEPER-949,Allow entryLog creation even when bookie is in RO mode for compaction,Sub-task,7,Resolved,5,Fixed,2017-01-30 22:25:15,2016-09-28 16:28:11,2017-01-31T12:49:50.000+0000,jujjuri,JV Jujjuri,jujjuri,"When storage usage goes above threshold, there won't be any writable ledger dirs available and bookie turns RO. There can be multiple ways bookie can start compaction including isForceGCAllowWhenNoSpace enabled or by other means. When this happens the compaction process need to create a new entrylog to make progress on compaction. Creation of entrylog will fail because there are no writable ledger dirs.

This is to allow entrylog creation if there is enough disk space even though used space is above threshold. Because after compaction space will stay the same or go below the threshold.",2016-09-28 16:28:11,2017-01-30 22:25:15
BOOKKEEPER-950,Ledger placement policy to accomodate different storage capacity of bookies,New Feature,2,Resolved,5,Fixed,2017-03-28 20:35:43,2016-10-05 23:27:18,2017-03-29T14:17:23.000+0000,rithin.shetty,Rithin Shetty,rithin.shetty,"In our environment, in Salesforce, we are likely to have bookie nodes with different storage capacity: some will have 1TB others might have 3TB. Also, our ledgers are likely going to be long lived. The current ledger placement policy selects the bookies randomly leading to uniform distribution. This would cause some of bookies to reach high utilization while the rest would be underutilized. We need a new ledger placement policy that has higher probability of selecting bookies with higher free disk space than the ones with lower disk free space.",2016-10-05 23:27:18,2017-03-28 20:35:43
BOOKKEEPER-951,CRC32C for bookkeeper,Improvement,4,Open,1,,,2016-10-14 00:23:13,2017-10-17T21:27:50.000+0000,,,,"CRC32C is hardware based CRC32 and it substantially improves performance and practically offloads CPU. 

[~merlimat] at yahoo implemented this for Pulsar, opening this item to port that change.

https://github.com/yahoo/pulsar/tree/master/pulsar-checksum

Java 9 has CRC32C native support but we need this JNI patch to achieve it on Java 8.",2016-10-14 00:23:13,
BOOKKEEPER-952,Fix RegionAwarePlacementPolicy,Bug,1,Resolved,5,Fixed,2016-10-20 17:38:53,2016-10-14 05:36:23,2016-10-21T13:09:53.000+0000,yzang,Yiming Zang,yzang,"TestRegionAwareEnsemblePlacementPolicy#testNewEnsembleWithThreeRegions is failing because RegionAwareEnsemblePlacementPolicy is not working as expected.

The current allocation policy is not evenly across the regions. The write quorum size is also not calculated correctly.

We need  to fix the placement policy and then fix the the test case.",2016-10-14 05:36:23,2016-10-20 17:38:53
BOOKKEEPER-953,command line options,Bug,1,Open,1,,,2016-10-16 19:29:01,2017-10-17T21:27:47.000+0000,,,,"Use more conventional patterns in usage warning messages ..

Eg  
{code}usage: listbookies  [-readwrite|-readonly] [-hostnames]{code}
ought to be 
{code}usage: listbookies  (-readwrite|-readonly) [-hostnames]{code}

.. if exactly one of -readwrite|-readonly are required as per the warning ...

{code}
$ bin/bookkeeper shell listbookies
20:23:17,808 ERROR One and only one of -readwrite and -readonly must be specified
listbookies: List the bookies, which are running as either readwrite or readonly mode.
usage: listbookies  [-readwrite|-readonly] [-hostnames]
 -h,--hostnames    Also print hostname of the bookie
 -ro,--readonly    Print readonly bookies
 -rw,--readwrite   Print readwrite bookies
{code}

There might be other instances so I suggest they are listed here and done in one go.",2016-10-16 19:29:01,
BOOKKEEPER-954,Bk vs gluster docs,Bug,1,Open,1,,,2016-10-19 10:29:41,2017-10-17T21:27:44.000+0000,,,,"https://cwiki.apache.org/confluence/display/BOOKKEEPER/BookKeeper+and+GlusterFS

It would be good if this page actually explained the GFS differences to Bk.


So for example where we have ""Now A and B are inconsistent."", this could be followed by a comparison to bk .. ""by contrast bk would avoid this possibility by...""",2016-10-19 10:29:41,
BOOKKEEPER-955,in BookKeeperAdmin listLedgers method currentRange variable is not getting updated to next iterator when it has run out of elements,Bug,1,Resolved,5,Fixed,2016-11-29 23:07:57,2016-10-19 21:33:04,2016-11-30T13:13:11.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,in BookKeeperAdmin listLedgers method currentRange variable is not getting updated to next iterator when it has run out of elements,2016-10-19 21:33:04,2016-11-29 23:07:57
BOOKKEEPER-956,HierarchicalLedgerManager doesn't work for ledgerid of length 9 and 10 because of order issue in HierarchicalLedgerRangeIterator,Bug,1,Resolved,5,Fixed,2016-11-09 02:09:10,2016-10-19 21:57:16,2016-11-09T13:12:47.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,"Issue Description:-
HierarchicalLedgerManager is supposed to work for ledgerids upto length of 10 (its layout is 2-4-4). But because of order issue in HierarchicalLedgerRangeIterator it doesn't work correctly if we create Ledgers of ledgerid length 9 and 10.

Rootcause:- in HierarchicalLedgerRangeIterator, in 'preload' method after getting l1Nodes by calling ""zk.getChildren(ledgerRootPath, null)"",  they need to be sorted, just like l2nodes in 'nextL1Node' method

How it manifests:-
If we try to create Ledgers using LedgerCreateAdv api with ledgerids of lengths 9 and 10, write entries and read entries, it will fail with following exception messages

2015-11-30 13:57:31,209 - WARN  - [GarbageCollectorThread:ScanAndCompareGarbageCollector@103] - Exception when iterating over the metadata {}
java.lang.IllegalArgumentException: inconsistent range
    at java.util.concurrent.ConcurrentSkipListMap$SubMap.<init>(ConcurrentSkipListMap.java:2506)
    at java.util.concurrent.ConcurrentSkipListMap.subMap(ConcurrentSkipListMap.java:1984)
    at java.util.concurrent.ConcurrentSkipListMap.subMap(ConcurrentSkipListMap.java:93)
    at org.apache.bookkeeper.bookie.ScanAndCompareGarbageCollector.gc(ScanAndCompareGarbageCollector.java:86)
    at org.apache.bookkeeper.bookie.GarbageCollectorThread.doGcLedgers(GarbageCollectorThread.java:419)
    at org.apache.bookkeeper.bookie.GarbageCollectorThread.run(GarbageCollectorThread.java:377)

org.apache.bookkeeper.client.BKException$BKNotEnoughBookiesException
    at org.apache.bookkeeper.client.BKException.create(BKException.java:58)
    at org.apache.bookkeeper.client.LedgerHandleAdv.addEntry(LedgerHandleAdv.java:101)
    at org.apache.bookkeeper.client.LedgerHandleAdv.addEntry(LedgerHandleAdv.java:70)
    at org.apache.bookkeeper.client.BookieWriteLedgerTest.testLedgerCreateAdvWithLedgerId(BookieWriteLedgerTest.java:212)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
    at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
    at java.lang.reflect.Method.invoke(Method.java:606)
    at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)
    at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
    at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)
    at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
    at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:298)
    at org.junit.internal.runners.statements.FailOnTimeout$CallableStatement.call(FailOnTimeout.java:292)
    at java.util.concurrent.FutureTask.run(FutureTask.java:262)
    at java.lang.Thread.run(Thread.java:745)",2016-10-19 21:57:16,2016-11-09 02:09:10
BOOKKEEPER-957,issues in LedgerHandleAdv ,Bug,1,Resolved,5,Fixed,2016-11-09 07:48:49,2016-10-19 22:31:59,2016-11-09T13:12:54.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,"1)  In LedgerHandleAdv in doAsyncAddEntry method, addToLength(length) call is not synchronized

In LedgerHandleAdv in doAsyncAddEntry method, call to addToLength(length) is not synchronized.

addEntry method is supposed to be thread safe, so when addEntry method of LedgerHandleAdv is called concurrently from multiple threads, addToLength will be messed up because its call is not synchrnoized.

in LedgerHandle it is synchronized over 'this'.

2) In LedgerHandleAdv, in asyncAddEntry it is incorrect to add 'op' to 'pendingAddOps' before calling doAsyncAddEntry

 In LedgerHandleAdv, in asyncAddEntry, it is incorrect to add 'op' to 'pendingAddOps' before calling doAsyncAddEntry.

Consider the following example,

Lets say ""asyncAddEntry(final long entryId, final byte[] data, final int offset, final int length, final AddCallback cb, final Object ctx)"" is called with incorrect arguments, and following condition is failed ""(offset < 0 || length < 0 || (offset + length) > data.length)"". Then as expected we would get ArrayIndexOutOfBoundsException, but now if we try to call asyncAddEntry with correct arguments for that entry, then it will fail with ""DuplicateEntryIdException"", since the op is added already in the previous call, which shouldn't have happened.",2016-10-19 22:31:59,2016-11-09 07:48:49
BOOKKEEPER-958,ZeroBuffer readOnlyBuffer returns ByteBuffer with 0 remaining bytes for length > 64k,Bug,1,Resolved,5,Fixed,2016-11-09 07:49:43,2016-10-19 23:23:54,2016-11-09T13:13:00.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,"in ZeroBuffer
here, if the length is > zeroBytes.length (64K), then it is returning zero ByteBuffer but its position is set to limit and hence its remaining will be 0, which is not expected, but if it is < 64k then its position is set to 0 and the remaining will be length.

Looking at the call hierearchy, it seems there are no callers for this function, but since this is utility class it needs to be corrected.

    public static ByteBuffer readOnlyBuffer(int length) {
        ByteBuffer buffer;
        if (length <= zeroBytes.length) {
            buffer = ByteBuffer.wrap(zeroBytes, 0, length);
        }
        else {
            buffer = ByteBuffer.allocate(length);
            put(buffer);
        }
        return buffer.asReadOnlyBuffer();
    }",2016-10-19 23:23:54,2016-11-09 07:49:43
BOOKKEEPER-959,ClientAuthProvider and BookieAuthProvider Public API used Protobuf Shaded classes,Bug,1,Resolved,5,Fixed,2017-01-31 01:22:32,2016-10-20 12:11:16,2017-01-31T12:49:49.000+0000,eolivelli,Enrico Olivelli,eolivelli,"With 4.4.0 we introduced the ability to implement custom authentication plugins.

The new interfaces ClientAuthProvider and BookieAuthProvider depend on ExtensionRegistry, which is a shaded dependency.

As a consequence it is not possibile to implement any custom auth provider in code outside the project, because shaded/relocated dependencies cannot be used.

We need to break the actual interface and introduce a new way to implement such plugins in a portable way",2016-10-20 12:11:16,2017-01-31 01:22:32
BOOKKEEPER-960,Re-replicator: bookie checking should handle flapping bookie registration,Improvement,4,In Progress,3,,,2016-10-31 05:41:31,2017-10-17T21:27:40.000+0000,yzang,Yiming Zang,yzang,"Problem:

currently re-replicator only uses the view of available/readonly bookies right at the time doing bookie checking. it would accidentally treat a bookie disappeared from zookeeper (e.g. zookeeper session expired, bookie restarted, flapping bookie registration due to network/gc) as lost bookies, which introduce unnecessary re-replication.

Solution:

introduce 'auditorStaleBookieInterval', if a bookie never register in the given interval, it would be marked as 'stale' bookies and re-replicate all ledgers belongs to that bookie. the default value is set 30 minutes.

Fixes:

- refactor bookie watcher to allow notifying bookie list thru BookiesListener
- introduce 'auditorStaleBookieInterval' to be able to mark bookies as 'stale' if bookies aren't registered themselves to zookeeper
- add more info logging about critical steps on re-replication logic
- misc changes",2016-10-31 05:41:31,
BOOKKEEPER-961,Assing read/write request for same ledger to a single thread,Improvement,4,Resolved,5,Fixed,2016-11-12 02:36:32,2016-11-02 20:31:25,2016-11-15T17:23:53.000+0000,mmerli,Matteo Merli,mmerli,"When entries for the same ledger are processed by the bookie we should avoid
the reordering of the request. Currently, if multiple read/write threads are
configured, the requests will be passed to the executor and writes for same
ledger will be spread across multiple threads.

This poses 2 issues:
  # Mutex contention to access the LedgerDescriptor
  # If the client receives add-entry acks out of order it has anyway to wait
      for the acks of previous entries before acknowledging the whole sequence
      to the application. In practice, the reordering is increasing the latency
      experienced by the application.
",2016-11-02 20:31:25,2016-11-12 02:36:32
BOOKKEEPER-962,Add more journal timing stats,Improvement,4,Resolved,5,Fixed,2016-11-12 02:38:08,2016-11-02 20:50:00,2016-11-12T13:12:00.000+0000,mmerli,Matteo Merli,mmerli,"It is useful to know the sync latency on the journal to identify disk/filesystem
related latency spikes that will cause all the entries to queue up. In the same
line, it's useful to track the amount of time spent in the journal queue.",2016-11-02 20:50:00,2016-11-12 02:38:08
BOOKKEEPER-964,Add concurrent maps and sets for primitive types,Improvement,4,Resolved,5,Fixed,2016-12-21 18:40:42,2016-11-02 21:07:17,2016-12-22T13:14:17.000+0000,mmerli,Matteo Merli,mmerli,"In BookKeeper there are many instances of maps and sets that use ledger id
and entry ids as keys or values. JDK concurrent collections have the overhead
of boxing all the primitive values into objects (eg: long --> Long) that would
need to be allocated from the heap. In addition to that, JDK map implementations
are closed hash tables and they will require at least one more allocation to hold
the linked-list/tree node.

There are already available libraries that offer primitive collections with
zero-allocation, but none of these support concurrent maps/sets.

We have added a handful of specializations, all based on the same implementation
idea. We have a hash table which is broken down into multiple sections. Each
sections, on its own, is an open hash table with linear probing, protected by
a stamped lock.

All insertions, lookups and iterations on these collections are allocation free.

{noformat}
ConcurrentLongHashMap: Map<long, Object>
ConcurrentLongHashSet: Set<long>
ConcurrentLongLongHashMap: Map<long, long>
ConcurrentLongLongPairHashMap: Map< Pair<long, long>, Pair<long, long> >
ConcurrentOpenHashMap: Map<Object, Object>
ConcurrentOpenHashSet: Set<Object>
{noformat}",2016-11-02 21:07:17,2016-12-21 18:40:42
BOOKKEEPER-965,Long Poll: Changes to the Write Path,Sub-task,7,Resolved,5,Fixed,2016-11-17 23:32:57,2016-11-08 15:25:53,2016-11-21T23:57:01.000+0000,robindhamankar,Robin Dhamankar,robindhamankar,,2016-11-08 15:25:53,2016-11-17 23:32:57
BOOKKEEPER-966,change the bookieServer cmdline to make conf-file and option co-exist,Improvement,4,Resolved,5,Fixed,2016-12-17 01:45:24,2016-11-09 07:43:28,2017-05-27T16:20:41.000+0000,zhaijia,Jia Zhai,zhaijia,"Currently, when using bookieServer cmdline to start a bookie, you will either give it a cofiguration file by ""-c booke.conf""; or add some options like ""<bookie_port> <zk_servers> <journal_dir> <ledger_dir [ledger_dir]>"" in a fix sequential.
It may not satisfy some of the requirement. So changed it to be co-exist for configuration file and options.

By this change, it will first use settings in configuration file; and then use options to overwrite some of the settings, if there are some options provided.

Here is an example after this change:
BookieServer -c bookie.conf -z localhost:2181 -m /bookkeeper/ledgers -p 3181 -j /mnt/journal -l ""/mnt/ledger1 /mnt/ledger2 /mnt/ledger3
Here, in this command:
-z is for Zookeeper client instance;
-m is for ""Zookeeper ledgers root path for bookies"";
-p is for ""bookie service port exported"";
-j is for ""bookie journal directory"";
-l is for ""bookie ledgers directories"".
",2016-11-09 07:43:28,2016-12-17 01:45:24
BOOKKEEPER-967,Create new testsuite for testing RackAwareEnsemblePlacementPolicy using ScriptBasedMapping.,Test,6,Resolved,5,Fixed,2016-12-17 01:42:31,2016-11-10 20:00:46,2016-12-17T12:49:45.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,,2016-11-10 20:00:46,2016-12-17 01:42:31
BOOKKEEPER-968,Entry log flushes happen on log rotation and cause long spikes in IO utilization,Improvement,4,Resolved,5,Fixed,2017-01-31 01:11:47,2016-11-11 08:08:22,2017-01-31T12:49:48.000+0000,ayegorov,Andrey Yegorov,ayegorov,"Caught this issue on the servers with 128G of RAM. This is probably not an issue on servers/VMs with less RAM.

With current implementation we end up with single entry log flush during log rotation.
OS tries to flush everything as fast as possible and saturates disk. This results in long periods of high latency (reads and writes).
 ",2016-11-11 08:08:22,2017-01-31 01:11:47
BOOKKEEPER-969,Security Support,New Feature,2,Resolved,5,Fixed,2017-08-02 08:48:12,2016-11-11 20:45:24,2017-08-02T08:48:12.000+0000,eolivelli,Enrico Olivelli,eolivelli,This is an umbrella issue for BP-3 BookKeeper Proposal about Security,2016-11-11 20:45:24,2017-08-02 08:48:12
BOOKKEEPER-970,Bump zookeeper version to 3.5,Improvement,4,Resolved,5,Fixed,2017-03-23 14:59:15,2016-11-19 01:09:08,2017-03-24T13:20:01.000+0000,hustlmsp,Sijie Guo,hustlmsp,"in DL, we need to leverage the asynchronous version of 'multi' in zookeeper. so this jira is to bump the zookeeper version to 3.5 to support async multi.",2016-11-19 01:09:08,2017-03-23 14:59:15
BOOKKEEPER-971,update bk codahale stats provider version,Improvement,4,Resolved,5,Fixed,2016-12-17 01:43:51,2016-11-23 01:34:01,2016-12-17T12:49:40.000+0000,zhaijia,Jia Zhai,zhaijia,"update bk stats provider: from codahale to yammer.
Currently io.dropwizard.metrics 3.1.0 is used most widely. will change version to this version, and run the test.
And would like to change CodahaleMetricsProvider.getMetrics() to public, since this would be used outside package.",2016-11-23 01:34:01,2016-12-17 01:43:51
BOOKKEEPER-972,Provide an DCOS Universe package for bookkeeper,Improvement,4,Open,1,,,2016-11-23 02:09:53,2017-10-17T21:27:37.000+0000,zhaijia,Jia Zhai,zhaijia,"Currently, the PR for this package is merged into main stream: https://github.com/mesosphere/universe
And the example PR is also merged into : https://github.com/dcos/examples

Maybe in next release of DCOS, we could use the bookkeeper package directly.

Left this ticket to tracking the following work left, such as the docker image automate update.
Since this version bookkeeper package use a fix version of bookkeeper docker, we need to handle automaticly ""update the package as we release new versions""",2016-11-23 02:09:53,
BOOKKEEPER-974,make pushing a docker image as part of the release procedure,Improvement,4,Open,1,,,2016-11-23 02:12:20,2017-10-17T21:27:34.000+0000,,,,make pushing a docker image as part of the release procedure.,2016-11-23 02:12:20,
BOOKKEEPER-975,Jenkins failed while test BookieClientTest.testWriteGaps,Bug,1,Open,1,,,2016-11-25 03:29:43,2017-10-17T21:27:31.000+0000,,,,"Here is error reporting:
```
2016-11-23 09:03:24,919 - ERROR - [BookieWriteThread-13645-orderedsafeexecutor-0-0:WriteEntryProcessorV3@125] - Unexpected exception while writing 1@1 : 
java.nio.BufferUnderflowException
	at java.nio.Buffer.nextGetIndex(Buffer.java:506)
	at java.nio.HeapByteBuffer.getLong(HeapByteBuffer.java:412)
	at org.apache.bookkeeper.bookie.SortedLedgerStorage.addEntry(SortedLedgerStorage.java:99)
	at org.apache.bookkeeper.bookie.LedgerDescriptorImpl.addEntry(LedgerDescriptorImpl.java:80)
	at org.apache.bookkeeper.bookie.Bookie.addEntryInternal(Bookie.java:1176)
	at org.apache.bookkeeper.bookie.Bookie.addEntry(Bookie.java:1235)
	at org.apache.bookkeeper.proto.WriteEntryProcessorV3.getAddResponse(WriteEntryProcessorV3.java:109)
	at org.apache.bookkeeper.proto.WriteEntryProcessorV3.safeRun(WriteEntryProcessorV3.java:142)
	at org.apache.bookkeeper.util.SafeRunnable.run(SafeRunnable.java:31)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-11-23 09:03:24,950 - ERROR - [BKClientOrderedSafeExecutor-orderedsafeexecutor-1-0:SafeRunnable@33] - Unexpected throwable caught 
java.lang.IndexOutOfBoundsException: Invalid readerIndex: 16 - Maximum is 0
	at org.jboss.netty.buffer.EmptyChannelBuffer.readerIndex(EmptyChannelBuffer.java:50)
	at org.apache.bookkeeper.test.BookieClientTest$1.readEntryComplete(BookieClientTest.java:112)
	at org.apache.bookkeeper.proto.PerChannelBookieClient$ReadCompletion$1.readEntryComplete(PerChannelBookieClient.java:930)
	at org.apache.bookkeeper.proto.PerChannelBookieClient.handleReadResponse(PerChannelBookieClient.java:868)
	at org.apache.bookkeeper.proto.PerChannelBookieClient$7.safeRun(PerChannelBookieClient.java:793)
	at org.apache.bookkeeper.util.SafeRunnable.run(SafeRunnable.java:31)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2016-11-23 09:03:25,088 - WARN  - [GarbageCollectorThread:ScanAndCompareGarbageCollector@153] - Exception when iterating over the metadata {}
java.lang.NullPointerException
	at org.apache.bookkeeper.util.ZkUtils.getChildrenInSingleNode(ZkUtils.java:207)
	at org.apache.bookkeeper.util.ZkUtils.getChildrenInSingleNode(ZkUtils.java:169)
	at org.apache.bookkeeper.meta.FlatLedgerManager$1.preload(FlatLedgerManager.java:110)
	at org.apache.bookkeeper.meta.FlatLedgerManager$1.hasNext(FlatLedgerManager.java:120)
	at org.apache.bookkeeper.bookie.ScanAndCompareGarbageCollector.gc(ScanAndCompareGarbageCollector.java:104)
	at org.apache.bookkeeper.bookie.GarbageCollectorThread.doGcLedgers(GarbageCollectorThread.java:371)
	at org.apache.bookkeeper.bookie.GarbageCollectorThread.run(GarbageCollectorThread.java:329)
2016-11-23 09:03:25,944 - INFO  - [main:BookieServer@167] - Shutting down BookieServer
2016-11-23 09:03:25,945 - INFO  - [main:BookieNettyServer@127] - Shutting down BookieNettyServer
2016-11-23 09:03:25,950 - INFO  - [New I/O worker #10:PerChannelBookieClient@701] - Disconnected from bookie channel [id: 0x7b660837, /127.0.0.1:48812 :> /127.0.0.1:13645]
2016-11-23 09:03:25,971 - INFO  - [main:Bookie@1096] - Shutting down Bookie-13645 with exitCode 0
2016-11-23 09:03:25,972 - INFO  - [main:Journal@970] - Shutting down Journal
2016-11-23 09:03:25,973 - ERROR - [ForceWriteThread:Journal$ForceWriteThread@433] - ForceWrite thread interrupted
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2048)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.bookkeeper.bookie.Journal$ForceWriteThread.run(Journal.java:393)
2016-11-23 09:03:25,974 - WARN  - [BookieJournal-13645:Journal@950] - Journal exits when shutting down
java.lang.InterruptedException
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.reportInterruptAfterWait(AbstractQueuedSynchronizer.java:2014)
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.await(AbstractQueuedSynchronizer.java:2048)
	at java.util.concurrent.LinkedBlockingQueue.take(LinkedBlockingQueue.java:442)
	at org.apache.bookkeeper.bookie.Journal.run(Journal.java:835)
2016-11-23 09:03:25,975 - INFO  - [BookieJournal-13645:Journal@959] - Journal exited loop!
```

This link contains more info:
https://builds.apache.org/job/bookkeeper-master-git-pullrequest/159/testReport/org.apache.bookkeeper.test/BookieClientTest/testWriteGaps/",2016-11-25 03:29:43,
BOOKKEEPER-976,"Fix license headers with ""Copyright 2016 The Apache Software Foundation""",Bug,1,Closed,6,,,2016-11-25 13:21:04,2017-08-14T06:51:31.000+0000,eolivelli,Enrico Olivelli,eolivelli,"Some files have wrong license headers. All of these files were auto-generated by my IDE. This JIRA applies the standard header

- SynchCallbackUtils
- ChannelManager
- NioServerSocketChannelManager
- VMLocalChannelManager
- NoSystemPropertiesConfigurationTest
- SystemPropertiesConfigurationTest",2016-11-25 13:21:04,
BOOKKEEPER-977,ReplicationWorker should choose bookies from cluster rather than using local bookie,Bug,1,Open,1,,,2016-11-28 19:39:26,2017-10-17T21:27:28.000+0000,hustlmsp,Sijie Guo,hustlmsp,"currently replication worker uses local address for the target address. it has two problems:

1) if autorecovery is running separately, it doesn't work
2) it will volatile the placement policy",2016-11-28 19:39:26,
BOOKKEEPER-978,PerChannelBookieClient logging is noisy,Bug,1,Resolved,5,Won't Do,2017-06-22 00:21:45,2016-11-28 19:53:25,2017-06-22T00:21:45.000+0000,hustlmsp,Sijie Guo,hustlmsp,The connecting logging is a bit noisy on PerChannelBookieClient.,2016-11-28 19:53:25,2017-06-22 00:21:45
BOOKKEEPER-979,Bookie recovery should skip replicating empty ledgers.,Bug,1,Open,1,,,2016-11-28 20:49:30,2017-10-17T21:27:25.000+0000,hustlmsp,Sijie Guo,hustlmsp,Skip replicating empty ledgers.,2016-11-28 20:49:30,
BOOKKEEPER-980,BookKeeper Tools doesn't process the argument correctly,Bug,1,Resolved,5,Fixed,2017-07-18 08:48:50,2016-11-29 18:44:28,2017-07-18T08:48:50.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,"- IndexOutOfBoundException when not provide the dest bookie
- The tool ignored the dest bookie when provide the dest bookie",2016-11-29 18:44:28,2017-07-18 08:48:50
BOOKKEEPER-982,"Open a Ticket for ""Who is using Bookkeeper""",Bug,1,Open,1,,,2016-12-07 11:25:57,2017-10-17T21:27:22.000+0000,zhaijia,Jia Zhai,zhaijia,"As discussed, would like to create an always open issue ""who is using Bookkeeper"" on github.

Here is some example of other project:
[https://github.com/alibaba/RocketMQ/issues/1] 
[https://github.com/mgechev/angular-seed/issues/855]
[https://github.com/labstack/echo/issues/295]",2016-12-07 11:25:57,
BOOKKEEPER-983,BookieShell Command for LedgerDelete,New Feature,2,Resolved,5,Fixed,2016-12-21 00:45:07,2016-12-09 23:22:54,2016-12-21T13:12:02.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,BookieShell Command for LedgerDelete,2016-12-09 23:22:54,2016-12-21 00:45:07
BOOKKEEPER-984, BookieClientTest.testWriteGaps tested,Bug,1,Resolved,5,Fixed,2016-12-17 01:39:58,2016-12-10 00:38:26,2016-12-17T12:49:41.000+0000,hustlmsp,Sijie Guo,hustlmsp,This test is failed.,2016-12-10 00:38:26,2016-12-17 01:39:58
BOOKKEEPER-985,change the bookieServer cmdline to pass any configuration property and system properties,Improvement,4,Open,1,,,2016-12-13 10:08:08,2017-10-17T21:27:18.000+0000,,,,"with  BOOKKEEPER-966 we have a better way to pass options from the command line.
A further enhancement will be to let the user pass any other configuration option and system property from the command line.
Something like
{code}
BookeServer -x option1=value1 -x option2=value2 -Djava.security.auth.login.config=jaas.conf
{code}

This change will enable to support new properties without changing the code of the CLI
",2016-12-13 10:08:08,
BOOKKEEPER-986,Handle Memtable flush failure,Bug,1,Resolved,5,Fixed,2016-12-21 00:49:22,2016-12-13 19:21:17,2016-12-21T13:12:03.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,"Consider the following scenario
 - currently bookie is in writemode but it is close to the diskusagethreshold and also entrymemtable is close to skipListSizeLimit
 - it received a addentry call, and now the size of the entrymemtable is greater than skipListSizeLimit
 - so onSizeLimitReached of SortedLedgerStorage will be called and now lets assume that memtable flush has failed because of diskusagethreshold 
 - because of previous step, bookie would turn to readonly
 - now lets assume after certain rounds of compaction bookie reclaimed sufficient storage and went back to writemode
 - now bookie would be receiving addentry calls
 - because of outstanding snapshot from previous memtable flush failure, it will never retry to flush memtable 
 - now the memory start keep going up and up and the process memory gets bloated",2016-12-13 19:21:17,2016-12-21 00:49:22
BOOKKEEPER-987,BookKeeper build is broken due to the shade plugin for commit ecbb053e6e,Bug,1,Resolved,5,Fixed,2016-12-17 01:40:35,2016-12-16 16:07:26,2016-12-17T12:49:42.000+0000,eolivelli,Enrico Olivelli,eolivelli,"Step to reproduce:
- clone BookKeeper repository from GitHub
- checkout master (or at least commit ecbb053e6e873859507e247cae727f4bc8b9f7fa)
- mvn clean install -DskipTests -X

The fix is to upgrade the shade plugin to the latest version (2.4.3)

this is the error
{code}
[INFO] Excluding log4j:log4j:jar:1.2.15 from the shaded jar.
[INFO] Minimizing jar org.apache.bookkeeper:bookkeeper-server:jar:4.5.0-SNAPSHOT
[INFO] ------------------------------------------------------------------------
[INFO] Reactor Summary:
[INFO] 
[INFO] bookkeeper ......................................... SUCCESS [  0.428 s]
[INFO] compability dependencies ........................... SUCCESS [  0.016 s]
[INFO] bookkeeper-server-compat400 ........................ SUCCESS [  2.772 s]
[INFO] bookkeeper-server-compat410 ........................ SUCCESS [  1.159 s]
[INFO] bookkeeper-server-compat420 ........................ SUCCESS [  1.370 s]
[INFO] Stats API for bookkeeper ........................... SUCCESS [  0.422 s]
[INFO] bookkeeper-server .................................. FAILURE [  4.002 s]
[INFO] bookkeeper-benchmark ............................... SKIPPED
[INFO] Stats provider for twitter-stats package ........... SKIPPED
[INFO] Stats provider for twitter-ostrich package ......... SKIPPED
[INFO] Stats provider for codahale metrics ................ SKIPPED
[INFO] bookkeeper-stats-providers ......................... SKIPPED
[INFO] ------------------------------------------------------------------------
[INFO] BUILD FAILURE
[INFO] ------------------------------------------------------------------------
[INFO] Total time: 10.328 s
[INFO] Finished at: 2016-12-16T17:06:08+01:00
[INFO] Final Memory: 46M/998M
[INFO] ------------------------------------------------------------------------
[ERROR] Failed to execute goal org.apache.maven.plugins:maven-shade-plugin:2.1:shade (default) on project bookkeeper-server: Error creating shaded jar: 46848 -> [Help 1]
org.apache.maven.lifecycle.LifecycleExecutionException: Failed to execute goal org.apache.maven.plugins:maven-shade-plugin:2.1:shade (default) on project bookkeeper-server: Error creating shaded jar: 46848
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:212)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:307)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:193)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:106)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:863)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:288)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)
Caused by: org.apache.maven.plugin.MojoExecutionException: Error creating shaded jar: 46848
	at org.apache.maven.plugins.shade.mojo.ShadeMojo.execute(ShadeMojo.java:528)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:134)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:207)
	... 20 more
Caused by: java.lang.ArrayIndexOutOfBoundsException: 46848
	at org.objectweb.asm.ClassReader.readClass(Unknown Source)
	at org.objectweb.asm.ClassReader.accept(Unknown Source)
	at org.objectweb.asm.ClassReader.accept(Unknown Source)
	at org.vafer.jdependency.Clazzpath.addClazzpathUnit(Clazzpath.java:94)
	at org.apache.maven.plugins.shade.filter.MinijarFilter.<init>(MinijarFilter.java:77)
	at org.apache.maven.plugins.shade.mojo.ShadeMojo.getFilters(ShadeMojo.java:767)
	at org.apache.maven.plugins.shade.mojo.ShadeMojo.execute(ShadeMojo.java:445)
	... 22 more

{code}",2016-12-16 16:07:26,2016-12-17 01:40:35
BOOKKEEPER-988,Missing license headers,Bug,1,Resolved,5,Fixed,2016-12-20 21:43:26,2016-12-18 16:21:23,2016-12-21T13:12:05.000+0000,hustlmsp,Sijie Guo,hustlmsp,"The recent commit failed the apache-rat:check, due to two new files missing license headers.

{code}
commit 4bb57ef0b1b72eb1118963efc3ab9f0e9bec0e1c
Author: Charan Reddy Guttapalem <cguttapalem@salesforce.com>
Date:   Fri Dec 16 17:42:18 2016 -0800

    BOOKKEEPER-967: New testsuite for RackPlacement
{code}",2016-12-18 16:21:23,2016-12-20 21:43:26
BOOKKEEPER-989,Enable travis CI for bookkeeper git,Bug,1,Resolved,5,Fixed,2017-06-01 21:00:00,2016-12-20 22:00:51,2017-06-02T16:42:30.000+0000,hustlmsp,Sijie Guo,hustlmsp,Let's enable travis build for bookkeeper project.,2016-12-20 22:00:51,2017-06-01 21:00:00
BOOKKEEPER-990,The merge pr script should handle new review comments,Bug,1,Open,1,,,2016-12-20 22:02:09,2017-10-17T21:27:15.000+0000,hustlmsp,Sijie Guo,hustlmsp,Current pr script only works github comments but doesn't work with the new github review comments. We need to improve the script to support it.,2016-12-20 22:02:09,
BOOKKEEPER-991,bk shell - Get a list of all on disk files,New Feature,2,Resolved,5,Fixed,2017-01-11 06:38:09,2016-12-28 21:41:52,2017-01-11T13:13:06.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,"BK saves the contents in multiple on disk files, journals, entrylog, and index files.

We need a way to list all these files in chronology order, so these files can be given as input to other shell operations like ReadJournalCmd.",2016-12-28 21:41:52,2017-01-11 06:38:09
BOOKKEEPER-992,ReadLog Command Enhancement,New Feature,2,Resolved,5,Fixed,2017-07-25 00:23:33,2016-12-29 00:49:08,2017-07-25T00:23:33.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,"- Take arguments lid and eid and prints just that entry
- Take arguments of position range and print entries
which are located in that position range",2016-12-29 00:49:08,2017-07-25 00:23:33
BOOKKEEPER-995,Implement guaranteed writes to specified number of racks,New Feature,2,Open,1,,,2017-01-26 00:26:55,2017-10-17T21:33:26.000+0000,rithin.shetty,Rithin Shetty,rithin.shetty,With rackaware ensemble placement we get guaranteed writes to at least 2 different racks for every write quorum. We want to extend this such that user can ask for writes to at least 3 or more racks per write quorum. This is useful to ensure higher availability when one of the racks is already down: the remaining copies are guaranteed to be on different racks and hence can with stand another rack failure assuming the write quorum is 3.,2017-01-26 00:26:55,
BOOKKEEPER-996,Apache Rat Check Failures,Task,3,Resolved,5,Fixed,2017-01-31 21:45:49,2017-01-31 03:01:10,2017-02-01T13:14:29.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,"{code}
[ERROR] Failed to execute goal org.apache.rat:apache-rat-plugin:0.7:check (default-cli) on project bookkeeper-server: Too many unapproved licenses: 1 -> [Help 1]
[ERROR] 
[ERROR] To see the full stack trace of the errors, re-run Maven with the -e switch.
[ERROR] Re-run Maven using the -X switch to enable full debug logging.
[ERROR] 
{code}",2017-01-31 03:01:10,2017-01-31 21:45:49
BOOKKEEPER-997,Wire protocol change for supporting long poll,Sub-task,7,Resolved,5,Fixed,2017-04-11 18:20:43,2017-01-31 22:14:07,2017-04-12T13:40:00.000+0000,robindhamankar,Robin Dhamankar,robindhamankar,"In order to support piggybacking lac and long poll, there will be changes to new fields added to the wire protocol.",2017-01-31 22:14:07,2017-04-11 18:20:43
BOOKKEEPER-998,Increased the max entry size to 5MB,Improvement,4,Resolved,5,Fixed,2017-03-22 23:48:21,2017-02-06 22:27:44,2017-03-23T13:18:40.000+0000,revans2,Robert Joseph Evans,revans2,"In practice we have found the Bookkeeper can handle 5MB entries without issue.  We should make the {{PerChannelBookieClient.MAX_FRAME_LENGTH}}, the {{BookieNettyServer.maxMessageSize}} and the {{EntryLogger.MAX_SANE_ENTRY_SIZE}} size all consistent with one another, and ideally 5MB.",2017-02-06 22:27:44,2017-03-22 23:48:21
BOOKKEEPER-999,BookKeeper client can leak threads,Bug,1,Resolved,5,Fixed,2017-03-22 23:52:02,2017-02-08 14:44:49,2017-03-23T13:18:44.000+0000,revans2,Robert Joseph Evans,revans2,"The client constructor

{{BookKeeper(ClientConfiguration conf, ZooKeeper zk)}}

in 4.4 and above will create a new NioClientSocketChannelFactory but does not set the ownership of that factory to true so threads are leaked.

This showed up as a failure in BookieRecoveryTest on MacOS where it has a hard coded limit of about 2000 threads in a single process, and this test was going beyond that.",2017-02-08 14:44:49,2017-03-22 23:52:02
BOOKKEEPER-1000,BookieRecoveryTest.ensurePasswordUsedForOldLedgers failing,Bug,1,Open,1,,,2017-02-08 16:13:42,2017-10-17T21:33:23.000+0000,knusbaum,Kyle Nusbaum,knusbaum,"Tests in error:
  BookieRecoveryTest.ensurePasswordUsedForOldLedgers[4]  BKNoSuchLedgerExists
  BookieRecoveryTest.ensurePasswordUsedForOldLedgers[5]  BKNoSuchLedgerExists

This has been happening in master recently both in Jenkins and on my Mac.  I'll try to take a look at it.",2017-02-08 16:13:42,
BOOKKEEPER-1001,Make LocalBookiesRegistry.isLocalBookie() public,Improvement,4,Resolved,5,Fixed,2017-03-23 14:58:19,2017-02-10 10:31:48,2017-03-24T13:19:57.000+0000,,,,"This function is useful for applications using an embedded local bookie, for example in order to create a custom EnsamblePlacementPolicy which prefers the local bookie if present.

This is an easy fix, I will file a PR.",2017-02-10 10:31:48,2017-03-23 14:58:19
BOOKKEEPER-1002,BookieRecoveryTest can run out of file descriptors,Improvement,4,Resolved,5,Fixed,2017-04-11 18:18:02,2017-02-10 17:03:06,2017-04-11T18:18:02.000+0000,kishorvpatil,Kishor Patil,kishorvpatil,We should limit the number of open files during the test to avoid hitting a ulimit on some test hardware.,2017-02-10 17:03:06,2017-04-11 18:18:02
BOOKKEEPER-1003,Fix TestDiskChecker so it can be used on /dev/shm,Improvement,4,Resolved,5,Fixed,2017-03-22 23:54:53,2017-02-10 17:16:13,2017-03-23T13:18:48.000+0000,kishorvpatil,Kishor Patil,kishorvpatil,"Some file systems don't report disk usage by byte (but by block) /dev/shm is one of these.

We should update the tests to be more lenient.",2017-02-10 17:16:13,2017-03-22 23:54:53
BOOKKEEPER-1004,Allow bookie garbage collection to be triggered manually from tests,Improvement,4,Resolved,5,Fixed,2017-03-28 20:39:34,2017-02-13 23:15:45,2017-03-29T14:17:29.000+0000,,,,"The current gc tests rely on waiting on a timeout for gc to run. It's
never certain whether it has run or not or if it's still running. 

This patch allows tests to trigger a gc run and gives the client
a future to know when it has completed. The gc algorithm is unchangedI but now it runs in a scheduled executor rather than as a
Thread.

This work was originally done by Ivan Kelly and I am just pushing it back to open source",2017-02-13 23:15:45,2017-03-28 20:39:34
BOOKKEEPER-1005,make MajorCompaction and MinorCompactions controlled by at least time of the day/day of the week,New Feature,2,Open,1,,,2017-02-14 02:35:30,2017-10-17T21:27:10.000+0000,,,,"MajorCompaction and Minor Compactions are strictly frequency based.
They should be at least time of the day based.

Ideally we should run longer compactions during low system load in background, and if the system load raises, reduce the compaction depending on the disk availability.
Simpler first step would be to schedule ""deeper"" compaction at the times of the day/days of the week with typically lower load. 
i.e. set major compaction threshold to 0.4 normally, 0.6 at night/weekdays and 0.8 at night/Saturday.
",2017-02-14 02:35:30,
BOOKKEEPER-1006,Remove Bookie global ZK Instance,Improvement,4,Open,1,,,2017-02-14 21:20:23,2017-10-17T21:33:19.000+0000,gmenon,Govind Menon,govindmenon,"Bookie has had a Zookeeper client for the whole process up to now. This
is only ever used in garbage collection though. This change moves the
creation and usage of the zookeeper client to the garbage collection
thread. It now creates a new zookeeper client for each GC iteration, and
tears it down afterwards. This means that if there is a problem with the
zookeeper connection, it will only exist for one iteration of garbage
 collection.

This work was originally done by Ivan Kelly and I am just pushing it back to open source
",2017-02-14 21:20:23,
BOOKKEEPER-1007,Explicit LAC: make the interval configurable in milliseconds instead of seconds,Improvement,4,Resolved,5,Fixed,2017-03-23 00:00:09,2017-02-16 12:16:36,2017-03-23T13:18:51.000+0000,eolivelli,Enrico Olivelli,eolivelli,"in BOOKKEEPER-874 we introduced the ""Explicit LAC"", but the interval is configurable in ""seconds"", and I need to achieve sub-second latency.

So my proposal is to make it configurable in ""milliseconds"", since 4.5.0 has not yet been released I think it is better to change it as soon as possible",2017-02-16 12:16:36,2017-03-23 00:00:09
BOOKKEEPER-1008,Move to netty4,Improvement,4,Resolved,5,Fixed,2017-05-15 17:56:12,2017-02-22 16:38:22,2017-05-16T13:36:11.000+0000,mmerli,Matteo Merli,mmerli,"As part of the Yahoo push back and in general we would like to move to netty 4, preferably netty 4.1.x for the client and server communication.

This lays the ground work for zero copy, or very nearly zero copy handling on the server side.",2017-02-22 16:38:22,2017-05-15 17:56:12
BOOKKEEPER-1010,Bump up Guava version to 20.0,Improvement,4,Resolved,5,Fixed,2017-05-26 14:53:13,2017-03-16 17:58:01,2017-05-27T13:48:54.000+0000,eolivelli,Enrico Olivelli,eolivelli,"Currently bookkeeper is using Guava 13.0. Guava has moved forward and at version 20.0 there are some API changes.
This becomes an issue if a project using Guava 20.0 tries to run bookie server inproc. Bumping the Guava version to 20.0 will fix that issue.",2017-03-16 17:58:01,2017-05-26 14:53:13
BOOKKEEPER-1011,Clean up internal Bookkeeper constructors,Improvement,4,Open,1,,,2017-03-20 15:29:25,2017-10-17T21:27:06.000+0000,,,,"One of the feedbacks from 

https://github.com/apache/bookkeeper/pull/105#issuecomment-287787603

was that there are some customer APIs that need to be cleaned up.  This is specifically for the two constructors in Bookkeeper

{code}
public BookKeeper(ClientConfiguration conf, ZooKeeper zk);
public BookKeeper(ClientConfiguration conf, ZooKeeper zk, ClientSocketChannelFactory channelFactory);
{code}

That are really for internal use only.  We should find a way to mark them as such.

",2017-03-20 15:29:25,
BOOKKEEPER-1013,Fix findbugs errors on latest master,Bug,1,Resolved,5,Fixed,2017-03-23 14:55:25,2017-03-23 03:06:29,2017-03-24T14:07:06.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,"The multiple journal dirs change and explict-lac change introduced a few findbug errors.

{code}
[INFO] BugInstance size is 8
[INFO] Error size is 0
[INFO] Total bugs: 8
[INFO] org.apache.bookkeeper.bookie.CheckpointSourceList$CheckpointList defines compareTo(Object) and uses Object.equals() [org.apache.bookkeeper.bookie.CheckpointSourceList$CheckpointList] At CheckpointSourceList.java:[line 53] EQ_COMPARETO_USE_OBJECT_EQUALS
[INFO] Dead store to ledgerId in org.apache.bookkeeper.bookie.FileInfo.setExplicitLac(ByteBuffer) [org.apache.bookkeeper.bookie.FileInfo] At FileInfo.java:[line 140] DLS_DEAD_LOCAL_STORE
[INFO] Inconsistent synchronization of org.apache.bookkeeper.bookie.FileInfo.explicitLac; locked 85% of time [org.apache.bookkeeper.bookie.FileInfo, org.apache.bookkeeper.bookie.FileInfo, org.apache.bookkeeper.bookie.FileInfo, org.apache.bookkeeper.bookie.FileInfo, org.apache.bookkeeper.bookie.FileInfo, org.apache.bookkeeper.bookie.FileInfo, org.apache.bookkeeper.bookie.FileInfo, org.apache.bookkeeper.bookie.FileInfo, org.apache.bookkeeper.bookie.FileInfo, org.apache.bookkeeper.bookie.FileInfo, org.apache.bookkeeper.bookie.FileInfo, org.apache.bookkeeper.bookie.FileInfo, org.apache.bookkeeper.bookie.FileInfo, org.apache.bookkeeper.bookie.FileInfo] Unsynchronized access at FileInfo.java:[line 118]Unsynchronized access at FileInfo.java:[line 145]Synchronized access at FileInfo.java:[line 121]Synchronized access at FileInfo.java:[line 122]Synchronized access at FileInfo.java:[line 123]Synchronized access at FileInfo.java:[line 124]Synchronized access at FileInfo.java:[line 125]Synchronized access at FileInfo.java:[line 134]Synchronized access at FileInfo.java:[line 137]Synchronized access at FileInfo.java:[line 138]Synchronized access at FileInfo.java:[line 140]Synchronized access at FileInfo.java:[line 135]Synchronized access at FileInfo.java:[line 141]Synchronized access at FileInfo.java:[line 143] IS2_INCONSISTENT_SYNC
[INFO] Inconsistent synchronization of org.apache.bookkeeper.client.LedgerHandle.length; locked 90% of time [org.apache.bookkeeper.client.ReadOnlyLedgerHandle$MetadataUpdater, org.apache.bookkeeper.client.LedgerHandle, org.apache.bookkeeper.client.LedgerHandle, org.apache.bookkeeper.client.LedgerHandle, org.apache.bookkeeper.client.LedgerHandle, org.apache.bookkeeper.client.LedgerHandle, org.apache.bookkeeper.client.LedgerHandle, org.apache.bookkeeper.client.LedgerHandle, org.apache.bookkeeper.client.LedgerHandle, org.apache.bookkeeper.client.LedgerRecoveryOp, org.apache.bookkeeper.client.LedgerHandle$2] Unsynchronized access at ReadOnlyLedgerHandle.java:[line 59]Synchronized access at LedgerHandle.java:[line 259]Synchronized access at LedgerHandle.java:[line 777]Synchronized access at LedgerHandle.java:[line 777]Synchronized access at LedgerHandle.java:[line 1360]Synchronized access at LedgerHandle.java:[line 249]Synchronized access at LedgerHandle.java:[line 249]Synchronized access at LedgerHandle.java:[line 250]Synchronized access at LedgerHandle.java:[line 976]Synchronized access at LedgerRecoveryOp.java:[line 151]Synchronized access at LedgerHandle.java:[line 379] IS2_INCONSISTENT_SYNC
[INFO] Redundant nullcheck of journalDirNames, which is known to be non-null in org.apache.bookkeeper.conf.ServerConfiguration.getJournalDirs() [org.apache.bookkeeper.conf.ServerConfiguration] Redundant null check at ServerConfiguration.java:[line 631] RCN_REDUNDANT_NULLCHECK_OF_NONNULL_VALUE
[INFO] Argument of type String[] formatted in useless way in org.apache.bookkeeper.proto.BookieServer.main(String[]) [org.apache.bookkeeper.proto.BookieServer] At BookieServer.java:[line 420] VA_FORMAT_STRING_BAD_CONVERSION_FROM_ARRAY
[INFO] Dead store to entrySize in org.apache.bookkeeper.proto.PerChannelBookieClient.writeLac(long, byte[], long, ChannelBuffer, BookkeeperInternalCallbacks$WriteLacCallback, Object) [org.apache.bookkeeper.proto.PerChannelBookieClient] At PerChannelBookieClient.java:[line 390] DLS_DEAD_LOCAL_STORE
[INFO] Futile attempt to change max pool size of ScheduledThreadPoolExecutor in new org.apache.bookkeeper.util.OrderedSafeExecutor(String, int, ThreadFactory, StatsLogger, boolean, long) [org.apache.bookkeeper.util.OrderedSafeExecutor] At OrderedSafeExecutor.java:[line 186] DMI_FUTILE_ATTEMPT_TO_CHANGE_MAXPOOL_SIZE_OF_SCHEDULED_THREAD_POOL_EXECUTOR
[INFO]

{code}",2017-03-23 03:06:29,2017-03-23 14:55:25
BOOKKEEPER-1017,Create documentation for ZooKeeper ACLs,Sub-task,7,Resolved,5,Fixed,2017-07-28 00:05:31,2017-03-24 11:26:35,2017-07-28T00:05:31.000+0000,eolivelli,Enrico Olivelli,eolivelli,,2017-03-24 11:26:35,2017-07-28 00:05:31
BOOKKEEPER-1018,Allow client to select older V2 protocol (no protobuf),Bug,1,Resolved,5,Fixed,2017-04-03 19:34:09,2017-03-27 19:13:25,2017-04-15T12:58:10.000+0000,gmenon,Govind Menon,govindmenon,Oriignally done by Matteo Merli,2017-03-27 19:13:25,2017-04-03 19:34:09
BOOKKEEPER-1019,Support for reading entries after LAC (causal consistency driven by out-of-band communications),New Feature,2,Resolved,5,Fixed,2017-05-22 14:54:57,2017-03-28 14:21:08,2017-05-22T14:54:57.000+0000,eolivelli,Enrico Olivelli,eolivelli,"Currently we check in  asyncReadEntries that the range of entries is within the range 0....LastAddConfirmed.

This is because the LAC guarantees that the client can read only entries that have been acked from the writer.
The LAC protocol is very useful when there is not direct communication between ""writers"" and ""readers"".

I have an use case in which the ""writer"" blocks until the write is acked (like addEntry) and then it takes the returned id (ledgerId + entryid) and passes it to a ""reader"" which in turn tries to read the entry.

This communication is done out-of-band in respect to BookKeeper and we can assume that the entries has been stored in a durable way (the write as been acked by a quorum of bookies).
As the 'reader' as received a confirmation the the writer as successifully written the entry it can read it without waiting for the piggyback of the LAC of the standard bookkeeper protocol.
This is the normal way of working with transactional databases or with filesystems.

This is kind of ""causal consistency"".

The idea is to add a configuration option to relax the check in asyncreadEntries

this is 4.4 version:
{code}
        if (lastEntry > lastAddConfirmed) {
            LOG.error(""ReadException on ledgerId:{} firstEntry:{} lastEntry:{}"",
                    new Object[] { ledgerId, firstEntry, lastEntry });
            cb.readComplete(BKException.Code.ReadException, this, null, ctx);
            return;
        }
{code}

this is my proposal:
{code}
        if (lastEntry > lastAddConfirmed && !allowReadingAfterLastAddConfirmed) {
            LOG.error(""ReadException on ledgerId:{} firstEntry:{} lastEntry:{}"",
                    new Object[] { ledgerId, firstEntry, lastEntry });
            cb.readComplete(BKException.Code.ReadException, this, null, ctx);
            return;
        }
{code}
",2017-03-28 14:21:08,2017-05-22 14:54:57
BOOKKEEPER-1020,Fix Explicit LAC tests on master,Bug,1,Resolved,5,Fixed,2017-04-03 16:58:39,2017-04-01 07:35:54,2017-04-04T13:38:26.000+0000,eolivelli,Enrico Olivelli,eolivelli,"Tests in error: 
  BookKeeperTest.testReadHandleWithExplicitLAC:404  TestTimedOut test timed out...
  BookKeeperTest.testReadHandleWithExplicitLAC:404  TestTimedOut test timed out...",2017-04-01 07:35:54,2017-04-03 16:58:39
BOOKKEEPER-1021,Improve the merge script to handle github reviews api,Bug,1,Resolved,5,Fixed,2017-05-26 12:53:23,2017-04-03 19:13:59,2017-05-26T16:56:53.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,"Current script doesn't handle the new reviews API. 

We need to improve the merge script to handle the new review API.

https://developer.github.com/v3/pulls/reviews/

We can do similar thing like what DistributedLog is doing.

https://github.com/apache/incubator-distributedlog/blob/master/scripts/dev/dl-merge-pr.py",2017-04-03 19:13:59,2017-05-26 12:53:23
BOOKKEEPER-1022,Make BookKeeperAdmin implement AutoCloseable,Improvement,4,Resolved,5,Fixed,2017-04-11 18:19:38,2017-04-06 12:30:39,2017-04-12T13:39:56.000+0000,eolivelli,Enrico Olivelli,eolivelli,as BookKeeper and LedgerHandler are AutoCloseable it would be good to make BookKeeperAdmin AutoCloseable too,2017-04-06 12:30:39,2017-04-11 18:19:38
BOOKKEEPER-1023,AutoRecovery bug fixes and improvements,Story,16,Resolved,5,Done,2017-10-06 09:02:39,2017-04-06 22:31:32,2017-10-06T09:02:39.000+0000,,,,"This is the master ticket to track all the bug fixes and improvements that made to bookkeeper auto recovery, also discuss the architecture changes.",2017-04-06 22:31:32,2017-10-06 09:02:39
BOOKKEEPER-1025,Release underreplicated lock after errors,Sub-task,7,Open,1,,,2017-04-06 23:14:56,2017-10-17T21:27:02.000+0000,,,,"There are some conditions in which the replication lock on some ledger is not being released, requiring manual intervention to bounce the replication work to let some other continue.

https://github.com/yahoo/bookkeeper/commit/850122ed56b9c3706cb44cce9f27989125b76e3a",2017-04-06 23:14:56,
BOOKKEEPER-1026,Ignore deleted ledgers,Sub-task,7,Open,1,,,2017-04-06 23:17:24,2017-10-17T21:26:59.000+0000,,,,"There is some corner case in which deleted ledgers are failing to get replicated, while they should just be ignored.

https://github.com/yahoo/bookkeeper/commit/56a0947e0c4ae902468abc4a96e5842a7a0aee9b",2017-04-06 23:17:24,
BOOKKEEPER-1027,Cleanup main README and main website page,Task,3,Resolved,5,Fixed,2017-07-20 15:24:14,2017-04-07 15:18:49,2017-07-20T15:24:14.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,"README file is really out-of date, it references Java6 and Hedwig

we should update it as it is one of the first descriptions of the project for new developers which are evaluating BookKeeper",2017-04-07 15:18:49,2017-07-20 15:24:14
BOOKKEEPER-1028,inc/excl opts listunderreplicate,New Feature,2,Resolved,5,Done,2017-10-09 09:10:03,2017-04-08 04:11:08,2017-10-09T09:10:03.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,"- Introduce including and excluding BookieId options
    for listunderreplicatedLedgers",2017-04-08 04:11:08,2017-10-09 09:10:03
BOOKKEEPER-1029,BookieDecommision Workflow,New Feature,2,Resolved,5,Fixed,2017-10-06 08:45:38,2017-04-08 05:00:49,2017-10-17T21:26:56.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,"- LostBookieRecoveryDelay config param is stored in ZK
    - if LostBookieRecoveryDelay is reset to same value then it force triggers audit immediately
    - Added logic to trigger immediately or schedule pending audittask depending on the changed value in ZK
    - good number of testcases validating focetrigger/reschedluing audittask
    - added bookieshell command to get/set LostBookieRecoveryDelay from ZK
    - added bookieshell command to triggeraudit by resetting LostBookieRecoveryDelay
    - added decommissionbookie bkshell command, which validates the complete replication of ledgers stored in the bookie",2017-04-08 05:00:49,2017-10-06 08:45:38
BOOKKEEPER-1030,Better management of OutOfMemory errors,Wish,5,Open,1,,,2017-04-10 08:16:08,2017-10-17T21:26:53.000+0000,eolivelli,Enrico Olivelli,eolivelli,"Some bookie in production run OutOfMemory and the Bookie became really unstable.

17-01-24-13-11-42 Unexpected exception while writing 0@91465 :
17-01-24-13-11-42 java.lang.OutOfMemoryError: Java heap space

That error was inside ""WriteEntryProcessorV3"" class in a catch (Throwable ) clause.

I'm running the Bookie inside a Java process not started with the ""standard"" scripts.

My idea to handle this kind of errors is to add a global ""System errors handler"" to attach to any critical thread/operation and to pass any uncatched exception to it.
In case of existing ""catch Throwable"" the code will call the system handler as well.

Maybe we can provide a default implementation which only logs the error to the logger, a more invasive implementation which calls Runtime#halt.

I'm trying in production with ExitOnOutOfMemoryError option but it does not give any chance to report the status of the JVM",2017-04-10 08:16:08,
BOOKKEEPER-1031,ReplicationWorker.rereplicate fails to call close() on ReadOnlyLedgerHandle,Bug,1,Resolved,5,Fixed,2017-04-11 18:14:35,2017-04-10 18:57:06,2017-04-12T13:39:54.000+0000,sjust2,Samuel Just,sjust2,This has the effect of permanently adding 1 listener per call into AbstractZkLedgerManager.listenerSet,2017-04-10 18:57:06,2017-04-11 18:14:35
BOOKKEEPER-1032,Hedwig link on homepage is broken,Bug,1,Resolved,5,Won't Do,2017-06-22 00:38:03,2017-04-11 19:19:25,2017-06-22T00:38:03.000+0000,,,,The link to the HedWig wiki on https://bookkeeper.apache.org leads to a deleted page.,2017-04-11 19:19:25,2017-06-22 00:38:03
BOOKKEEPER-1033,Handle DirsPartitionDuplication,New Feature,2,Open,1,,,2017-04-11 23:07:03,2017-10-17T21:26:50.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,"- Provide configuration for allowDirsPartitionDuplication
- while calculating total disk metrics account Partition Duplication",2017-04-11 23:07:03,
BOOKKEEPER-1034,"When all disks are full, start Bookie in RO mode if RO mode is enabled ",New Feature,2,Resolved,5,Fixed,2017-06-28 21:24:22,2017-04-12 00:19:16,2017-06-28T21:24:22.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,"- When all disks are full start Bookie in RO mode if RO mode is enabled
- This will work only if ""isForceGCAllowWhenNoSpace"" is allowed, since LedgerDirsManager.getWritableLedgerDirsForNewLog will be able to find new writableLedgerDir even when all disks are full.
- If bookie has died abruptly then it may have missed flushing EntryMemtable and
IndexInMemoryPageManager. So next time when it starts when disc is full
it fails to create index file and it shuts down. So Bookie should be able to create index file though it has reached the diskusagethreshold, while starting the Bookie in Readonly Mode. But ofcourse there should be some config to safeguard when disk usable space is so low.",2017-04-12 00:19:16,2017-06-28 21:24:22
BOOKKEEPER-1035,Add Enrico Olivelli to commiters list on website,Task,3,Resolved,5,Fixed,2017-04-26 10:26:10,2017-04-12 19:35:42,2017-04-26T10:26:10.000+0000,eolivelli,Enrico Olivelli,eolivelli,,2017-04-12 19:35:42,2017-04-26 10:26:10
BOOKKEEPER-1036,Add Charan Reddy to commiters list on website,Task,3,Resolved,5,Done,2017-10-09 09:09:32,2017-04-12 19:36:33,2017-10-09T09:09:32.000+0000,hustlmsp,Sijie Guo,hustlmsp,,2017-04-12 19:36:33,2017-10-09 09:09:32
BOOKKEEPER-1038,Fix findbugs warnings and upgrade to 3.0.4,Task,3,Resolved,5,Fixed,2017-04-20 17:55:33,2017-04-15 12:13:18,2017-04-21T13:38:51.000+0000,eolivelli,Enrico Olivelli,eolivelli,"This findbugs errors are on master, they have to be fixed
{code}
INFO] --- findbugs-maven-plugin:3.0.3:check (default-cli) @ bookkeeper-server ---
[INFO] BugInstance size is 2
[INFO] Error size is 0
[INFO] Total bugs: 2
[INFO] Dead store to requested in org.apache.bookkeeper.client.BookieInfoReader.getReadWriteBookieInfo(Collection) [org.apache.bookkeeper.client.BookieInfoReader] At BookieInfoReader.java:[line 166] DLS_DEAD_LOCAL_STORE
[INFO] org.apache.bookkeeper.proto.PerChannelBookieClient$V2CompletionKey overrides equals in PerChannelBookieClient$CompletionKey and may not be symmetric [org.apache.bookkeeper.proto.PerChannelBookieClient$V2CompletionKey] At PerChannelBookieClient.java:[lines 1720-1724] EQ_OVERRIDING_EQUALS_NOT_SYMMETRIC
[INFO] 
{code}",2017-04-15 12:13:18,2017-04-20 17:55:33
BOOKKEEPER-1039,bk-merge-pr.py ask to run findbugs and rat before merge,Improvement,4,Resolved,5,Fixed,2017-04-18 17:59:49,2017-04-18 15:16:01,2017-04-19T13:37:53.000+0000,eolivelli,Enrico Olivelli,eolivelli,"The bk-merge-pr.py script currently asks for running ""mvn clean install"".

The full test suite is very slow.
Many times we are merging patches which break findbugs and rat check

I would like to add a step like
""Do you want to validate findbugs and rat after the merge? (y/n)""
",2017-04-18 15:16:01,2017-04-18 17:59:49
BOOKKEEPER-1040,Use separate log for compaction,Bug,1,Patch Available,10002,,,2017-04-20 05:45:10,2022-05-11T22:22:32.000+0000,yzang,Yiming Zang,yzang,"1. Bookkeeper is not able to reclaim disk space when it's full
If all disks are full or almost full, both major and minor compactions would be suspended, and only GC will be running. In the current design, this is the right thing to do, because when disks are full, EntryLogger can not allocate any new entry logs any more, and apart from that,  the intention is to prevent disk usage from keep growing.
However, the problem is if we have a mixed of short-lived ledgers and long-lived ledgers in all entry logs, when disks are full, GC wouldn't be able to delete any entry logs, and if compaction is disabled, bookie can't reclaim any disk space any more by itself.

2. Compaction might keep generating duplicated data which would cause disk full
Currently, there's no transactional operation for compaction. In the current CompactionScannerFactory, if it fails to flush entry log file, or fails to flush ledgerCache, the data which is already flushed wouldn't be deleted, and the entry log that is being compacted will be retried again for the next time, which would generate duplicated data.
Moreover, if the entry log being compacted has long-lived data and the compaction keeps failing for some reason(e.g. corrupted entry, corrupted index), it would cause the BK disk usage keep growing until the either the entry log can be garbage collected, or disk full.
",2017-04-20 05:45:10,
BOOKKEEPER-1041,Multiple active entrylogs,Improvement,4,Open,1,,,2017-04-20 06:05:56,2017-10-17T21:26:43.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,"Current bookkeeper is tuned for rotational HDDs. It has one active entrylog, and all the ledger/entries go to the same entrylog until it is rotated out. This is perfect for HDDs as seeks and moving head allover the disk platter is very expensive. But this is very inefficient for SSDs, as each SSD can handle multiple parallel writers, also this method is extremely inefficient for compaction as it causes write amplification and inefficient disk space usage.

Our proposal is to have multiple active entrylogs and a configuration param on how many parallel entrylogs the system can have. This way one can have ability to configure to have less (may be  one) ledger per entrylog.",2017-04-20 06:05:56,
BOOKKEEPER-1042,Deploy SNAPSHOTS of master to public Apache Repository,Task,3,Resolved,5,Fixed,2017-06-03 00:25:38,2017-04-22 11:15:51,2017-06-03T00:25:38.000+0000,eolivelli,Enrico Olivelli,eolivelli,It would be useful to deploy regularly current master to Maven Central so that it will be simpler for downstream projects to test new version without the need of custom local repositories,2017-04-22 11:15:51,2017-06-03 00:25:38
BOOKKEEPER-1043,Upgrade Apache Parent Pom Reference to latest version,Task,3,Resolved,5,Fixed,2017-04-25 05:44:20,2017-04-24 09:59:14,2017-04-27T18:11:27.000+0000,eolivelli,Enrico Olivelli,eolivelli,"Latest version is 18 
http://repo.maven.apache.org/maven2/org/apache/apache/",2017-04-24 09:59:14,2017-04-25 05:44:20
BOOKKEEPER-1044,Entrylogger is not readding rolled logs back to the logChannelsToFlush list when exception happens while trying to flush rolled logs,Bug,1,Resolved,5,Fixed,2017-07-25 09:04:49,2017-04-25 00:08:16,2017-07-26T13:52:37.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,"SyncThread.checkpoint(Checkpoint checkpoint) (which is called periodically by SyncThread's executor for every flushInterval) ultimately calls EntryLogger.flushRotatedLogs.  

In EntryLogger.flushRotatedLogs, first we set 'logChannelsToFlush' to null and then we try to flush and close individual file. Now, if IOException happens while trying to flush/close the logchannel, then exception is thrown as it is and it get propagates back upto SyncThread.checkpoint. Here we catch that IOException, log it and return without calling the checkpointComplete. But by now we lost reference of 'logChannelsToFlush' (rolled logs which are yet to be closed), because it is set to null before we try to flush/close individually rolledlogs. The next execution of 'checkpoint' (after flushinterval) wouldn't be knowing about the rolledlogs it failed to flush/close the previous time and it would flush the newly rolledlogs. So the failure of flush/close of the previous rolledlogs goes unnoticed completely. 

in EntryLogger.java
        void flushRotatedLogs() throws IOException {
        List<BufferedLogChannel> channels = null;
        long flushedLogId = INVALID_LID;
        synchronized (this) {
            channels = logChannelsToFlush;
            logChannelsToFlush = null;               <--------- here we set 'logChannelsToFlush' to null before it tries to flush/close rolledlogs 
        }
        if (null == channels) {
            return;
        }
        for (BufferedLogChannel channel : channels) {
            channel.flush(true);                      <------------IOEXception can happen here or in the following closeFileChannel call             
            // since this channel is only used for writing, after flushing the channel,
            // we had to close the underlying file channel. Otherwise, we might end up
            // leaking fds which cause the disk spaces could not be reclaimed.
            closeFileChannel(channel);
            if (channel.getLogId() > flushedLogId) {
                flushedLogId = channel.getLogId();
            }
            LOG.info(""Synced entry logger {} to disk."", channel.getLogId());
        }
        // move the leastUnflushedLogId ptr
        leastUnflushedLogId = flushedLogId + 1;
    }

in SyncThread.java
    public void checkpoint(Checkpoint checkpoint) {
        try {
            checkpoint = ledgerStorage.checkpoint(checkpoint);
        } catch (NoWritableLedgerDirException e) {
            LOG.error(""No writeable ledger directories"", e);
            dirsListener.allDisksFull();
            return;
        } catch (IOException e) {
            LOG.error(""Exception flushing ledgers"", e); <-----that IOExc gets propagated to this method and here it is caught and not dealt appropriately    
            return;
        }

        try {
            checkpointSource.checkpointComplete(checkpoint, true);
        } catch (IOException e) {
            LOG.error(""Exception marking checkpoint as complete"", e);
            dirsListener.allDisksFull();
        }
    }",2017-04-25 00:08:16,2017-07-25 09:04:49
BOOKKEEPER-1045,Execute tests in different JVM processes,Test,6,Resolved,5,Fixed,2017-05-04 08:32:29,2017-05-04 00:38:24,2017-05-04T13:49:45.000+0000,mmerli,Matteo Merli,mmerli,"The current Maven Surefire configuration is using:

{code:xml}
<forkMode>always</forkMode>
{code}

This is a deprecated config and apparently it's not creating new processes for each test as intended. 

Currently the tests are leaking a big number of files and threads due to several reasons: 

 * Tests that instantiate bookies and call shutdown() without calling start() before are creating and initializing the ledger storage but not closing it, leaking threads and several fds
 * ZooKeeperClient sometimes doesn't shutdown the zk handle if the test completes too quickly, leaking sockets.
 * Several tests are passing bad config, so the bookie/client start gets exception (on purpose) and then doesn't clean up some partial objects.
 * ...

That make running the test suite to be dependent on ulimit of the machine. 

Until we can fix (almost) all the test to do proper cleanup, we should make maven to run tests in separated processes.
",2017-05-04 00:38:24,2017-05-04 08:32:29
BOOKKEEPER-1046,Avoid long to Long conversion in OrderedSafeExecutor task submit,Improvement,4,Resolved,5,Fixed,2017-05-04 20:39:48,2017-05-04 06:45:28,2017-05-05T13:46:12.000+0000,mmerli,Matteo Merli,mmerli,"When submitting tasks to an OrderedSafeExecutor, most of the time a ledger id is being passed. Given that the method accepts and Object, the primitive long is boxed into a Long allocated on the heap.

Added specific method overload to directly accept longs as the key in the OrderedSafeExecutor.",2017-05-04 06:45:28,2017-05-04 20:39:48
BOOKKEEPER-1047,Add missing error code in ZK setData return path,Bug,1,Resolved,5,Fixed,2017-05-15 21:21:24,2017-05-04 17:21:31,2017-05-15T21:21:24.000+0000,mmerli,Matteo Merli,mmerli,The log warning is not printing the error code returned by ZooKeeper,2017-05-04 17:21:31,2017-05-15 21:21:24
BOOKKEEPER-1048,Use ByteBuf in LedgerStorageInterface,Improvement,4,Resolved,5,Fixed,2017-05-15 22:32:13,2017-05-05 23:52:03,2017-05-16T13:36:22.000+0000,mmerli,Matteo Merli,mmerli,"To pass ref-counted buffer from Netty directly to the storage and the Journal, we need to have LedgerStorage to accept ByteBuf instead of ByteBuffer",2017-05-05 23:52:03,2017-05-15 22:32:13
BOOKKEEPER-1049,Run BookKeeper on Java9,Improvement,4,Open,1,,,2017-05-08 13:10:53,2017-10-17T21:26:39.000+0000,eolivelli,Enrico Olivelli,eolivelli,"I am tring to run BookKeeper on Java9, a part from simple issues:
- exclude the transitive dependency to jdk.tools in bookkeeer-benchmarks
- fix a warning due to the fact the Class.forName in java9 is deprecated and we are running javac with the ""Werror"" option (warning = error)

we have a real stopper, in fact we want to access the low level ID of FileDescriptors using the reflaction and by default this is not allowed.

This is the error:

{code}
java.lang.AssertionError
        at org.apache.bookkeeper.util.NativeIO.getFieldByReflection(NativeIO.java:63)
        at org.apache.bookkeeper.util.NativeIO.getSysFileDescriptor(NativeIO.java:75)
        at org.apache.bookkeeper.bookie.JournalChannel.<init>(JournalChannel.java:218)
        at org.apache.bookkeeper.bookie.JournalChannel.<init>(JournalChannel.java:97)
        at org.apache.bookkeeper.bookie.JournalChannel.<init>(JournalChannel.java:86)
        at org.apache.bookkeeper.bookie.UpgradeTest.writeJournal(UpgradeTest.java:83)
        at org.apache.bookkeeper.bookie.UpgradeTest.newV1JournalDirectory(UpgradeTest.java:114)
        at org.apache.bookkeeper.bookie.UpgradeTest.testUpgradeV1toCurrent(UpgradeTest.java:192)
{code}",2017-05-08 13:10:53,
BOOKKEEPER-1050,Cache journalFormatVersionToWrite when starting Journal,Improvement,4,Resolved,5,Fixed,2017-05-09 20:26:45,2017-05-09 17:16:35,2017-05-10T14:02:14.000+0000,mmerli,Matteo Merli,mmerli,"Reading the journal version format from {{ServiceConfiguration}} each time is inefficient. 

{{ServiceConfiguration}} is based on Java properties which is based on a String to object hashtable. Each read implies acquiring a mutex and converting from object to int.",2017-05-09 17:16:35,2017-05-09 20:26:45
BOOKKEEPER-1051,Fast shutdown for GarbageCollectorThread,Improvement,4,Resolved,5,Fixed,2017-05-09 21:06:26,2017-05-09 17:59:53,2017-05-11T15:15:46.000+0000,mmerli,Matteo Merli,mmerli,"Several unit tests are taking very long time to complete (eg: {{BookieLedgerIndexTest}} taking ~10 minutes). 
The reason is that these tests are playing with the ZK quorum shutting it down and after the test succeeds, the shutdown phase is taking long time, since we try to do graceful shutdown with 1min wait time. 

I think is better to interrupt immediately the garbage collector thread when shutting down the bookie.",2017-05-09 17:59:53,2017-05-09 21:06:26
BOOKKEEPER-1052,Print autorecovery enabled or not in bookie shell,Improvement,4,Resolved,5,Fixed,2017-05-09 21:08:04,2017-05-09 20:29:28,2017-05-10T14:02:44.000+0000,mmerli,Matteo Merli,mmerli,"Print the current status of auto-recovery, whether it's enabled or disabled.",2017-05-09 20:29:28,2017-05-09 21:08:04
BOOKKEEPER-1053,Upgrade RAT maven version to 0.12 and ignore Eclipse project files,Improvement,4,Resolved,5,Fixed,2017-05-10 01:17:46,2017-05-09 23:58:00,2017-05-10T14:03:05.000+0000,mmerli,Matteo Merli,mmerli,RAT maven plugin should ignore existing Eclipse project files.,2017-05-09 23:58:00,2017-05-10 01:17:46
BOOKKEEPER-1054,Add gitignore file,Task,3,Resolved,5,Fixed,2017-05-10 21:18:00,2017-05-10 00:37:09,2017-05-11T13:25:39.000+0000,mmerli,Matteo Merli,mmerli,We should have a .gitignore file to hide all build generated files.,2017-05-10 00:37:09,2017-05-10 21:18:00
BOOKKEEPER-1055,Optimize handling of masterKey in case it is empty,Improvement,4,Resolved,5,Fixed,2017-05-17 06:58:13,2017-05-10 17:45:41,2017-05-17T13:25:41.000+0000,mmerli,Matteo Merli,mmerli,"On each request client and bookies are exchanging the ledger masterKey, which is a 20 bytes MAC digest of the ledger password.

For each request there is a considerable overhead in allocating byte arrays when parsing the add/read requests. 

If the client is a passing an empty password, we should optimize the data path to skip all allocations (related to the masterKey) and instead rely on a static byte array.",2017-05-10 17:45:41,2017-05-17 06:58:13
BOOKKEEPER-1056,Removed PacketHeader serialization/deserialization allocation,Improvement,4,Resolved,5,Fixed,2017-06-01 19:23:04,2017-05-10 17:51:38,2017-06-02T13:23:57.000+0000,mmerli,Matteo Merli,mmerli,"When parsing the request packet header, use static methods to avoid creating a {{PacketHeader}} instance.",2017-05-10 17:51:38,2017-06-01 19:23:04
BOOKKEEPER-1057,Do not log error message after read failure in PendingReadOp,Task,3,Resolved,5,Fixed,2017-10-09 09:08:56,2017-05-10 18:05:42,2017-10-09T09:08:56.000+0000,mmerli,Matteo Merli,mmerli,"In {{PendingReadOp}}, there is an error message that is printed each time a read on a specific bookie is failing: 

{noformat}
LOG.error(""Read of ledger entry failed: L{} E{}-E{}, Heard from {}. First unread entry is {}"",
    new Object[] { lh.getId(), startEntryId, endEntryId, heardFromHosts, firstUnread });
{noformat}

This message is getting printed each time a ledger is recovered and there is no error, since the ledger recovery logic is to keep reading and incrementing the entryId until a NoEntry error is received.

This log message should be set at debug level.
",2017-05-10 18:05:42,2017-10-09 09:08:56
BOOKKEEPER-1058,Ignore already deleted ledger on replication audit,Bug,1,Resolved,5,Fixed,2017-05-15 17:32:47,2017-05-10 18:18:51,2017-05-16T13:36:06.000+0000,mmerli,Matteo Merli,mmerli,Replication auditor should skip ledgers that were deleted since the auditing was started.,2017-05-10 18:18:51,2017-05-15 17:32:47
BOOKKEEPER-1059,Upgrade to SLF4J-1.7.25,Task,3,Resolved,5,Fixed,2017-05-10 21:15:20,2017-05-10 18:30:07,2017-05-11T13:25:21.000+0000,mmerli,Matteo Merli,mmerli,"BookKeeper is currently using SLF4J 1.6.4. By upgrading to 1.7x, the most visible change would be to be able to pass a variable number of arguments without needing to wrap them into a:
{code:java}
log.info(""msg: {} {} {}"", new Object[] {x, y, x});
// versus
log.info(""msg: {} {} {}"", x, y, x);
{code}

SLF4J 1.7 has been around since 2012.",2017-05-10 18:30:07,2017-05-10 21:15:20
BOOKKEEPER-1060,Add utility to use SafeRunnable from Java8 Lambda,Task,3,Resolved,5,Fixed,2017-05-10 20:47:20,2017-05-10 20:27:54,2017-05-11T13:25:02.000+0000,mmerli,Matteo Merli,mmerli,"Since BK-4.5.0 is already switched to Java8, we should have a simple and concise way to pass lambdas where a {{SafeRunnable}} is required.",2017-05-10 20:27:54,2017-05-10 20:47:20
BOOKKEEPER-1061,BookieWatcher should not do ZK blocking operations from ZK async callback thread,Bug,1,Resolved,5,Fixed,2017-05-15 19:35:43,2017-05-10 20:50:34,2017-05-16T13:36:18.000+0000,mmerli,Matteo Merli,mmerli,"In some cases, the BookieWatcher can get the ZK event thread stuck. This happens when a ZK blocking request is issued from a ZK callback thread. 

We should decouple the blocking requests in a separate executor to avoid deadlocking ZK client.",2017-05-10 20:50:34,2017-05-15 19:35:43
BOOKKEEPER-1062,AuditorLedgerCheckerTest intermittent failures,Test,6,Open,1,,,2017-05-10 21:44:37,2017-10-17T21:33:16.000+0000,revans2,Robert Joseph Evans,revans2,"A couple of tests in {{AuditorLedgerCheckerTest}} keep failing from time to time on Jenkins builds, irrespective of the PR changes.

Example:
{noformat}
org.apache.bookkeeper.replication.AuditorLedgerCheckerTest.testReadOnlyBookieExclusionFromURLedgersCheck[4]
org.apache.bookkeeper.replication.AuditorLedgerCheckerTest.testReadOnlyBookieShutdown[4]
{noformat}

{noformat}
java.lang.AssertionError: latch should not have completed
	at org.apache.bookkeeper.replication.AuditorLedgerCheckerTest.testReadOnlyBookieExclusionFromURLedgersCheck(AuditorLedgerCheckerTest.java:283)
{noformat}

",2017-05-10 21:44:37,
BOOKKEEPER-1063,Use executure.execute() instead of submit() to avoid creation of unused FutureTask,Improvement,4,Resolved,5,Fixed,2017-05-15 21:20:55,2017-05-10 21:55:41,2017-05-15T21:20:55.000+0000,mmerli,Matteo Merli,mmerli,"When submitting tasks to an executor, if the {{FutureTask}} object is not being used we should use {{execute()}} instead of {{submit()}} in order to avoid the task object allocation.",2017-05-10 21:55:41,2017-05-15 21:20:55
BOOKKEEPER-1064,ConcurrentModificationException in AuditorLedgerCheckerTest,Test,6,Resolved,5,Fixed,2017-05-12 13:20:51,2017-05-11 16:40:52,2017-05-13T14:01:45.000+0000,mmerli,Matteo Merli,mmerli,"As seen in:
https://builds.apache.org/job/bookkeeper-master-git-pullrequest/371/

The test is iterating over a hash map that gets updated by a different thread. The map needs to be concurrent.

{noformat}
java.util.ConcurrentModificationException
	at org.apache.bookkeeper.replication.AuditorLedgerCheckerTest.stopAuditorElectors(AuditorLedgerCheckerTest.java:130)
	at org.apache.bookkeeper.replication.AuditorLedgerCheckerTest.tearDown(AuditorLedgerCheckerTest.java:114)
{noformat}

All subsequent tests in the same class are failing because of the 1st test not cleaning up properly.
",2017-05-11 16:40:52,2017-05-12 13:20:51
BOOKKEEPER-1065,OrderedSafeExecutor should only have 1 thread per bucket,Bug,1,Resolved,5,Invalid,2017-05-11 20:25:51,2017-05-11 16:58:28,2017-05-11T20:25:51.000+0000,mmerli,Matteo Merli,mmerli,"In a earlier commit, ""BOOKKEEPER-874: Explict LAC from Writer to Bookie"", there was this change in the OrderedSafeExecutor implementation: 

{noformat}
         for (int i = 0; i < numThreads; i++) {
-            queues[i] = new LinkedBlockingQueue<Runnable>();
-            threads[i] =  new ThreadPoolExecutor(1, 1,
-                    0L, TimeUnit.MILLISECONDS, queues[i],
+            threads[i] =  new ScheduledThreadPoolExecutor(1,
                     new ThreadFactoryBuilder()
                         .setNameFormat(name + ""-orderedsafeexecutor-"" + i + ""-%d"")
                         .setThreadFactory(threadFactory)
                         .build());
+            threads[i].setMaximumPoolSize(1);
{noformat}

Then, as part of ""BOOKKEEPER-1013: Fix findbugs errors on latest master"", the max pool size line has been removed.

{noformat}
@@ -183,7 +183,6 @@ public class OrderedSafeExecutor {
                         .setNameFormat(name + ""-orderedsafeexecutor-"" + i + ""-%d"")
                         .setThreadFactory(threadFactory)
                         .build());
-            threads[i].setMaximumPoolSize(1);

             // Save thread ids
             final int idx = i;
{noformat}

Without that the thread pool would create multiple threads for the same bucket, breaking the ordering guarantee of the executor.",2017-05-11 16:58:28,2017-05-11 20:25:51
BOOKKEEPER-1066,Introduce GrowableArrayBlockingQueue,Improvement,4,Resolved,5,Fixed,2017-05-12 13:18:23,2017-05-11 18:29:05,2017-05-16T00:18:24.000+0000,mmerli,Matteo Merli,mmerli,"In multiple places, (eg: journal, ordered executor, etc..), we are using {{LinkedBlockingQueue}} instances to pass objects between threads.

The {{LinkedBlockingQueue}} differs from the {{ArrayBlockingQueue}} in that it doesn't require to define a max queue size, though, being implemented with a linked list, it requires to allocates list nodes each time an item is added.

We can use a {{GrowableArrayBlockingQueue}} that behaves in the same way as the {{LinkedBlockingQueue}}, but it's implemented with an array that can be resized when the queue reaches the capacity.

",2017-05-11 18:29:05,2017-05-12 13:18:23
BOOKKEEPER-1067,Add Prometheus stats provider,New Feature,2,Resolved,5,Fixed,2017-05-15 19:25:32,2017-05-15 17:25:57,2017-05-16T13:36:14.000+0000,mmerli,Matteo Merli,mmerli,"Prometheus (https://prometheus.io) is a metrics collection system, similar but much more flexible than graphite. 

It would be good to expose the Bookie and BookKeeper client stats directly so that a Prometheus instance can collect them (and also check the process status and add alerts).

",2017-05-15 17:25:57,2017-05-15 19:25:32
BOOKKEEPER-1068,Expose ByteBuf in LedgerEntry to avoid data copy,Improvement,4,Resolved,5,Fixed,2017-05-25 12:23:18,2017-05-15 23:00:04,2017-05-25T13:23:03.000+0000,mmerli,Matteo Merli,mmerli,"To avoid copying the entries payloads when writing/reading on a ledger and having to allocate a lot of byte[] on the JVM heap, we need to accept Netty ByteBuf buffer.

By passing a ByteBuf, an application can use a pooled buffer, pointing to direct memory, to the {{LedgerHandle.addEntry()}} and have the same buffer forwarded on the connection sockets to the bookies.

The same thing on the read side, {{LedgerEntry}} exposes an additional {{getEntryBuffer()}} method that can be used to get the underlying buffer and possibly forward that to some other connection, with zero-copy behavior (excluding getting data in-out of the kernel).

",2017-05-15 23:00:04,2017-05-25 12:23:18
BOOKKEEPER-1069,"If client uses V2 proto, set the connection to always decode V2 messages",Improvement,4,Resolved,5,Fixed,2017-05-18 03:42:14,2017-05-15 23:57:19,2017-05-18T03:43:36.000+0000,mmerli,Matteo Merli,mmerli,Avoid handling parsing exception for each request and instead adapt to what the client is sending.,2017-05-15 23:57:19,2017-05-18 03:42:14
BOOKKEEPER-1070,bk-merge-pr.py use apache-rat:check goal instead of rat:rat,Task,3,Resolved,5,Fixed,2017-05-18 14:22:00,2017-05-17 15:19:01,2017-05-19T14:04:13.000+0000,eolivelli,Enrico Olivelli,eolivelli,,2017-05-17 15:19:01,2017-05-18 14:22:00
BOOKKEEPER-1071,BookieRecoveryTest is failing due to a Netty4 IllegalReferenceCountException,Bug,1,Resolved,5,Fixed,2017-06-01 07:47:42,2017-05-18 03:07:45,2017-06-01T11:52:29.000+0000,mmerli,Matteo Merli,mmerli,"this is the killer commit:
e44c7388399e5589cf44e38c58bb84c74da544af BOOKKEEPER-1069: If client uses V2 proto, set the connection to always decode V2 messages

this commit was working:
0f81461d2d1dc5cf9db4de9a46599d7d64e3dac6 BOOKKEEPER-1048: Use ByteBuf in LedgerStorage interface

{code}
2017-05-18 04:50:39,691 - WARN  - [bookie-io-4:Slf4JLogger@151] - An exceptionCaught() event was fired, and it reached at the tail of the pipeline. It usually means the last handler in the pipeline did not handl
e the exception.
io.netty.util.IllegalReferenceCountException: refCnt: 0, decrement: 1
        at io.netty.buffer.AbstractReferenceCountedByteBuf.release0(AbstractReferenceCountedByteBuf.java:101)
        at io.netty.buffer.AbstractReferenceCountedByteBuf.release(AbstractReferenceCountedByteBuf.java:89)
        at io.netty.util.ReferenceCountUtil.release(ReferenceCountUtil.java:84)
        at io.netty.channel.DefaultChannelPipeline.onUnhandledInboundMessage(DefaultChannelPipeline.java:1169)
        at io.netty.channel.DefaultChannelPipeline$TailContext.channelRead(DefaultChannelPipeline.java:1221)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
        at org.apache.bookkeeper.proto.BookieRequestHandler.channelRead(BookieRequestHandler.java:77)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
        at io.netty.channel.ChannelInboundHandlerAdapter.channelRead(ChannelInboundHandlerAdapter.java:86)
        at org.apache.bookkeeper.proto.AuthHandler$ServerSideHandler.channelRead(AuthHandler.java:90)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
        at io.netty.handler.codec.MessageToMessageDecoder.channelRead(MessageToMessageDecoder.java:102)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
        at io.netty.handler.codec.ByteToMessageDecoder.fireChannelRead(ByteToMessageDecoder.java:293)
        at io.netty.handler.codec.ByteToMessageDecoder.channelRead(ByteToMessageDecoder.java:267)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.AbstractChannelHandlerContext.fireChannelRead(AbstractChannelHandlerContext.java:340)
        at io.netty.channel.DefaultChannelPipeline$HeadContext.channelRead(DefaultChannelPipeline.java:1334)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:362)
        at io.netty.channel.AbstractChannelHandlerContext.invokeChannelRead(AbstractChannelHandlerContext.java:348)
        at io.netty.channel.DefaultChannelPipeline.fireChannelRead(DefaultChannelPipeline.java:926)
        at io.netty.channel.epoll.AbstractEpollStreamChannel$EpollStreamUnsafe.epollInReady(AbstractEpollStreamChannel.java:1017)
        at io.netty.channel.epoll.EpollEventLoop.processReady(EpollEventLoop.java:394)
        at io.netty.channel.epoll.EpollEventLoop.run(EpollEventLoop.java:299)
        at io.netty.util.concurrent.SingleThreadEventExecutor$5.run(SingleThreadEventExecutor.java:858)

{code}",2017-05-18 03:07:45,2017-06-01 07:47:42
BOOKKEEPER-1072,CompactionTest is flaky when disks are almost full,Bug,1,Resolved,5,Fixed,2017-05-25 11:38:21,2017-05-25 01:31:22,2017-05-25T11:39:35.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,"The tests will fail when the disks are almost full. Because it will trigger force compaction.

Set the threshold to 0.99 for tests to make it more reliable.",2017-05-25 01:31:22,2017-05-25 11:38:21
BOOKKEEPER-1073,Several stats provider related changes.,Bug,1,Resolved,5,Fixed,2017-06-01 06:57:19,2017-05-25 02:54:06,2017-06-01T11:52:25.000+0000,l4stewar,Leigh Stewart,l4stewar,"Merge changes from twitter's branch:

- add finagle stats provider
- provide the ability to remove gauge and scopes
- update jetty versions for twitter-sciences stats provider",2017-05-25 02:54:06,2017-06-01 06:57:19
BOOKKEEPER-1074,Remove JMX Bean ,Bug,1,Resolved,5,Fixed,2017-06-01 11:21:16,2017-05-25 03:20:07,2017-06-01T15:21:19.000+0000,l4stewar,Leigh Stewart,l4stewar,"JMX Bean was the old fashion used for exporting metrics. It was introduced before stats-provider introduced. Now stats-provider is there. Let's remove JMX Bean.

It is the change ported from Twitter branch.",2017-05-25 03:20:07,2017-06-01 11:21:16
BOOKKEEPER-1075,BK LedgerMetadata: more memory-efficient parsing of configs,Bug,1,Resolved,5,Fixed,2017-05-25 12:32:13,2017-05-25 03:33:15,2017-05-25T13:23:07.000+0000,l4stewar,Leigh Stewart,l4stewar,"Looking at the most prevalent client-side memory allocations, I noticed that we allocate 4KB every time we open a ledger. This is caused by allocating a 4KB buffer (in TextFormat.toStringBuilder) to account for the maximum possible Protobufs message, which is unnecessary in our case: we know the exact size of the metadata ( << 500 B) and don't need to allocate more.
    TextFormat.merge(Readable, Message.Builder) is the current method we use. This changes to use TextFormat.merge(CharSequence, Message.Builder), which avoids the extra 4K allocation conversion + an extra StringBuilder.

It is the contribution from Alex Yarmula

{quote}
commit 9d9d7dd26235a9beda4421b7bed750fea1789076
Author: Alex Yarmula <ak@twitter.com>
Date:   Wed Sep 23 05:57:30 2015 -0700

    BK LedgerMetadata: more memory-efficient parsing of configs

    Looking at the most prevalent client-side memory allocations, I noticed that we allocate 4KB every time we open a ledger. This is caused by allocating a 4KB buffer (in TextFormat.toStringBuilder) to account for the maximum possible Protobufs message, which is unnecessary in our case: we know the exact size of the metadata ( << 500 B) and don't need to allocate more.
    TextFormat.merge(Readable, Message.Builder) is the current method we use. This changes to use TextFormat.merge(CharSequence, Message.Builder), which avoids the extra 4K allocation conversion + an extra StringBuilder.
    RB_ID=745700
{quote}
",2017-05-25 03:33:15,2017-05-25 12:32:13
BOOKKEEPER-1077,BookKeeper: Local Bookie Journal and ledger paths,Bug,1,Resolved,5,Fixed,2017-05-26 10:38:54,2017-05-25 03:58:12,2017-05-26T13:48:52.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,"Use the journal directory and ledger paths specified in the configuration file passed in to local bookie. Before this change local bookie was always creating directories in the temp folder
",2017-05-25 03:58:12,2017-05-26 10:38:54
BOOKKEEPER-1078,Local BookKeeper enhancements for testability,Test,6,Resolved,5,Fixed,2017-06-01 09:31:27,2017-05-25 04:04:42,2017-06-01T11:52:35.000+0000,robindhamankar,Robin Dhamankar,robindhamankar,"    BookKeeper: Local Bookkeeper enhancements for testability
    1. Allow creating local bookies without always starting a zookeeper server - This is required as tests may want to create and use their own instance of a test zookeeper
    2. Allow using non default zookeeper host and more importantly non default ZK port
    3. Allowing the caller to specify the initial port for the bookies
    4. Optionally shutdown bookies when the bookie thread exits",2017-05-25 04:04:42,2017-06-01 09:31:27
BOOKKEEPER-1079,shell lastMark throws NPE,Bug,1,Resolved,5,Fixed,2017-05-26 19:44:54,2017-05-26 14:31:52,2017-05-27T13:48:58.000+0000,eolivelli,Enrico Olivelli,eolivelli,"
{code}
[enrico.olivelli@DNA101PC193 bookkeeper-server-4.5.0-SNAPSHOT]$ bin/bookkeeper shell lastmark
JMX enabled by default
Exception in thread ""main"" java.lang.NullPointerException
	at org.apache.bookkeeper.bookie.BookieShell.printLastLogMark(BookieShell.java:2304)
	at org.apache.bookkeeper.bookie.BookieShell$LastMarkCmd.runCmd(BookieShell.java:1064)
	at org.apache.bookkeeper.bookie.BookieShell$MyCommand.runCmd(BookieShell.java:175)
	at org.apache.bookkeeper.bookie.BookieShell.run(BookieShell.java:1915)
	at org.apache.bookkeeper.bookie.BookieShell.main(BookieShell.java:1992)
{code}",2017-05-26 14:31:52,2017-05-26 19:44:54
BOOKKEEPER-1080,Add reference to Scala tutorial to documentation,Task,3,Resolved,5,Fixed,2017-05-27 07:37:35,2017-05-26 20:08:26,2017-05-27T07:37:35.000+0000,eolivelli,Enrico Olivelli,eolivelli,Add a reference to https://github.com/bwsw/bookkeeper-tutorial-scala to the official documentation website,2017-05-26 20:08:26,2017-05-27 07:37:35
BOOKKEEPER-1081,Would like to provide a docker file for bookkeeper,Wish,5,Resolved,5,Fixed,2017-10-06 08:56:45,2017-05-27 13:09:43,2017-10-06T08:56:45.000+0000,zhaijia,Jia Zhai,zhaijia,Would like to provide a docker file for bookkeeper,2017-05-27 13:09:43,2017-10-06 08:56:45
BOOKKEEPER-1082,Issue with 'preallocation' feature in EntryLogger,Bug,1,Open,1,,,2017-06-01 06:16:27,2017-10-17T21:26:35.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,"With BOOKKEEPER-643 (https://github.com/apache/bookkeeper/commit/694568b0ff0d048c284c8d5db0c9455d30dfa3ce) feature, 'entryLogFilePreallocationEnabled' is introduced. But by the way it is handled,  it looks like it can never be used. 

In EntryLoggerAllocator.createNewLog, even if entryLogPreAllocationEnabled is configured to true, else block is unreachable because preallocation will always be null and it would end up with if block. So effectively entryLogFilePreallocationEnabled logic is broken.



        synchronized BufferedLogChannel createNewLog() throws IOException {
            BufferedLogChannel bc;
            if (!entryLogPreAllocationEnabled || null == preallocation) {
                // initialization time to create a new log
                bc = allocateNewLog();
            } else {
                // has a preallocated entry log
                ......
                ......
                preallocation = allocatorExecutor.submit(new Callable<BufferedLogChannel>() {   <-------- this is the only place where 'preallocation' is set and it is not possible to get into the else block in this method  ------------>

                    @Override
                    public BufferedLogChannel call() throws IOException {
                        return allocateNewLog();
                    }
                });
            }
            LOG.info(""Created new entry logger {}."", bc.getLogId());
            return bc;
        }
",2017-06-01 06:16:27,
BOOKKEEPER-1083,Improvements on OrderedSafeExecutor,Improvement,4,Resolved,5,Fixed,2017-06-01 10:31:06,2017-06-01 07:35:31,2017-06-01T11:52:47.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,Merge the the improvements made to OrderedSafeExecutor.,2017-06-01 07:35:31,2017-06-01 10:31:06
BOOKKEEPER-1084,Make variables finale if necessary,Improvement,4,Resolved,5,Fixed,2017-06-01 09:42:20,2017-06-01 08:08:57,2017-06-01T11:52:41.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,"Merge commit 

{code}
commit daffc8460670cd15994bb8650add3be5a9dc2eef
Author: Sijie Guo <sijieg@twitter.com>
Date:   Thu Apr 18 17:54:55 2013 -0700

    make logger as a static variable
    not all logger in bookkeeper & hedwig are static. some class like PendnigReadOp and LedgerEntry would have lots of objects, it might be bad. so this task is to make logger as a static variable if it didn't.

    with benefit, cleaning up the imports when touching that file.

    RB_ID=141138
{code}",2017-06-01 08:08:57,2017-06-01 09:42:20
BOOKKEEPER-1085,Introduce the AlertStatsLogger,Improvement,4,Resolved,5,Fixed,2017-06-01 11:17:03,2017-06-01 08:15:07,2017-06-01T11:52:54.000+0000,robindhamankar,Robin Dhamankar,robindhamankar,Introduce the AlertStatsLogger used to increment a metric whenever an event that should never happen is detected. Allow specifying an optional scope to better classify the error  conditions,2017-06-01 08:15:07,2017-06-01 11:17:03
BOOKKEEPER-1086,Ledger Recovery - Refactor PendingReadOp,Sub-task,7,Resolved,5,Fixed,2017-06-01 20:40:58,2017-06-01 19:13:34,2017-06-28T21:28:53.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org," bookkeeper recovery improvement (part-1): refactor PendingReadOp

    this change is the first part of improving bookkeeper recovery. it is basically a refactor change, which:

    - abstract an interface for LedgerEntryRequest in PendingReadOp
    - rename current implementation to SequenceReadRequest, which read the entry in the sequence of quorum.",2017-06-01 19:13:34,2017-06-01 20:40:58
BOOKKEEPER-1087,Ledger Recovery - Add a parallel reading request in PendingReadOp,Sub-task,7,Resolved,5,Fixed,2017-06-05 19:48:47,2017-06-01 19:14:30,2017-06-06T18:13:07.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,"    bookkeeper recovery improvement (part-2): add a parallel reading request in PendingReadOp

    - add a parallel reading request in PendingReadOp
    - allow PendingReadOp to configure whether to do parallel reading or not
    - add flag in ClientConfiguration to allow configuring whether to do parallel reading in LedgerRecoveryOp or not.",2017-06-01 19:14:30,2017-06-05 19:48:47
BOOKKEEPER-1088,Ledger Recovery - Add a ReadEntryListener to callback on individual request,Sub-task,7,Resolved,5,Fixed,2017-06-05 20:13:47,2017-06-01 19:15:52,2017-06-10T13:23:23.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,"bookkeeper recovery improvement (part-3): add a ReadEntryListener to callback on individual request.

    - add read entry listener which allow doing batch read, but callback on individual entries in sequence. so in recovery op, we could issue batch reads, then on each individual callback do add entry and stop when received NoSuchEntry.",2017-06-01 19:15:52,2017-06-05 20:13:47
BOOKKEEPER-1089,Ledger Recovery - allow batch reads in ledger recovery,Sub-task,7,Resolved,5,Fixed,2017-06-21 17:50:38,2017-06-01 19:16:32,2017-06-22T13:26:06.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,"bookkeeper recovery improvement (part-4): allow batch reading in ledger recovery

    - enable batch read in ledger recovery, so we could parallel reading to improve recovery time.",2017-06-01 19:16:32,2017-06-21 17:50:38
BOOKKEEPER-1090,Use LOG.isDebugEnabled() to avoid unexpected allocations,Improvement,4,Resolved,5,Fixed,2017-06-22 00:11:39,2017-06-01 21:05:06,2017-06-22T00:11:39.000+0000,mmerli,Matteo Merli,mmerli,"Using {{LOG.debug(...)}} can lead to multiple unexpected memory allocation, even when the logger it's turned off.

For example, {{int}} and {{long}} parameter are boxed into {{Integer}} and {{Long}} objects and the var-arg parameters are using an {{Object[]}} to hold
them.

We should guard all usages of {{LOG.debug()}} with the {{if (LOG.isDebugEnabled()}} guard.",2017-06-01 21:05:06,2017-06-22 00:11:39
BOOKKEEPER-1091,Remove Hedwig from BookKeeper website page,Task,3,Resolved,5,Fixed,2017-06-03 00:39:37,2017-06-01 21:50:53,2017-06-03T00:39:37.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,"We removed Hedwig before, but it still exists in the website and links to a deleted wiki page. ",2017-06-01 21:50:53,2017-06-03 00:39:37
BOOKKEEPER-1092,Ledger Recovery - Add Test Case for Parallel Ledger Recovery,Sub-task,7,Resolved,5,Fixed,2017-06-21 19:00:26,2017-06-01 23:52:48,2017-06-22T13:26:08.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,Add test case for parallel ledger recovery,2017-06-01 23:52:48,2017-06-21 19:00:26
BOOKKEEPER-1093,Piggyback LAC on ReadResponse,Sub-task,7,Resolved,5,Fixed,2017-06-21 17:58:13,2017-06-02 20:17:11,2017-06-22T13:26:07.000+0000,sijie@apache.org,Sijie Guo,sijie@apache.org,"Currently LAC is only updated when the reader explicitly calls #readLastAddConfirmed(). In tailing-read use cases, it will not wise to keep calling #readLastAddConfirmed, especially when the traffic is huge.

The idea here is piggy-back LAC along with the read responses. so the client will get advanced LAC along with read responses. so it will reduce calling #readLastAddConfirmed. ",2017-06-02 20:17:11,2017-06-21 17:58:13
BOOKKEEPER-1094,Long Poll - Server and Client Side Changes,Sub-task,7,Resolved,5,Fixed,2017-07-17 21:28:38,2017-06-02 20:17:52,2017-07-17T21:28:38.000+0000,robindhamankar,Robin Dhamankar,robindhamankar,Server side changes for supporting long poll.,2017-06-02 20:17:52,2017-07-17 21:28:38
BOOKKEEPER-1096,"When ledger is deleted, along with leaf node all the eligible branch nodes also should be deleted in ZooKeeper.",Improvement,4,Resolved,5,Fixed,2017-06-12 15:21:05,2017-06-09 23:04:07,2017-06-13T13:26:01.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,"Currently when we delete a ledger, we delete just the leaf node in the ZK but we ignore about the branch nodes. This is ok for FlatLedgerManager, but for HierarchicalLedgerManagers, especially for LongHierarchicalLedgerManager, the number of internal nodes gets blown up over time and we would get into ZK capacity limitations. When ZK reaches the capacity limits, it will manifest in very severe performance and stability issues of cluster. So for HierarchicalLedgerManagers, when we delete a ledger we should optimistically recursively delete the parent znodes as well if they dont have anymore child znodes. ",2017-06-09 23:04:07,2017-06-12 15:21:05
BOOKKEEPER-1097,GC test when no WritableDirs,Test,6,Resolved,5,Fixed,2017-06-21 19:07:57,2017-06-13 01:05:13,2017-06-22T13:26:10.000+0000,reddycharan18@gmail.com,Charan Reddy Guttapalem,reddycharan18@gmail.com,"    
    - Functional test validating that Compaction takes place even if there
    are no writableledgerdir but there are ledgerdirs according to
    LedgerDirsManager.getWritableLedgerDirsForNewLog
    
    - end-to-end testcase of Bookie recovery, incase of Bookie ledgerdir reaching
    the threshold, and recovering by forcing the gc/compaction
",2017-06-13 01:05:13,2017-06-21 19:07:57
BOOKKEEPER-1098,ZkUnderreplicationManager can build up an unbounded number of watchers,Bug,1,Resolved,5,Fixed,2017-06-28 21:30:12,2017-06-14 22:26:20,2017-06-28T21:36:15.000+0000,sjust2,Samuel Just,sjust2,"getLedgerToReplicate leaves watches each time it traverses the
tree until it finds a suitable replication target.  Since we don't have
a way of canceling watches, these watches tend to get abandoned,
particularly on interior nodes, which aren't changed much.  Thus,
over time, some nodes would build up a very large number of watches.",2017-06-14 22:26:20,2017-06-28 21:30:12
BOOKKEEPER-1099,Make bookie automatically create folders on new machine.,Improvement,4,Open,1,,,2017-06-21 23:20:51,2017-10-17T21:25:47.000+0000,,,,When bookie start and found it need run bookie format to create folders it should do that automatically. That way will make new machine deployment and machine replacement process much simpler without manually call the bookieformat command.,2017-06-21 23:20:51,
BOOKKEEPER-1100,Add Http Endpoint for Bookkeeper,New Feature,2,Resolved,5,Fixed,2017-08-16 01:37:33,2017-06-25 00:59:05,2017-08-16T13:31:53.000+0000,yzang,Yiming Zang,yzang,"Add a Http Server Component for Bookkeeper.

It would be great that Bookkeeper can have an Http Server to expose some useful APIs. We can expose and manage the server status, server configuration, lifecycle states, query or trigger auto recovery through HTTP Endpoint, or even trigger GC and compaction over Http Endpoint.

This ticket is mainly to add a Http framework for Bookkeeper, so that we can extend more useful APIs based on the existing Http framework.",2017-06-25 00:59:05,2017-08-16 01:37:33
BOOKKEEPER-1101,BookKeeper website menus not working under https,Bug,1,Resolved,5,Fixed,2017-07-19 03:50:20,2017-07-19 02:35:58,2017-07-19T03:50:20.000+0000,zhaijia,Jia Zhai,zhaijia,"the 'Documentation', 'Get Involved' and 'Project Info' drop down menus
on https://bookkeeper.apache.org site are not working.

",2017-07-19 02:35:58,2017-07-19 03:50:20
BOOKKEEPER-1102,org.apache.bookkeeper.client.BookKeeperDiskSpaceWeightedLedgerPlacementTest.testDiskSpaceWeightedBookieSelectionWithBookiesBeingAdded is unreliable,Bug,1,Resolved,5,Fixed,2017-08-01 06:40:46,2017-07-22 00:47:20,2017-08-01T13:56:11.000+0000,sjust2,Samuel Just,sjust2,"org.apache.bookkeeper.client.BookKeeperDiskSpaceWeightedLedgerPlacementTest.testDiskSpaceWeightedBookieSelectionWithBookiesBeingAdded can intermittently fail depending on the timing of the client receiving the info back from the bookies.

Additionally, the synchronization in BookieInfoReader is more complicated than necessary and not entirely correct.",2017-07-22 00:47:20,2017-08-01 06:40:46
BOOKKEEPER-1103,LedgerMetadataCreateTest bug in ledger id generation causes intermittent hang,Bug,1,Resolved,5,Fixed,2017-07-28 20:35:16,2017-07-26 21:39:06,2017-07-29T14:01:01.000+0000,sjust2,Samuel Just,sjust2,,2017-07-26 21:39:06,2017-07-28 20:35:16
BOOKKEEPER-1104,BookieInitializationTest.testWithDiskFullAndAbilityToCreateNewIndexFile testcase is unreliable,Bug,1,Resolved,5,Fixed,2017-07-28 04:39:44,2017-07-27 21:53:15,2017-07-28T13:52:49.000+0000,sjust2,Samuel Just,sjust2,"The bug is that the test sets the full threshhold really close the actual usage (though just below), and if the disk is otherwise in use, the usage can fall below that threshhold during the test.  Instead, just set it to .001 since that's not what we're testing here anyway.
",2017-07-27 21:53:15,2017-07-28 04:39:44
BOOKKEEPER-1105,RackAwarePolicy: Failure to map node into rack may result in failure to add other nodes.,Bug,1,Resolved,5,Fixed,2017-08-16 01:42:23,2017-08-09 18:25:48,2017-08-16T13:31:54.000+0000,ayegorov,Andrey Yegorov,ayegorov,"Ran into this issue:
due to some misconfiguration of new node and rack assignments we've ended up with nodes being assigned to default rack. We are not using region-aware, only rack-aware policy.
This generates the following sequence of events:
- default rack is /default-region/default-rack even though region-aware is not used.
- other nodes mapped to racks like /rack1, /rack2 etc.
- mixing /region/rack and /rack styles is not allowed, but exception on addition of such nodes is swallowed. All following nodes to add (if there were any) just skipped as result.",2017-08-09 18:25:48,2017-08-16 01:42:23
BOOKKEEPER-1106,Ledger eviction should not impact write performance,Bug,1,In Progress,3,,,2017-09-16 17:01:29,2017-10-17T21:24:25.000+0000,yzang,Yiming Zang,yzang,"When read behind happens, it would quickly read bunch of ledgers, which will evict current active ledgers for writing from the ledger cache. with the ledger being evicted from cache, it would impact the write performance.

In order to address this issue, we should separate write FileInfo and read FileInfo in the cache.",2017-09-16 17:01:29,
BOOKKEEPER-1107,Make Apache Bookkeeper JIRA read-only,Bug,1,Open,1,,,2017-10-17 21:54:33,2017-10-17T21:54:33.000+0000,,,,"We have migrated our issues to github, so could you please make JIRA read-only so we don't miss anything.

I've already updated the banner.

Github issues are at: https://github.com/apache/bookkeeper/issues",2017-10-17 21:54:33,
